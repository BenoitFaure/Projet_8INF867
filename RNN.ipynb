{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf32834e",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7f09b02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "22002d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9c5c7a",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0764cd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "company = '^FCHI' # Symbol of CAC40\n",
    "#company = 'BTC-USD'\n",
    "\n",
    "start = dt.datetime(1990,3,1)\n",
    "#start = dt.datetime(2014, 9, 17)\n",
    "today = dt.datetime.now()\n",
    "\n",
    "df = yf.download(company, start = start, end=today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8d069e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-03-01</th>\n",
       "      <td>1836.0</td>\n",
       "      <td>1838.0</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>1832.0</td>\n",
       "      <td>1832.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-03-02</th>\n",
       "      <td>1831.0</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>1831.0</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-03-05</th>\n",
       "      <td>1866.0</td>\n",
       "      <td>1874.0</td>\n",
       "      <td>1862.0</td>\n",
       "      <td>1874.0</td>\n",
       "      <td>1874.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-03-06</th>\n",
       "      <td>1869.0</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>1866.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-03-07</th>\n",
       "      <td>1874.0</td>\n",
       "      <td>1881.0</td>\n",
       "      <td>1874.0</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low   Close  Adj Close  Volume\n",
       "Date                                                         \n",
       "1990-03-01  1836.0  1838.0  1827.0  1832.0     1832.0       0\n",
       "1990-03-02  1831.0  1860.0  1831.0  1860.0     1860.0       0\n",
       "1990-03-05  1866.0  1874.0  1862.0  1874.0     1874.0       0\n",
       "1990-03-06  1869.0  1875.0  1866.0  1872.0     1872.0       0\n",
       "1990-03-07  1874.0  1881.0  1874.0  1880.0     1880.0       0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7910e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_train = df[\"Close\"][\"2000-01-03\":\"2018-12-31\"] / 1e6\n",
    "#close_train = df[\"Close\"][\"2014-09-17\":\"2018-12-31\"] / 1e6\n",
    "close_valid = df[\"Close\"][\"2019-01-01\":\"2021-05-31\"] / 1e6\n",
    "close_test = df[\"Close\"][\"2021-06-01\":] / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "13a03451",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 50\n",
    "#seq_length = 56\n",
    "tf.random.set_seed(42)  # extra code â€“ ensures reproducibility\n",
    "train_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    close_train.to_numpy(),\n",
    "    targets=close_train[seq_length:],\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "valid_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    close_valid.to_numpy(),\n",
    "    targets=close_valid[seq_length:],\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ee4cd3",
   "metadata": {},
   "source": [
    "# Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0257f316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 6.4042e-07 - mae: 9.6599e-04 - val_loss: 1.3648e-07 - val_mae: 4.3132e-04\n",
      "Epoch 2/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 2.0898e-07 - mae: 5.2156e-04 - val_loss: 1.2610e-07 - val_mae: 4.0386e-04\n",
      "Epoch 3/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 1.3125e-07 - mae: 4.1025e-04 - val_loss: 3.5778e-07 - val_mae: 7.8830e-04\n",
      "Epoch 4/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 1.1180e-07 - mae: 3.7887e-04 - val_loss: 2.6035e-07 - val_mae: 6.6191e-04\n",
      "Epoch 5/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 1.0859e-07 - mae: 3.7199e-04 - val_loss: 2.4169e-07 - val_mae: 6.3427e-04\n",
      "Epoch 6/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 1.0662e-07 - mae: 3.6881e-04 - val_loss: 2.4381e-07 - val_mae: 6.3757e-04\n",
      "Epoch 7/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 1.0579e-07 - mae: 3.6758e-04 - val_loss: 2.4488e-07 - val_mae: 6.3929e-04\n",
      "Epoch 8/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 1.0584e-07 - mae: 3.6709e-04 - val_loss: 2.3413e-07 - val_mae: 6.2280e-04\n",
      "Epoch 9/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 1.0472e-07 - mae: 3.6558e-04 - val_loss: 2.6403e-07 - val_mae: 6.6759e-04\n",
      "Epoch 10/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 1.0449e-07 - mae: 3.6489e-04 - val_loss: 2.5089e-07 - val_mae: 6.4854e-04\n",
      "Epoch 11/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 1.0395e-07 - mae: 3.6396e-04 - val_loss: 2.4406e-07 - val_mae: 6.3837e-04\n",
      "Epoch 12/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 1.0375e-07 - mae: 3.6337e-04 - val_loss: 2.3339e-07 - val_mae: 6.2199e-04\n",
      "Epoch 13/1000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 1.0320e-07 - mae: 3.6295e-04 - val_loss: 2.7139e-07 - val_mae: 6.7838e-04\n",
      "Epoch 14/1000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 1.0394e-07 - mae: 3.6396e-04 - val_loss: 2.3447e-07 - val_mae: 6.2386e-04\n",
      "Epoch 15/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 1.0345e-07 - mae: 3.6220e-04 - val_loss: 2.2149e-07 - val_mae: 6.0323e-04\n",
      "Epoch 16/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 1.0188e-07 - mae: 3.6012e-04 - val_loss: 2.4425e-07 - val_mae: 6.3906e-04\n",
      "Epoch 17/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 1.0188e-07 - mae: 3.5959e-04 - val_loss: 2.3290e-07 - val_mae: 6.2165e-04\n",
      "Epoch 18/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 1.0181e-07 - mae: 3.5936e-04 - val_loss: 2.1844e-07 - val_mae: 5.9850e-04\n",
      "Epoch 19/1000\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 1.0047e-07 - mae: 3.5750e-04 - val_loss: 2.5300e-07 - val_mae: 6.5234e-04\n",
      "Epoch 20/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 1.0073e-07 - mae: 3.5769e-04 - val_loss: 2.3767e-07 - val_mae: 6.2930e-04\n",
      "Epoch 21/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 1.0042e-07 - mae: 3.5690e-04 - val_loss: 2.2638e-07 - val_mae: 6.1169e-04\n",
      "Epoch 22/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.9628e-08 - mae: 3.5513e-04 - val_loss: 2.3189e-07 - val_mae: 6.2048e-04\n",
      "Epoch 23/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.8813e-08 - mae: 3.5447e-04 - val_loss: 2.5740e-07 - val_mae: 6.5909e-04\n",
      "Epoch 24/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.9531e-08 - mae: 3.5533e-04 - val_loss: 2.2663e-07 - val_mae: 6.1234e-04\n",
      "Epoch 25/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.8549e-08 - mae: 3.5321e-04 - val_loss: 2.2467e-07 - val_mae: 6.0928e-04\n",
      "Epoch 26/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.7644e-08 - mae: 3.5183e-04 - val_loss: 2.4273e-07 - val_mae: 6.3750e-04\n",
      "Epoch 27/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.8198e-08 - mae: 3.5239e-04 - val_loss: 2.1187e-07 - val_mae: 5.8832e-04\n",
      "Epoch 28/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.6912e-08 - mae: 3.5044e-04 - val_loss: 2.3297e-07 - val_mae: 6.2264e-04\n",
      "Epoch 29/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.6489e-08 - mae: 3.4974e-04 - val_loss: 2.4514e-07 - val_mae: 6.4135e-04\n",
      "Epoch 30/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.6296e-08 - mae: 3.4907e-04 - val_loss: 2.2075e-07 - val_mae: 6.0336e-04\n",
      "Epoch 31/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.6070e-08 - mae: 3.4842e-04 - val_loss: 2.1790e-07 - val_mae: 5.9876e-04\n",
      "Epoch 32/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.5560e-08 - mae: 3.4754e-04 - val_loss: 2.2923e-07 - val_mae: 6.1709e-04\n",
      "Epoch 33/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.5371e-08 - mae: 3.4708e-04 - val_loss: 2.2140e-07 - val_mae: 6.0466e-04\n",
      "Epoch 34/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.4991e-08 - mae: 3.4635e-04 - val_loss: 2.2075e-07 - val_mae: 6.0368e-04\n",
      "Epoch 35/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.4886e-08 - mae: 3.4600e-04 - val_loss: 2.2431e-07 - val_mae: 6.0952e-04\n",
      "Epoch 36/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.3972e-08 - mae: 3.4434e-04 - val_loss: 2.2097e-07 - val_mae: 6.0420e-04\n",
      "Epoch 37/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.3733e-08 - mae: 3.4373e-04 - val_loss: 2.1882e-07 - val_mae: 6.0078e-04\n",
      "Epoch 38/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.3085e-08 - mae: 3.4261e-04 - val_loss: 2.3160e-07 - val_mae: 6.2124e-04\n",
      "Epoch 39/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.3722e-08 - mae: 3.4379e-04 - val_loss: 2.2123e-07 - val_mae: 6.0486e-04\n",
      "Epoch 40/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.3327e-08 - mae: 3.4240e-04 - val_loss: 2.0882e-07 - val_mae: 5.8424e-04\n",
      "Epoch 41/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.2685e-08 - mae: 3.4128e-04 - val_loss: 2.0693e-07 - val_mae: 5.8106e-04\n",
      "Epoch 42/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.1558e-08 - mae: 3.3947e-04 - val_loss: 2.3152e-07 - val_mae: 6.2141e-04\n",
      "Epoch 43/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.2033e-08 - mae: 3.4100e-04 - val_loss: 2.1874e-07 - val_mae: 6.0110e-04\n",
      "Epoch 44/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.2074e-08 - mae: 3.3994e-04 - val_loss: 2.0718e-07 - val_mae: 5.8176e-04\n",
      "Epoch 45/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.0622e-08 - mae: 3.3737e-04 - val_loss: 2.1439e-07 - val_mae: 5.9407e-04\n",
      "Epoch 46/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.0145e-08 - mae: 3.3696e-04 - val_loss: 2.3031e-07 - val_mae: 6.1978e-04\n",
      "Epoch 47/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 9.0601e-08 - mae: 3.3723e-04 - val_loss: 2.1759e-07 - val_mae: 5.9951e-04\n",
      "Epoch 48/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 8.9798e-08 - mae: 3.3561e-04 - val_loss: 2.1092e-07 - val_mae: 5.8847e-04\n",
      "Epoch 49/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 8.9820e-08 - mae: 3.3530e-04 - val_loss: 2.0185e-07 - val_mae: 5.7290e-04\n",
      "Epoch 50/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 8.8775e-08 - mae: 3.3348e-04 - val_loss: 2.1492e-07 - val_mae: 5.9532e-04\n",
      "Epoch 51/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 8.8326e-08 - mae: 3.3294e-04 - val_loss: 2.1768e-07 - val_mae: 5.9994e-04\n",
      "Epoch 52/1000\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 8.8266e-08 - mae: 3.3252e-04 - val_loss: 2.1423e-07 - val_mae: 5.9430e-04\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape=[seq_length])\n",
    "])\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_mae\", patience=50, restore_best_weights=True)\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.99)\n",
    "model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])\n",
    "history = model.fit(train_ds, validation_data=valid_ds, epochs=1000,\n",
    "                    callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "eeb2c6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step - loss: 1.2610e-07 - mae: 4.0386e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "403.85668398812413"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code â€“ evaluates the model\n",
    "valid_loss, valid_mae = model.evaluate(valid_ds)\n",
    "valid_mae * 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71227e51",
   "metadata": {},
   "source": [
    "# Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5ffa88ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(1, input_shape=[None, 1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "51485948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_evaluate(model, train_set, valid_set, learning_rate, epochs=1000):\n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_mae\", patience=50, restore_best_weights=True)\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.99)\n",
    "    model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\",\"mse\"])\n",
    "    history = model.fit(train_set, validation_data=valid_set, epochs=epochs,\n",
    "                        callbacks=[early_stopping_cb])\n",
    "    valid_loss, valid_mae,valid_mse = model.evaluate(valid_set)\n",
    "    return valid_mae * 1e6, valid_mse *1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1e115b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.4919 - mae: 0.9898 - mse: 0.9838 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 2/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 3/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 4/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 5/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 6/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 7/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 8/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 9/1000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 10/1000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 11/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 12/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 13/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 14/1000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 15/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 16/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 17/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 18/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 19/1000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 20/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 21/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 22/1000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 23/1000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 24/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 25/1000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 26/1000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 27/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 28/1000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 29/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 30/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 31/1000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 32/1000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 33/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 34/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 35/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 36/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 37/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 38/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 39/1000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 40/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 41/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 42/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 43/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 44/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 45/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 46/1000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 47/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 48/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 49/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 50/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "Epoch 51/1000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4956 - mae: 0.9956 - mse: 0.9913 - val_loss: 0.4946 - val_mae: 0.9946 - val_mse: 0.9892\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4946 - mae: 0.9946 - mse: 0.9892\n"
     ]
    }
   ],
   "source": [
    "# BEST LEARNING RATE  = 150 * 0.001 + 0.002\n",
    "\n",
    "#min_learning_rate = 0.002\n",
    "#max_learning_rate = 0.2\n",
    "#step = 0.001\n",
    "\n",
    "#Mae = []\n",
    "\n",
    "#for learning_rate in np.arange(min_learning_rate, max_learning_rate + step, step):\n",
    "#    mae = fit_and_evaluate(model, train_ds, valid_ds, learning_rate=learning_rate)\n",
    "#    Mae.append(mae)\n",
    "    \n",
    "\n",
    "#for mae in Mae :\n",
    "#    print(mae)\n",
    "\n",
    "#plt.plot(Mae)\n",
    "#plt.show()\n",
    "    \n",
    "mae_rnn, mse_rnn = fit_and_evaluate(model, train_ds, valid_ds, learning_rate=0.152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2f1a1c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code â€“ ensures reproducibility\n",
    "univar_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, input_shape=[None, 1]),\n",
    "    tf.keras.layers.Dense(1)  # no activation function by default\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "24f20cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "151/151 [==============================] - 2s 6ms/step - loss: 6.6095 - mae: 6.9090 - mse: 120.3827 - val_loss: 28.1834 - val_mae: 28.6834 - val_mse: 822.7390\n",
      "Epoch 2/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 15.8957 - mae: 16.3865 - mse: 399.2704 - val_loss: 43.3148 - val_mae: 43.8148 - val_mse: 1919.7407\n",
      "Epoch 3/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 13.2887 - mae: 13.7781 - mse: 344.3161 - val_loss: 6.9891 - val_mae: 7.4891 - val_mse: 56.0867\n",
      "Epoch 4/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 12.9470 - mae: 13.4376 - mse: 241.8472 - val_loss: 12.6275 - val_mae: 13.1275 - val_mse: 172.3303\n",
      "Epoch 5/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 23.4828 - mae: 23.9791 - mse: 850.0773 - val_loss: 1.8816 - val_mae: 2.3816 - val_mse: 5.6720\n",
      "Epoch 6/2000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 9.7405 - mae: 10.2290 - mse: 152.3460 - val_loss: 5.7678 - val_mae: 6.2678 - val_mse: 39.2847\n",
      "Epoch 7/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 25.6481 - mae: 26.1428 - mse: 947.8770 - val_loss: 67.7281 - val_mae: 68.2281 - val_mse: 4655.0679\n",
      "Epoch 8/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 42.4955 - mae: 42.9923 - mse: 2574.6702 - val_loss: 29.4056 - val_mae: 29.9056 - val_mse: 894.3464\n",
      "Epoch 9/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.1443 - mae: 27.6443 - mse: 918.0168 - val_loss: 29.3342 - val_mae: 29.8342 - val_mse: 890.0802\n",
      "Epoch 10/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.5787 - mae: 28.0787 - mse: 933.4131 - val_loss: 7.3627 - val_mae: 7.8627 - val_mse: 61.8216\n",
      "Epoch 11/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.2241 - mae: 27.7241 - mse: 911.1662 - val_loss: 5.3409 - val_mae: 5.8409 - val_mse: 34.1161\n",
      "Epoch 12/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.2741 - mae: 27.7741 - mse: 917.9861 - val_loss: 26.9553 - val_mae: 27.4553 - val_mse: 753.7925\n",
      "Epoch 13/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.0421 - mae: 27.5421 - mse: 901.6311 - val_loss: 31.0378 - val_mae: 31.5378 - val_mse: 994.6302\n",
      "Epoch 14/2000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 27.0481 - mae: 27.5481 - mse: 902.5057 - val_loss: 42.7451 - val_mae: 43.2451 - val_mse: 1870.1417\n",
      "Epoch 15/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.1137 - mae: 27.6137 - mse: 907.0600 - val_loss: 36.8626 - val_mae: 37.3626 - val_mse: 1395.9642\n",
      "Epoch 16/2000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 27.0827 - mae: 27.5827 - mse: 904.6333 - val_loss: 38.4899 - val_mae: 38.9899 - val_mse: 1520.2152\n",
      "Epoch 17/2000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 27.4480 - mae: 27.9480 - mse: 925.5168 - val_loss: 22.4366 - val_mae: 22.9366 - val_mse: 526.0873\n",
      "Epoch 18/2000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 27.3096 - mae: 27.8096 - mse: 913.3242 - val_loss: 13.7794 - val_mae: 14.2794 - val_mse: 203.9008\n",
      "Epoch 19/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.4820 - mae: 27.9820 - mse: 926.8250 - val_loss: 11.6514 - val_mae: 12.1514 - val_mse: 147.6569\n",
      "Epoch 20/2000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 27.1034 - mae: 27.6034 - mse: 905.5082 - val_loss: 20.6685 - val_mae: 21.1685 - val_mse: 448.1068\n",
      "Epoch 21/2000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 27.1285 - mae: 27.6285 - mse: 908.4910 - val_loss: 37.3186 - val_mae: 37.8186 - val_mse: 1430.2437\n",
      "Epoch 22/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.0455 - mae: 27.5455 - mse: 901.8019 - val_loss: 36.4671 - val_mae: 36.9671 - val_mse: 1366.5668\n",
      "Epoch 23/2000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 27.0327 - mae: 27.5327 - mse: 901.2470 - val_loss: 43.1379 - val_mae: 43.6379 - val_mse: 1904.2656\n",
      "Epoch 24/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.2474 - mae: 27.7474 - mse: 915.9274 - val_loss: 32.2174 - val_mae: 32.7174 - val_mse: 1070.4266\n",
      "Epoch 25/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.1998 - mae: 27.6998 - mse: 910.0834 - val_loss: 28.7064 - val_mae: 29.2064 - val_mse: 853.0149\n",
      "Epoch 26/2000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 27.5629 - mae: 28.0629 - mse: 930.1459 - val_loss: 7.5123 - val_mae: 8.0123 - val_mse: 64.1967\n",
      "Epoch 27/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.2287 - mae: 27.7287 - mse: 910.8920 - val_loss: 5.3870 - val_mae: 5.8870 - val_mse: 34.6573\n",
      "Epoch 28/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.2730 - mae: 27.7730 - mse: 917.7018 - val_loss: 26.9302 - val_mae: 27.4302 - val_mse: 752.4140\n",
      "Epoch 29/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.0424 - mae: 27.5424 - mse: 901.5148 - val_loss: 31.0597 - val_mae: 31.5597 - val_mse: 996.0121\n",
      "Epoch 30/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.0481 - mae: 27.5480 - mse: 902.3666 - val_loss: 42.7233 - val_mae: 43.2233 - val_mse: 1868.2509\n",
      "Epoch 31/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.1135 - mae: 27.6135 - mse: 906.9047 - val_loss: 36.8845 - val_mae: 37.3845 - val_mse: 1397.5974\n",
      "Epoch 32/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.0833 - mae: 27.5833 - mse: 904.5364 - val_loss: 38.4681 - val_mae: 38.9681 - val_mse: 1518.5123\n",
      "Epoch 33/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.4471 - mae: 27.9471 - mse: 925.3259 - val_loss: 22.4584 - val_mae: 22.9584 - val_mse: 527.0901\n",
      "Epoch 34/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.3105 - mae: 27.8105 - mse: 913.2469 - val_loss: 13.7575 - val_mae: 14.2575 - val_mse: 203.2771\n",
      "Epoch 35/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.4811 - mae: 27.9811 - mse: 926.6323 - val_loss: 11.6296 - val_mae: 12.1296 - val_mse: 147.1263\n",
      "Epoch 36/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.1040 - mae: 27.6040 - mse: 905.4146 - val_loss: 20.6904 - val_mae: 21.1904 - val_mse: 449.0325\n",
      "Epoch 37/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.1282 - mae: 27.6282 - mse: 908.3316 - val_loss: 37.2967 - val_mae: 37.7967 - val_mse: 1428.5916\n",
      "Epoch 38/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.0454 - mae: 27.5454 - mse: 901.6660 - val_loss: 36.4890 - val_mae: 36.9890 - val_mse: 1368.1827\n",
      "Epoch 39/2000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 27.0330 - mae: 27.5330 - mse: 901.1307 - val_loss: 43.1160 - val_mae: 43.6160 - val_mse: 1902.3589\n",
      "Epoch 40/2000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 27.2468 - mae: 27.7468 - mse: 915.7513 - val_loss: 32.2392 - val_mae: 32.7392 - val_mse: 1071.8571\n",
      "Epoch 41/2000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 27.2006 - mae: 27.7006 - mse: 910.0015 - val_loss: 28.6846 - val_mae: 29.1846 - val_mse: 851.7388\n",
      "Epoch 42/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.5621 - mae: 28.0621 - mse: 929.9532 - val_loss: 7.5341 - val_mae: 8.0341 - val_mse: 64.5474\n",
      "Epoch 43/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.2296 - mae: 27.7296 - mse: 910.8125 - val_loss: 5.4089 - val_mae: 5.9089 - val_mse: 34.9152\n",
      "Epoch 44/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.2724 - mae: 27.7724 - mse: 917.5224 - val_loss: 26.9083 - val_mae: 27.4083 - val_mse: 751.2153\n",
      "Epoch 45/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.0427 - mae: 27.5427 - mse: 901.4019 - val_loss: 31.0815 - val_mae: 31.5815 - val_mse: 997.3919\n",
      "Epoch 46/2000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 27.0480 - mae: 27.5480 - mse: 902.2286 - val_loss: 42.7014 - val_mae: 43.2014 - val_mse: 1866.3624\n",
      "Epoch 47/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.1132 - mae: 27.6132 - mse: 906.7487 - val_loss: 36.9063 - val_mae: 37.4063 - val_mse: 1399.2316\n",
      "Epoch 48/2000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 27.0839 - mae: 27.5839 - mse: 904.4388 - val_loss: 38.4462 - val_mae: 38.9462 - val_mse: 1516.8094\n",
      "Epoch 49/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.4463 - mae: 27.9463 - mse: 925.1375 - val_loss: 22.4803 - val_mae: 22.9803 - val_mse: 528.0941\n",
      "Epoch 50/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.3114 - mae: 27.8114 - mse: 913.1708 - val_loss: 13.7357 - val_mae: 14.2357 - val_mse: 202.6543\n",
      "Epoch 51/2000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 27.4802 - mae: 27.9802 - mse: 926.4406 - val_loss: 11.6077 - val_mae: 12.1077 - val_mse: 146.5965\n",
      "Epoch 52/2000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 27.1046 - mae: 27.6046 - mse: 905.3231 - val_loss: 20.7122 - val_mae: 21.2122 - val_mse: 449.9591\n",
      "Epoch 53/2000\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 27.1279 - mae: 27.6279 - mse: 908.1695 - val_loss: 37.2749 - val_mae: 37.7749 - val_mse: 1426.9403\n",
      "Epoch 54/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.0455 - mae: 27.5455 - mse: 901.5345 - val_loss: 36.5108 - val_mae: 37.0108 - val_mse: 1369.7997\n",
      "Epoch 55/2000\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 27.0333 - mae: 27.5333 - mse: 901.0161 - val_loss: 43.0942 - val_mae: 43.5942 - val_mse: 1900.4536\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8816 - mae: 2.3816 - mse: 5.6720\n"
     ]
    }
   ],
   "source": [
    "# CHECK LEARNING RATE AFTER 150 * 0.001 + 0.002\n",
    "\n",
    "#min_learning_rate = 0.002\n",
    "#max_learning_rate = 0.2\n",
    "#step = 0.001\n",
    "\n",
    "#Mae = []\n",
    "\n",
    "#for learning_rate in np.arange(min_learning_rate, max_learning_rate + step, step):\n",
    "#    mae = fit_and_evaluate(univar_model, train_ds, valid_ds, learning_rate=learning_rate)\n",
    "#    Mae.append(mae)\n",
    "    \n",
    "\n",
    "#for mae in Mae :\n",
    "#    print(mae)\n",
    "\n",
    "#plt.plot(Mae)\n",
    "#plt.show()\n",
    "\n",
    "# extra code â€“ compiles, fits, and evaluates the model, like earlier\n",
    "mae_univar, mse_univar = fit_and_evaluate(univar_model, train_ds, valid_ds, learning_rate=0.152, epochs=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a75506",
   "metadata": {},
   "source": [
    "# Deep RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c88bb679",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code â€“ ensures reproducibility\n",
    "deep_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None, 1]),\n",
    "    tf.keras.layers.SimpleRNN(32, return_sequences=True),\n",
    "    tf.keras.layers.SimpleRNN(32),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4502e5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "151/151 [==============================] - 4s 15ms/step - loss: 0.0123 - mae: 0.1225 - mse: 0.0247 - val_loss: 0.0052 - val_mae: 0.1015 - val_mse: 0.0103\n",
      "Epoch 2/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 0.0014 - mae: 0.0461 - mse: 0.0028 - val_loss: 0.0012 - val_mae: 0.0485 - val_mse: 0.0024\n",
      "Epoch 3/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 2.9831e-04 - mae: 0.0215 - mse: 5.9662e-04 - val_loss: 2.3107e-04 - val_mae: 0.0215 - val_mse: 4.6214e-04\n",
      "Epoch 4/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 6.6708e-05 - mae: 0.0101 - mse: 1.3342e-04 - val_loss: 6.4877e-05 - val_mae: 0.0114 - val_mse: 1.2975e-04\n",
      "Epoch 5/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 1.5280e-05 - mae: 0.0048 - mse: 3.0560e-05 - val_loss: 7.7298e-06 - val_mae: 0.0039 - val_mse: 1.5460e-05\n",
      "Epoch 6/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 3.9203e-06 - mae: 0.0024 - mse: 7.8407e-06 - val_loss: 4.2814e-06 - val_mae: 0.0029 - val_mse: 8.5628e-06\n",
      "Epoch 7/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 1.1685e-06 - mae: 0.0013 - mse: 2.3370e-06 - val_loss: 3.3436e-07 - val_mae: 7.0781e-04 - val_mse: 6.6872e-07\n",
      "Epoch 8/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 5.8875e-07 - mae: 8.9043e-04 - mse: 1.1775e-06 - val_loss: 8.4484e-07 - val_mae: 0.0012 - val_mse: 1.6897e-06\n",
      "Epoch 9/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 5.9562e-07 - mae: 8.8569e-04 - mse: 1.1912e-06 - val_loss: 8.7445e-07 - val_mae: 0.0012 - val_mse: 1.7489e-06\n",
      "Epoch 10/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 5.8761e-07 - mae: 8.8345e-04 - mse: 1.1752e-06 - val_loss: 5.8485e-07 - val_mae: 9.6815e-04 - val_mse: 1.1697e-06\n",
      "Epoch 11/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.6066e-07 - mae: 7.8716e-04 - mse: 9.2132e-07 - val_loss: 8.9192e-07 - val_mae: 0.0012 - val_mse: 1.7838e-06\n",
      "Epoch 12/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.2001e-07 - mae: 7.5689e-04 - mse: 8.4002e-07 - val_loss: 8.3353e-07 - val_mae: 0.0012 - val_mse: 1.6671e-06\n",
      "Epoch 13/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.2462e-07 - mae: 7.6498e-04 - mse: 8.4925e-07 - val_loss: 4.7679e-07 - val_mae: 8.6428e-04 - val_mse: 9.5358e-07\n",
      "Epoch 14/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.2118e-07 - mae: 7.5965e-04 - mse: 8.4236e-07 - val_loss: 6.9576e-07 - val_mae: 0.0011 - val_mse: 1.3915e-06\n",
      "Epoch 15/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.4052e-07 - mae: 7.7736e-04 - mse: 8.8104e-07 - val_loss: 5.2126e-07 - val_mae: 9.0779e-04 - val_mse: 1.0425e-06\n",
      "Epoch 16/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.5489e-07 - mae: 7.8357e-04 - mse: 9.0979e-07 - val_loss: 3.2391e-07 - val_mae: 6.9495e-04 - val_mse: 6.4783e-07\n",
      "Epoch 17/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 5.0252e-07 - mae: 8.2867e-04 - mse: 1.0050e-06 - val_loss: 1.1734e-06 - val_mae: 0.0014 - val_mse: 2.3468e-06\n",
      "Epoch 18/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 5.3914e-07 - mae: 8.4093e-04 - mse: 1.0783e-06 - val_loss: 1.9149e-07 - val_mae: 5.2723e-04 - val_mse: 3.8297e-07\n",
      "Epoch 19/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 5.6739e-07 - mae: 8.7108e-04 - mse: 1.1348e-06 - val_loss: 1.4187e-06 - val_mae: 0.0016 - val_mse: 2.8374e-06\n",
      "Epoch 20/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.4817e-07 - mae: 7.7781e-04 - mse: 8.9633e-07 - val_loss: 8.3348e-07 - val_mae: 0.0012 - val_mse: 1.6670e-06\n",
      "Epoch 21/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.3278e-07 - mae: 7.6974e-04 - mse: 8.6557e-07 - val_loss: 5.3505e-07 - val_mae: 9.2103e-04 - val_mse: 1.0701e-06\n",
      "Epoch 22/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.2980e-07 - mae: 7.6761e-04 - mse: 8.5959e-07 - val_loss: 5.9231e-07 - val_mae: 9.7510e-04 - val_mse: 1.1846e-06\n",
      "Epoch 23/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.1246e-07 - mae: 7.5236e-04 - mse: 8.2491e-07 - val_loss: 4.5208e-07 - val_mae: 8.3935e-04 - val_mse: 9.0416e-07\n",
      "Epoch 24/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.4642e-07 - mae: 7.8143e-04 - mse: 8.9285e-07 - val_loss: 7.5008e-07 - val_mae: 0.0011 - val_mse: 1.5002e-06\n",
      "Epoch 25/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.1490e-07 - mae: 7.5266e-04 - mse: 8.2981e-07 - val_loss: 6.1853e-07 - val_mae: 9.9940e-04 - val_mse: 1.2371e-06\n",
      "Epoch 26/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.1344e-07 - mae: 7.5280e-04 - mse: 8.2689e-07 - val_loss: 4.3049e-07 - val_mae: 8.1691e-04 - val_mse: 8.6097e-07\n",
      "Epoch 27/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.0942e-07 - mae: 7.4878e-04 - mse: 8.1884e-07 - val_loss: 3.6628e-07 - val_mae: 7.4587e-04 - val_mse: 7.3256e-07\n",
      "Epoch 28/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.7176e-07 - mae: 8.0446e-04 - mse: 9.4352e-07 - val_loss: 8.8701e-07 - val_mae: 0.0012 - val_mse: 1.7740e-06\n",
      "Epoch 29/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.2365e-07 - mae: 7.6252e-04 - mse: 8.4730e-07 - val_loss: 7.5217e-07 - val_mae: 0.0011 - val_mse: 1.5043e-06\n",
      "Epoch 30/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.4508e-07 - mae: 7.7602e-04 - mse: 8.9015e-07 - val_loss: 1.1914e-06 - val_mae: 0.0015 - val_mse: 2.3828e-06\n",
      "Epoch 31/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.5268e-07 - mae: 7.8341e-04 - mse: 9.0536e-07 - val_loss: 3.0783e-07 - val_mae: 6.7494e-04 - val_mse: 6.1566e-07\n",
      "Epoch 32/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.4324e-07 - mae: 7.7372e-04 - mse: 8.8648e-07 - val_loss: 5.3326e-07 - val_mae: 9.1931e-04 - val_mse: 1.0665e-06\n",
      "Epoch 33/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.5061e-07 - mae: 7.8334e-04 - mse: 9.0123e-07 - val_loss: 1.2518e-06 - val_mae: 0.0015 - val_mse: 2.5035e-06\n",
      "Epoch 34/1000\n",
      "151/151 [==============================] - 2s 14ms/step - loss: 4.8569e-07 - mae: 8.0877e-04 - mse: 9.7138e-07 - val_loss: 3.0526e-07 - val_mae: 6.7171e-04 - val_mse: 6.1051e-07\n",
      "Epoch 35/1000\n",
      "151/151 [==============================] - 2s 15ms/step - loss: 4.5632e-07 - mae: 7.8908e-04 - mse: 9.1265e-07 - val_loss: 1.0077e-06 - val_mae: 0.0013 - val_mse: 2.0155e-06\n",
      "Epoch 36/1000\n",
      "151/151 [==============================] - 2s 15ms/step - loss: 4.3212e-07 - mae: 7.7256e-04 - mse: 8.6424e-07 - val_loss: 4.8009e-07 - val_mae: 8.6756e-04 - val_mse: 9.6018e-07\n",
      "Epoch 37/1000\n",
      "151/151 [==============================] - 2s 14ms/step - loss: 4.2697e-07 - mae: 7.6377e-04 - mse: 8.5394e-07 - val_loss: 6.5531e-07 - val_mae: 0.0010 - val_mse: 1.3106e-06\n",
      "Epoch 38/1000\n",
      "151/151 [==============================] - 2s 14ms/step - loss: 4.1400e-07 - mae: 7.5382e-04 - mse: 8.2800e-07 - val_loss: 8.8543e-07 - val_mae: 0.0012 - val_mse: 1.7709e-06\n",
      "Epoch 39/1000\n",
      "151/151 [==============================] - 2s 14ms/step - loss: 4.1577e-07 - mae: 7.5573e-04 - mse: 8.3153e-07 - val_loss: 4.9797e-07 - val_mae: 8.8516e-04 - val_mse: 9.9593e-07\n",
      "Epoch 40/1000\n",
      "151/151 [==============================] - 2s 14ms/step - loss: 4.0804e-07 - mae: 7.4862e-04 - mse: 8.1609e-07 - val_loss: 9.4593e-07 - val_mae: 0.0013 - val_mse: 1.8919e-06\n",
      "Epoch 41/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.4711e-07 - mae: 7.7982e-04 - mse: 8.9423e-07 - val_loss: 2.9944e-07 - val_mae: 6.6438e-04 - val_mse: 5.9888e-07\n",
      "Epoch 42/1000\n",
      "151/151 [==============================] - 2s 14ms/step - loss: 4.4565e-07 - mae: 7.8286e-04 - mse: 8.9129e-07 - val_loss: 1.0686e-06 - val_mae: 0.0014 - val_mse: 2.1372e-06\n",
      "Epoch 43/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.3581e-07 - mae: 7.6933e-04 - mse: 8.7163e-07 - val_loss: 6.2244e-07 - val_mae: 0.0010 - val_mse: 1.2449e-06\n",
      "Epoch 44/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.7047e-07 - mae: 8.0212e-04 - mse: 9.4094e-07 - val_loss: 1.0857e-06 - val_mae: 0.0014 - val_mse: 2.1715e-06\n",
      "Epoch 45/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 5.3596e-07 - mae: 8.4406e-04 - mse: 1.0719e-06 - val_loss: 5.9481e-07 - val_mae: 9.7743e-04 - val_mse: 1.1896e-06\n",
      "Epoch 46/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.7273e-07 - mae: 8.0221e-04 - mse: 9.4545e-07 - val_loss: 5.5433e-07 - val_mae: 9.3931e-04 - val_mse: 1.1087e-06\n",
      "Epoch 47/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 5.0248e-07 - mae: 8.1770e-04 - mse: 1.0050e-06 - val_loss: 8.3529e-07 - val_mae: 0.0012 - val_mse: 1.6706e-06\n",
      "Epoch 48/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.2757e-07 - mae: 7.6663e-04 - mse: 8.5513e-07 - val_loss: 6.2880e-07 - val_mae: 0.0010 - val_mse: 1.2576e-06\n",
      "Epoch 49/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.1088e-07 - mae: 7.5103e-04 - mse: 8.2176e-07 - val_loss: 6.7374e-07 - val_mae: 0.0010 - val_mse: 1.3475e-06\n",
      "Epoch 50/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.3874e-07 - mae: 7.7618e-04 - mse: 8.7747e-07 - val_loss: 1.0459e-06 - val_mae: 0.0013 - val_mse: 2.0918e-06\n",
      "Epoch 51/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.6907e-07 - mae: 7.9749e-04 - mse: 9.3815e-07 - val_loss: 4.1698e-07 - val_mae: 8.0248e-04 - val_mse: 8.3396e-07\n",
      "Epoch 52/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.4883e-07 - mae: 7.8543e-04 - mse: 8.9766e-07 - val_loss: 6.5919e-07 - val_mae: 0.0010 - val_mse: 1.3184e-06\n",
      "Epoch 53/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.2108e-07 - mae: 7.5997e-04 - mse: 8.4215e-07 - val_loss: 4.1492e-07 - val_mae: 8.0025e-04 - val_mse: 8.2984e-07\n",
      "Epoch 54/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.6425e-07 - mae: 7.9649e-04 - mse: 9.2850e-07 - val_loss: 5.7490e-07 - val_mae: 9.5882e-04 - val_mse: 1.1498e-06\n",
      "Epoch 55/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.9005e-07 - mae: 8.1141e-04 - mse: 9.8010e-07 - val_loss: 5.2686e-07 - val_mae: 9.1319e-04 - val_mse: 1.0537e-06\n",
      "Epoch 56/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.3493e-07 - mae: 7.7021e-04 - mse: 8.6986e-07 - val_loss: 6.4294e-07 - val_mae: 0.0010 - val_mse: 1.2859e-06\n",
      "Epoch 57/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.1739e-07 - mae: 7.5662e-04 - mse: 8.3478e-07 - val_loss: 3.9696e-07 - val_mae: 7.8057e-04 - val_mse: 7.9393e-07\n",
      "Epoch 58/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.2466e-07 - mae: 7.6474e-04 - mse: 8.4933e-07 - val_loss: 5.3204e-07 - val_mae: 9.1815e-04 - val_mse: 1.0641e-06\n",
      "Epoch 59/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.0919e-07 - mae: 7.5166e-04 - mse: 8.1838e-07 - val_loss: 8.9854e-07 - val_mae: 0.0012 - val_mse: 1.7971e-06\n",
      "Epoch 60/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.2603e-07 - mae: 7.6135e-04 - mse: 8.5207e-07 - val_loss: 7.7579e-07 - val_mae: 0.0011 - val_mse: 1.5516e-06\n",
      "Epoch 61/1000\n",
      "151/151 [==============================] - 2s 14ms/step - loss: 4.3404e-07 - mae: 7.6765e-04 - mse: 8.6808e-07 - val_loss: 7.5502e-07 - val_mae: 0.0011 - val_mse: 1.5100e-06\n",
      "Epoch 62/1000\n",
      "151/151 [==============================] - 2s 14ms/step - loss: 4.1188e-07 - mae: 7.5199e-04 - mse: 8.2375e-07 - val_loss: 6.7362e-07 - val_mae: 0.0010 - val_mse: 1.3472e-06\n",
      "Epoch 63/1000\n",
      "151/151 [==============================] - 2s 14ms/step - loss: 4.2593e-07 - mae: 7.6453e-04 - mse: 8.5186e-07 - val_loss: 6.6112e-07 - val_mae: 0.0010 - val_mse: 1.3222e-06\n",
      "Epoch 64/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.2526e-07 - mae: 7.6387e-04 - mse: 8.5053e-07 - val_loss: 3.3300e-07 - val_mae: 7.0615e-04 - val_mse: 6.6601e-07\n",
      "Epoch 65/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.3492e-07 - mae: 7.7110e-04 - mse: 8.6983e-07 - val_loss: 9.4656e-07 - val_mae: 0.0013 - val_mse: 1.8931e-06\n",
      "Epoch 66/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 5.0504e-07 - mae: 8.2196e-04 - mse: 1.0101e-06 - val_loss: 2.5267e-07 - val_mae: 6.0377e-04 - val_mse: 5.0534e-07\n",
      "Epoch 67/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.4740e-07 - mae: 7.8181e-04 - mse: 8.9481e-07 - val_loss: 1.0137e-06 - val_mae: 0.0013 - val_mse: 2.0274e-06\n",
      "Epoch 68/1000\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 4.2265e-07 - mae: 7.6355e-04 - mse: 8.4530e-07 - val_loss: 5.8159e-07 - val_mae: 9.6510e-04 - val_mse: 1.1632e-06\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.9149e-07 - mae: 5.2723e-04 - mse: 3.8297e-07\n"
     ]
    }
   ],
   "source": [
    "# BEST LEARNING_RATE = 25 * 0.001 + 0.002\n",
    "\n",
    "#min_learning_rate = 0.002\n",
    "#max_learning_rate = 0.2\n",
    "#step = 0.001\n",
    "\n",
    "#Mae = []\n",
    "\n",
    "#for learning_rate in np.arange(min_learning_rate, max_learning_rate + step, step):\n",
    "#    mae = fit_and_evaluate(deep_model, train_ds, valid_ds, learning_rate=learning_rate)\n",
    "#    Mae.append(mae)\n",
    "    \n",
    "\n",
    "#for mae in Mae :\n",
    "#    print(mae)\n",
    "\n",
    "#plt.plot(Mae)\n",
    "#plt.show()\n",
    "\n",
    "# extra code â€“ compiles, fits, and evaluates the model, like earlier\n",
    "mae_deep, mse_deep = fit_and_evaluate(deep_model, train_ds, valid_ds, learning_rate=0.0027)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271ba204",
   "metadata": {},
   "source": [
    "# Multivariate time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ec7faa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mulvar = df[[\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"]] / 1e6  # use both bus & rail series as input\n",
    "df_mulvar[\"next_day_close\"] = df[\"Close\"].shift(-1)  # we know tomorrow's type\n",
    "df_mulvar = pd.get_dummies(df_mulvar)  # one-hot encode the day type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9c2a2c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "mulvar_train = df_mulvar[\"1990-03-01\":\"2018-12-31\"]\n",
    "#mulvar_train = df_mulvar[\"2014-09-17\":\"2018-12-31\"]\n",
    "mulvar_valid = df_mulvar[\"2019-01-01\":\"2021-05-31\"]\n",
    "mulvar_test = df_mulvar[\"2021-06-01\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "37feafb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code â€“ ensures reproducibility\n",
    "\n",
    "train_mulvar_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    mulvar_train.to_numpy(),  # use all 5 columns as input\n",
    "    targets=mulvar_train[\"Close\"][seq_length:],  # forecast only the rail series\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "valid_mulvar_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    mulvar_valid.to_numpy(),\n",
    "    targets=mulvar_valid[\"Close\"][seq_length:],\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d9f6e4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code â€“ ensures reproducibility\n",
    "mulvar_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, input_shape=[None, 7]),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5a2934e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "227/227 [==============================] - 2s 5ms/step - loss: 9.5922 - mae: 10.0857 - mse: 158.0541 - val_loss: 13.0077 - val_mae: 13.5077 - val_mse: 182.4574\n",
      "Epoch 2/1000\n",
      "227/227 [==============================] - 1s 5ms/step - loss: 23.0803 - mae: 23.5774 - mse: 770.7057 - val_loss: 18.1152 - val_mae: 18.6152 - val_mse: 346.5242\n",
      "Epoch 3/1000\n",
      "227/227 [==============================] - 1s 5ms/step - loss: 12.2490 - mae: 12.7417 - mse: 225.6082 - val_loss: 6.9458 - val_mae: 7.4458 - val_mse: 55.4395\n",
      "Epoch 4/1000\n",
      "227/227 [==============================] - 1s 5ms/step - loss: 44.0499 - mae: 44.5461 - mse: 2966.0437 - val_loss: 55.5161 - val_mae: 56.0161 - val_mse: 3137.8069\n",
      "Epoch 5/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 20.1626 - mae: 20.6597 - mse: 638.6945 - val_loss: 12.2269 - val_mae: 12.7269 - val_mse: 161.9733\n",
      "Epoch 6/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 8.5609 - mae: 9.0503 - mse: 128.6754 - val_loss: 0.4350 - val_mae: 0.9327 - val_mse: 0.8700\n",
      "Epoch 7/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 8.2836 - mae: 8.7765 - mse: 129.7210 - val_loss: 6.4324 - val_mae: 6.9324 - val_mse: 48.0586\n",
      "Epoch 8/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1127 - mae: 7.6127 - mse: 66.8785 - val_loss: 8.4581 - val_mae: 8.9581 - val_mse: 80.2477\n",
      "Epoch 9/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1100 - mae: 7.6100 - mse: 66.1232 - val_loss: 3.3801 - val_mae: 3.8801 - val_mse: 15.0555\n",
      "Epoch 10/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.0946 - mae: 7.5946 - mse: 65.9745 - val_loss: 11.0377 - val_mae: 11.5377 - val_mse: 133.1187\n",
      "Epoch 11/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1284 - mae: 7.6284 - mse: 66.5029 - val_loss: 3.0075 - val_mae: 3.5075 - val_mse: 12.3025\n",
      "Epoch 12/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.0904 - mae: 7.5904 - mse: 66.0019 - val_loss: 8.3484 - val_mae: 8.8484 - val_mse: 78.2951\n",
      "Epoch 13/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1269 - mae: 7.6269 - mse: 66.4846 - val_loss: 9.2571 - val_mae: 9.7571 - val_mse: 95.2013\n",
      "Epoch 14/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.0971 - mae: 7.5971 - mse: 66.0326 - val_loss: 4.4596 - val_mae: 4.9596 - val_mse: 24.5975\n",
      "Epoch 15/1000\n",
      "227/227 [==============================] - 1s 6ms/step - loss: 7.1100 - mae: 7.6100 - mse: 66.2553 - val_loss: 9.9263 - val_mae: 10.4263 - val_mse: 108.7085\n",
      "Epoch 16/1000\n",
      "227/227 [==============================] - 1s 5ms/step - loss: 7.1325 - mae: 7.6325 - mse: 66.6042 - val_loss: 4.1268 - val_mae: 4.6268 - val_mse: 21.4071\n",
      "Epoch 17/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.0746 - mae: 7.5746 - mse: 65.7200 - val_loss: 9.4748 - val_mae: 9.9748 - val_mse: 99.4966\n",
      "Epoch 18/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1328 - mae: 7.6328 - mse: 66.6122 - val_loss: 8.1241 - val_mae: 8.6241 - val_mse: 74.3759\n",
      "Epoch 19/1000\n",
      "227/227 [==============================] - 1s 5ms/step - loss: 7.1113 - mae: 7.6113 - mse: 66.2927 - val_loss: 3.3204 - val_mae: 3.8204 - val_mse: 14.5957\n",
      "Epoch 20/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.0939 - mae: 7.5939 - mse: 66.0098 - val_loss: 11.0713 - val_mae: 11.5713 - val_mse: 133.8945\n",
      "Epoch 21/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1283 - mae: 7.6283 - mse: 66.5371 - val_loss: 2.9765 - val_mae: 3.4765 - val_mse: 12.0862\n",
      "Epoch 22/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.0908 - mae: 7.5908 - mse: 66.0436 - val_loss: 8.3197 - val_mae: 8.8197 - val_mse: 77.7868\n",
      "Epoch 23/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1268 - mae: 7.6268 - mse: 66.5138 - val_loss: 9.2837 - val_mae: 9.7837 - val_mse: 95.7204\n",
      "Epoch 24/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.0967 - mae: 7.5967 - mse: 66.0560 - val_loss: 4.4839 - val_mae: 4.9839 - val_mse: 24.8395\n",
      "Epoch 25/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1103 - mae: 7.6103 - mse: 66.2879 - val_loss: 9.9042 - val_mae: 10.4042 - val_mse: 108.2481\n",
      "Epoch 26/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1325 - mae: 7.6325 - mse: 66.6300 - val_loss: 4.1467 - val_mae: 4.6467 - val_mse: 21.5915\n",
      "Epoch 27/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.0743 - mae: 7.5743 - mse: 65.7369 - val_loss: 9.4925 - val_mae: 9.9925 - val_mse: 99.8492\n",
      "Epoch 28/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1329 - mae: 7.6329 - mse: 66.6340 - val_loss: 8.1087 - val_mae: 8.6087 - val_mse: 74.1096\n",
      "Epoch 29/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1114 - mae: 7.6114 - mse: 66.3120 - val_loss: 3.3072 - val_mae: 3.8072 - val_mse: 14.4946\n",
      "Epoch 30/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.0937 - mae: 7.5937 - mse: 66.0208 - val_loss: 11.0823 - val_mae: 11.5823 - val_mse: 134.1498\n",
      "Epoch 31/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1283 - mae: 7.6283 - mse: 66.5488 - val_loss: 2.9677 - val_mae: 3.4677 - val_mse: 12.0249\n",
      "Epoch 32/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.0909 - mae: 7.5909 - mse: 66.0552 - val_loss: 8.3126 - val_mae: 8.8126 - val_mse: 77.6623\n",
      "Epoch 33/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1267 - mae: 7.6267 - mse: 66.5195 - val_loss: 9.2890 - val_mae: 9.7890 - val_mse: 95.8239\n",
      "Epoch 34/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.0967 - mae: 7.5967 - mse: 66.0608 - val_loss: 4.4875 - val_mae: 4.9875 - val_mse: 24.8748\n",
      "Epoch 35/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1104 - mae: 7.6104 - mse: 66.2916 - val_loss: 9.9020 - val_mae: 10.4020 - val_mse: 108.2020\n",
      "Epoch 36/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1325 - mae: 7.6325 - mse: 66.6311 - val_loss: 4.1480 - val_mae: 4.6480 - val_mse: 21.6037\n",
      "Epoch 37/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.0743 - mae: 7.5743 - mse: 65.7374 - val_loss: 9.4929 - val_mae: 9.9929 - val_mse: 99.8583\n",
      "Epoch 38/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1329 - mae: 7.6329 - mse: 66.6344 - val_loss: 8.1087 - val_mae: 8.6087 - val_mse: 74.1093\n",
      "Epoch 39/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1114 - mae: 7.6114 - mse: 66.3127 - val_loss: 3.3072 - val_mae: 3.8072 - val_mse: 14.4946\n",
      "Epoch 40/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.0937 - mae: 7.5937 - mse: 66.0210 - val_loss: 11.0823 - val_mae: 11.5823 - val_mse: 134.1499\n",
      "Epoch 41/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1283 - mae: 7.6283 - mse: 66.5485 - val_loss: 2.9677 - val_mae: 3.4677 - val_mse: 12.0249\n",
      "Epoch 42/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.0910 - mae: 7.5910 - mse: 66.0555 - val_loss: 8.3126 - val_mae: 8.8126 - val_mse: 77.6623\n",
      "Epoch 43/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1267 - mae: 7.6267 - mse: 66.5203 - val_loss: 9.2890 - val_mae: 9.7890 - val_mse: 95.8239\n",
      "Epoch 44/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.0967 - mae: 7.5967 - mse: 66.0609 - val_loss: 4.4875 - val_mae: 4.9875 - val_mse: 24.8748\n",
      "Epoch 45/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1103 - mae: 7.6103 - mse: 66.2914 - val_loss: 9.9020 - val_mae: 10.4020 - val_mse: 108.2019\n",
      "Epoch 46/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1325 - mae: 7.6325 - mse: 66.6318 - val_loss: 4.1480 - val_mae: 4.6480 - val_mse: 21.6037\n",
      "Epoch 47/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.0743 - mae: 7.5743 - mse: 65.7377 - val_loss: 9.4929 - val_mae: 9.9929 - val_mse: 99.8583\n",
      "Epoch 48/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1329 - mae: 7.6329 - mse: 66.6342 - val_loss: 8.1087 - val_mae: 8.6087 - val_mse: 74.1093\n",
      "Epoch 49/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1114 - mae: 7.6114 - mse: 66.3123 - val_loss: 3.3072 - val_mae: 3.8072 - val_mse: 14.4946\n",
      "Epoch 50/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.0937 - mae: 7.5937 - mse: 66.0211 - val_loss: 11.0823 - val_mae: 11.5823 - val_mse: 134.1499\n",
      "Epoch 51/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1283 - mae: 7.6282 - mse: 66.5484 - val_loss: 2.9677 - val_mae: 3.4677 - val_mse: 12.0248\n",
      "Epoch 52/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.0909 - mae: 7.5909 - mse: 66.0551 - val_loss: 8.3126 - val_mae: 8.8126 - val_mse: 77.6623\n",
      "Epoch 53/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1267 - mae: 7.6267 - mse: 66.5199 - val_loss: 9.2890 - val_mae: 9.7890 - val_mse: 95.8240\n",
      "Epoch 54/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.0967 - mae: 7.5967 - mse: 66.0608 - val_loss: 4.4875 - val_mae: 4.9875 - val_mse: 24.8748\n",
      "Epoch 55/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1103 - mae: 7.6103 - mse: 66.2913 - val_loss: 9.9020 - val_mae: 10.4020 - val_mse: 108.2019\n",
      "Epoch 56/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 7.1325 - mae: 7.6325 - mse: 66.6319 - val_loss: 4.1480 - val_mae: 4.6480 - val_mse: 21.6037\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - mae: 0.9327 - mse: 0.8700\n"
     ]
    }
   ],
   "source": [
    "# LEARNING_RATE A REFAIRE ENTRE 0 ET 100 * 0.001 + 0.002\n",
    "\n",
    "#min_learning_rate = 0.002\n",
    "#max_learning_rate = 0.2\n",
    "#step = 0.001\n",
    "\n",
    "#Mae = []\n",
    "\n",
    "#for learning_rate in np.arange(min_learning_rate, max_learning_rate + step, step):\n",
    "#    mae = fit_and_evaluate(mulvar_model, train_mulvar_ds, valid_mulvar_ds, learning_rate=learning_rate)\n",
    "#    Mae.append(mae)\n",
    "    \n",
    "\n",
    "#for mae in Mae :\n",
    "#    print(mae)\n",
    "\n",
    "#plt.plot(Mae)\n",
    "#plt.show()\n",
    "\n",
    "# extra code â€“ compiles, fits, and evaluates the model, like earlier\n",
    "mae_mul, mse_mul = fit_and_evaluate(mulvar_model, train_mulvar_ds, valid_mulvar_ds,\n",
    "                 learning_rate=0.102)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa296edb",
   "metadata": {},
   "source": [
    "# Forecasting Several Steps Ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "139fbad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = close_valid.to_numpy()[np.newaxis, :seq_length, np.newaxis]\n",
    "for step_ahead in range(14):\n",
    "    y_pred_one = univar_model.predict(X)\n",
    "    X = np.concatenate([X, y_pred_one.reshape(1, 1, 1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0b9d4409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leamd\\anaconda3\\envs\\tensorflow-gpu\\Lib\\site-packages\\matplotlib\\axis.py:1769: FutureWarning: Period with BDay freq is deprecated and will be removed in a future version. Use a DatetimeIndex with BDay freq instead.\n",
      "  ret = self.converter.convert(x, self.units, self)\n",
      "C:\\Users\\leamd\\anaconda3\\envs\\tensorflow-gpu\\Lib\\site-packages\\matplotlib\\axis.py:1769: FutureWarning: PeriodDtype[B] is deprecated and will be removed in a future version. Use a DatetimeIndex with freq='B' instead\n",
      "  ret = self.converter.convert(x, self.units, self)\n",
      "C:\\Users\\leamd\\anaconda3\\envs\\tensorflow-gpu\\Lib\\site-packages\\matplotlib\\axis.py:1495: FutureWarning: Period with BDay freq is deprecated and will be removed in a future version. Use a DatetimeIndex with BDay freq instead.\n",
      "  return self.major.locator()\n",
      "C:\\Users\\leamd\\anaconda3\\envs\\tensorflow-gpu\\Lib\\site-packages\\matplotlib\\axis.py:1495: FutureWarning: PeriodDtype[B] is deprecated and will be removed in a future version. Use a DatetimeIndex with freq='B' instead\n",
      "  return self.major.locator()\n",
      "C:\\Users\\leamd\\anaconda3\\envs\\tensorflow-gpu\\Lib\\site-packages\\matplotlib\\ticker.py:216: FutureWarning: Period with BDay freq is deprecated and will be removed in a future version. Use a DatetimeIndex with BDay freq instead.\n",
      "  return [self(value, i) for i, value in enumerate(values)]\n",
      "C:\\Users\\leamd\\AppData\\Local\\Temp\\ipykernel_25168\\1846164004.py:7: FutureWarning: PeriodDtype[B] is deprecated and will be removed in a future version. Use a DatetimeIndex with freq='B' instead\n",
      "  (Y_pred * 1e6).plot(\n",
      "C:\\Users\\leamd\\anaconda3\\envs\\tensorflow-gpu\\Lib\\site-packages\\matplotlib\\axis.py:1769: FutureWarning: PeriodDtype[B] is deprecated and will be removed in a future version. Use a DatetimeIndex with freq='B' instead\n",
      "  ret = self.converter.convert(x, self.units, self)\n",
      "C:\\Users\\leamd\\anaconda3\\envs\\tensorflow-gpu\\Lib\\site-packages\\matplotlib\\axis.py:1495: FutureWarning: Period with BDay freq is deprecated and will be removed in a future version. Use a DatetimeIndex with BDay freq instead.\n",
      "  return self.major.locator()\n",
      "C:\\Users\\leamd\\anaconda3\\envs\\tensorflow-gpu\\Lib\\site-packages\\matplotlib\\axis.py:1495: FutureWarning: PeriodDtype[B] is deprecated and will be removed in a future version. Use a DatetimeIndex with freq='B' instead\n",
      "  return self.major.locator()\n",
      "C:\\Users\\leamd\\anaconda3\\envs\\tensorflow-gpu\\Lib\\site-packages\\matplotlib\\ticker.py:216: FutureWarning: Period with BDay freq is deprecated and will be removed in a future version. Use a DatetimeIndex with BDay freq instead.\n",
      "  return [self(value, i) for i, value in enumerate(values)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_pred = pd.Series(X[0, -14:, 0],\n",
    "                   index=pd.date_range(\"2019-02-26\", \"2019-03-11\"))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 3.5))\n",
    "(close_valid * 1e6)[\"2019-02-01\":\"2019-03-11\"].plot(\n",
    "    label=\"True\", marker=\".\", ax=ax)\n",
    "(Y_pred * 1e6).plot(\n",
    "    label=\"Predictions\", grid=True, marker=\"x\", color=\"r\", ax=ax)\n",
    "plt.legend(loc=\"center left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4c7d2394",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code â€“ ensures reproducibility\n",
    "\n",
    "def split_inputs_and_targets(mulvar_series, ahead=14, target_col=1):\n",
    "    return mulvar_series[:, :-ahead], mulvar_series[:, -ahead:, target_col]\n",
    "\n",
    "ahead_train_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    mulvar_train.to_numpy(),\n",
    "    targets=None,\n",
    "    sequence_length=seq_length + 14,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ").map(split_inputs_and_targets)\n",
    "ahead_valid_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    mulvar_valid.to_numpy(),\n",
    "    targets=None,\n",
    "    sequence_length=seq_length + 14,\n",
    "    batch_size=32\n",
    ").map(split_inputs_and_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cac20074",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "ahead_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, input_shape=[None, 7]),\n",
    "    tf.keras.layers.Dense(14)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5502ceed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "227/227 [==============================] - 2s 5ms/step - loss: 0.1044 - mae: 0.2893 - mse: 0.2390 - val_loss: 0.0323 - val_mae: 0.1767 - val_mse: 0.0645\n",
      "Epoch 2/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 0.0114 - mae: 0.0908 - mse: 0.0228 - val_loss: 0.0035 - val_mae: 0.0557 - val_mse: 0.0071\n",
      "Epoch 3/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0290 - mse: 0.0023 - val_loss: 3.7054e-04 - val_mae: 0.0172 - val_mse: 7.4107e-04\n",
      "Epoch 4/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.1886e-04 - mae: 0.0094 - mse: 2.3772e-04 - val_loss: 3.5707e-05 - val_mae: 0.0058 - val_mse: 7.1414e-05\n",
      "Epoch 5/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.1883e-05 - mae: 0.0033 - mse: 2.3766e-05 - val_loss: 3.9297e-06 - val_mae: 0.0020 - val_mse: 7.8594e-06\n",
      "Epoch 6/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 2.6945e-06 - mae: 0.0018 - mse: 5.3891e-06 - val_loss: 5.7400e-07 - val_mae: 7.3772e-04 - val_mse: 1.1480e-06\n",
      "Epoch 7/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.7347e-06 - mae: 0.0015 - mse: 3.4694e-06 - val_loss: 7.7239e-07 - val_mae: 0.0011 - val_mse: 1.5448e-06\n",
      "Epoch 8/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.0823e-06 - mae: 0.0012 - mse: 2.1646e-06 - val_loss: 9.3250e-07 - val_mae: 0.0013 - val_mse: 1.8650e-06\n",
      "Epoch 9/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 9.4041e-07 - mae: 0.0011 - mse: 1.8808e-06 - val_loss: 3.9434e-06 - val_mae: 0.0028 - val_mse: 7.8868e-06\n",
      "Epoch 10/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.0557e-06 - mae: 0.0012 - mse: 2.1114e-06 - val_loss: 4.8280e-07 - val_mae: 8.7259e-04 - val_mse: 9.6559e-07\n",
      "Epoch 11/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.0350e-06 - mae: 0.0012 - mse: 2.0700e-06 - val_loss: 5.1229e-07 - val_mae: 9.0078e-04 - val_mse: 1.0246e-06\n",
      "Epoch 12/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.0835e-06 - mae: 0.0012 - mse: 2.1671e-06 - val_loss: 2.3125e-06 - val_mae: 0.0021 - val_mse: 4.6250e-06\n",
      "Epoch 13/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.6213e-06 - mae: 0.0015 - mse: 3.2425e-06 - val_loss: 3.1393e-06 - val_mae: 0.0025 - val_mse: 6.2787e-06\n",
      "Epoch 14/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.9060e-06 - mae: 0.0016 - mse: 3.8120e-06 - val_loss: 3.0650e-06 - val_mae: 0.0024 - val_mse: 6.1301e-06\n",
      "Epoch 15/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.3516e-06 - mae: 0.0013 - mse: 2.7032e-06 - val_loss: 2.5203e-06 - val_mae: 0.0022 - val_mse: 5.0406e-06\n",
      "Epoch 16/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.0445e-06 - mae: 0.0012 - mse: 2.0890e-06 - val_loss: 3.8375e-06 - val_mae: 0.0027 - val_mse: 7.6750e-06\n",
      "Epoch 17/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.0029e-06 - mae: 0.0012 - mse: 2.0058e-06 - val_loss: 4.4360e-07 - val_mae: 8.3320e-04 - val_mse: 8.8721e-07\n",
      "Epoch 18/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.2692e-06 - mae: 0.0013 - mse: 2.5385e-06 - val_loss: 1.3940e-07 - val_mae: 4.3740e-04 - val_mse: 2.7881e-07\n",
      "Epoch 19/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 9.9877e-07 - mae: 0.0012 - mse: 1.9975e-06 - val_loss: 1.4300e-06 - val_mae: 0.0016 - val_mse: 2.8600e-06\n",
      "Epoch 20/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 9.1857e-07 - mae: 0.0011 - mse: 1.8371e-06 - val_loss: 1.1320e-06 - val_mae: 0.0014 - val_mse: 2.2641e-06\n",
      "Epoch 21/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.2733e-06 - mae: 0.0013 - mse: 2.5465e-06 - val_loss: 3.6270e-06 - val_mae: 0.0026 - val_mse: 7.2541e-06\n",
      "Epoch 22/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.5619e-06 - mae: 0.0014 - mse: 3.1238e-06 - val_loss: 8.0272e-07 - val_mae: 0.0012 - val_mse: 1.6054e-06\n",
      "Epoch 23/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.1426e-06 - mae: 0.0012 - mse: 2.2852e-06 - val_loss: 4.0294e-07 - val_mae: 7.8914e-04 - val_mse: 8.0587e-07\n",
      "Epoch 24/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.2356e-06 - mae: 0.0013 - mse: 2.4712e-06 - val_loss: 1.7460e-07 - val_mae: 5.0154e-04 - val_mse: 3.4920e-07\n",
      "Epoch 25/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.1669e-06 - mae: 0.0013 - mse: 2.3337e-06 - val_loss: 1.0691e-06 - val_mae: 0.0014 - val_mse: 2.1382e-06\n",
      "Epoch 26/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.8059e-06 - mae: 0.0016 - mse: 3.6117e-06 - val_loss: 1.3633e-07 - val_mae: 4.1080e-04 - val_mse: 2.7266e-07\n",
      "Epoch 27/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.6971e-06 - mae: 0.0015 - mse: 3.3943e-06 - val_loss: 1.4349e-07 - val_mae: 4.5049e-04 - val_mse: 2.8697e-07\n",
      "Epoch 28/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.3961e-06 - mae: 0.0014 - mse: 2.7921e-06 - val_loss: 1.0627e-06 - val_mae: 0.0014 - val_mse: 2.1254e-06\n",
      "Epoch 29/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.3342e-06 - mae: 0.0013 - mse: 2.6683e-06 - val_loss: 5.4780e-06 - val_mae: 0.0033 - val_mse: 1.0956e-05\n",
      "Epoch 30/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.8862e-06 - mae: 0.0016 - mse: 3.7724e-06 - val_loss: 2.3115e-06 - val_mae: 0.0021 - val_mse: 4.6230e-06\n",
      "Epoch 31/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.2051e-06 - mae: 0.0013 - mse: 2.4103e-06 - val_loss: 2.5732e-06 - val_mae: 0.0022 - val_mse: 5.1464e-06\n",
      "Epoch 32/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.2887e-06 - mae: 0.0013 - mse: 2.5775e-06 - val_loss: 9.7361e-07 - val_mae: 0.0013 - val_mse: 1.9472e-06\n",
      "Epoch 33/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.1933e-06 - mae: 0.0013 - mse: 2.3867e-06 - val_loss: 2.8909e-06 - val_mae: 0.0023 - val_mse: 5.7818e-06\n",
      "Epoch 34/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 2.0140e-06 - mae: 0.0016 - mse: 4.0280e-06 - val_loss: 6.7712e-06 - val_mae: 0.0036 - val_mse: 1.3542e-05\n",
      "Epoch 35/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.0725e-06 - mae: 0.0012 - mse: 2.1449e-06 - val_loss: 6.9961e-07 - val_mae: 0.0011 - val_mse: 1.3992e-06\n",
      "Epoch 36/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.1619e-06 - mae: 0.0013 - mse: 2.3238e-06 - val_loss: 3.5979e-06 - val_mae: 0.0026 - val_mse: 7.1958e-06\n",
      "Epoch 37/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.0411e-06 - mae: 0.0012 - mse: 2.0822e-06 - val_loss: 1.0261e-06 - val_mae: 0.0013 - val_mse: 2.0521e-06\n",
      "Epoch 38/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.4698e-06 - mae: 0.0014 - mse: 2.9397e-06 - val_loss: 6.2208e-07 - val_mae: 0.0010 - val_mse: 1.2442e-06\n",
      "Epoch 39/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.2922e-06 - mae: 0.0013 - mse: 2.5844e-06 - val_loss: 2.6671e-07 - val_mae: 6.2470e-04 - val_mse: 5.3343e-07\n",
      "Epoch 40/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.1888e-06 - mae: 0.0013 - mse: 2.3776e-06 - val_loss: 1.7608e-06 - val_mae: 0.0018 - val_mse: 3.5215e-06\n",
      "Epoch 41/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 9.5724e-07 - mae: 0.0011 - mse: 1.9145e-06 - val_loss: 1.3000e-06 - val_mae: 0.0015 - val_mse: 2.5999e-06\n",
      "Epoch 42/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.0824e-06 - mae: 0.0012 - mse: 2.1649e-06 - val_loss: 3.1606e-07 - val_mae: 6.8772e-04 - val_mse: 6.3212e-07\n",
      "Epoch 43/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.2243e-06 - mae: 0.0013 - mse: 2.4487e-06 - val_loss: 2.7054e-06 - val_mae: 0.0023 - val_mse: 5.4108e-06\n",
      "Epoch 44/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.4897e-06 - mae: 0.0014 - mse: 2.9794e-06 - val_loss: 7.4942e-07 - val_mae: 0.0011 - val_mse: 1.4988e-06\n",
      "Epoch 45/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.4832e-06 - mae: 0.0014 - mse: 2.9664e-06 - val_loss: 2.3743e-06 - val_mae: 0.0021 - val_mse: 4.7486e-06\n",
      "Epoch 46/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.3355e-06 - mae: 0.0013 - mse: 2.6710e-06 - val_loss: 2.3153e-07 - val_mae: 5.3160e-04 - val_mse: 4.6307e-07\n",
      "Epoch 47/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.5436e-06 - mae: 0.0014 - mse: 3.0872e-06 - val_loss: 2.0754e-06 - val_mae: 0.0020 - val_mse: 4.1507e-06\n",
      "Epoch 48/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.9717e-06 - mae: 0.0016 - mse: 3.9434e-06 - val_loss: 8.2824e-06 - val_mae: 0.0040 - val_mse: 1.6565e-05\n",
      "Epoch 49/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.4280e-06 - mae: 0.0014 - mse: 2.8560e-06 - val_loss: 1.6324e-06 - val_mae: 0.0017 - val_mse: 3.2648e-06\n",
      "Epoch 50/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 9.4378e-07 - mae: 0.0011 - mse: 1.8876e-06 - val_loss: 3.5877e-07 - val_mae: 7.3735e-04 - val_mse: 7.1754e-07\n",
      "Epoch 51/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.3491e-06 - mae: 0.0013 - mse: 2.6981e-06 - val_loss: 7.6359e-07 - val_mae: 0.0011 - val_mse: 1.5272e-06\n",
      "Epoch 52/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.7866e-06 - mae: 0.0016 - mse: 3.5733e-06 - val_loss: 3.2420e-07 - val_mae: 6.9714e-04 - val_mse: 6.4840e-07\n",
      "Epoch 53/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.7875e-06 - mae: 0.0015 - mse: 3.5751e-06 - val_loss: 6.0331e-07 - val_mae: 9.8733e-04 - val_mse: 1.2066e-06\n",
      "Epoch 54/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.1697e-06 - mae: 0.0013 - mse: 2.3393e-06 - val_loss: 2.3008e-06 - val_mae: 0.0021 - val_mse: 4.6015e-06\n",
      "Epoch 55/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 9.1902e-07 - mae: 0.0011 - mse: 1.8380e-06 - val_loss: 1.8087e-06 - val_mae: 0.0018 - val_mse: 3.6175e-06\n",
      "Epoch 56/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.3670e-06 - mae: 0.0014 - mse: 2.7340e-06 - val_loss: 2.6727e-07 - val_mae: 6.2558e-04 - val_mse: 5.3453e-07\n",
      "Epoch 57/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.0870e-06 - mae: 0.0012 - mse: 2.1741e-06 - val_loss: 3.4969e-06 - val_mae: 0.0026 - val_mse: 6.9938e-06\n",
      "Epoch 58/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.5774e-06 - mae: 0.0014 - mse: 3.1549e-06 - val_loss: 1.4840e-06 - val_mae: 0.0016 - val_mse: 2.9680e-06\n",
      "Epoch 59/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.1335e-06 - mae: 0.0012 - mse: 2.2671e-06 - val_loss: 2.5424e-06 - val_mae: 0.0022 - val_mse: 5.0848e-06\n",
      "Epoch 60/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.2319e-06 - mae: 0.0013 - mse: 2.4639e-06 - val_loss: 1.8874e-06 - val_mae: 0.0019 - val_mse: 3.7748e-06\n",
      "Epoch 61/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.0625e-06 - mae: 0.0012 - mse: 2.1250e-06 - val_loss: 2.1142e-06 - val_mae: 0.0020 - val_mse: 4.2285e-06\n",
      "Epoch 62/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 9.6540e-07 - mae: 0.0011 - mse: 1.9308e-06 - val_loss: 2.2345e-06 - val_mae: 0.0021 - val_mse: 4.4691e-06\n",
      "Epoch 63/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.1148e-06 - mae: 0.0012 - mse: 2.2296e-06 - val_loss: 1.0506e-06 - val_mae: 0.0014 - val_mse: 2.1012e-06\n",
      "Epoch 64/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.4071e-06 - mae: 0.0014 - mse: 2.8141e-06 - val_loss: 2.5918e-07 - val_mae: 6.1504e-04 - val_mse: 5.1835e-07\n",
      "Epoch 65/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.4838e-06 - mae: 0.0014 - mse: 2.9676e-06 - val_loss: 1.3697e-07 - val_mae: 4.1151e-04 - val_mse: 2.7394e-07\n",
      "Epoch 66/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.2631e-06 - mae: 0.0013 - mse: 2.5263e-06 - val_loss: 1.1125e-06 - val_mae: 0.0014 - val_mse: 2.2251e-06\n",
      "Epoch 67/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.2055e-06 - mae: 0.0013 - mse: 2.4110e-06 - val_loss: 1.5572e-07 - val_mae: 4.7645e-04 - val_mse: 3.1144e-07\n",
      "Epoch 68/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.4810e-06 - mae: 0.0014 - mse: 2.9621e-06 - val_loss: 4.7933e-07 - val_mae: 8.6750e-04 - val_mse: 9.5865e-07\n",
      "Epoch 69/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.1122e-06 - mae: 0.0012 - mse: 2.2244e-06 - val_loss: 2.4767e-06 - val_mae: 0.0022 - val_mse: 4.9534e-06\n",
      "Epoch 70/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 9.5664e-07 - mae: 0.0011 - mse: 1.9133e-06 - val_loss: 6.5691e-07 - val_mae: 0.0010 - val_mse: 1.3138e-06\n",
      "Epoch 71/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.3888e-06 - mae: 0.0014 - mse: 2.7777e-06 - val_loss: 4.1379e-07 - val_mae: 8.0202e-04 - val_mse: 8.2758e-07\n",
      "Epoch 72/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.2039e-06 - mae: 0.0013 - mse: 2.4077e-06 - val_loss: 9.1111e-07 - val_mae: 0.0013 - val_mse: 1.8222e-06\n",
      "Epoch 73/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.1090e-06 - mae: 0.0012 - mse: 2.2180e-06 - val_loss: 3.4476e-07 - val_mae: 7.2310e-04 - val_mse: 6.8952e-07\n",
      "Epoch 74/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 1.3736e-06 - mae: 0.0013 - mse: 2.7471e-06 - val_loss: 1.6436e-06 - val_mae: 0.0017 - val_mse: 3.2871e-06\n",
      "Epoch 75/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 9.6857e-07 - mae: 0.0012 - mse: 1.9371e-06 - val_loss: 6.7369e-07 - val_mae: 0.0011 - val_mse: 1.3474e-06\n",
      "Epoch 76/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 9.6208e-07 - mae: 0.0011 - mse: 1.9242e-06 - val_loss: 1.9524e-06 - val_mae: 0.0019 - val_mse: 3.9048e-06\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3633e-07 - mae: 4.1080e-04 - mse: 2.7266e-07\n"
     ]
    }
   ],
   "source": [
    "# BEST LEARNING_RATE = 150 * 0.001 + 0.002 BUT STILL SUCKS\n",
    "\n",
    "#min_learning_rate = 0.002\n",
    "#max_learning_rate = 0.2\n",
    "#step = 0.001\n",
    "\n",
    "#Mae = []\n",
    "\n",
    "#for learning_rate in np.arange(min_learning_rate, max_learning_rate + step, step):\n",
    "#    mae = fit_and_evaluate(ahead_model, ahead_train_ds, ahead_valid_ds, learning_rate=learning_rate)\n",
    "#    Mae.append(mae)\n",
    "    \n",
    "\n",
    "#for mae in Mae :\n",
    "#    print(mae)\n",
    "\n",
    "#plt.plot(Mae)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "mae_ahead, mse_ahead = fit_and_evaluate(ahead_model, ahead_train_ds, ahead_valid_ds,\n",
    "                 learning_rate=0.152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9c521c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 116ms/step\n"
     ]
    }
   ],
   "source": [
    "X = mulvar_valid.to_numpy()[np.newaxis, :seq_length]  # shape [1, 56, 7]\n",
    "Y_pred = ahead_model.predict(X)  # shape [1, 14]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9b966f",
   "metadata": {},
   "source": [
    "# Deep RNNs with Layer Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8f0e6c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_windows(dataset, length):\n",
    "    dataset = dataset.window(length, shift=1, drop_remainder=True)\n",
    "    return dataset.flat_map(lambda window_ds: window_ds.batch(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b36df4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_seq2seq_dataset(series, seq_length=56, ahead=14, target_col=1,\n",
    "                       batch_size=32, shuffle=False, seed=None):\n",
    "    ds = to_windows(tf.data.Dataset.from_tensor_slices(series), ahead + 1)\n",
    "    ds = to_windows(ds, seq_length).map(lambda S: (S[:, 0], S[:, 1:, 1]))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(8 * batch_size, seed=seed)\n",
    "    return ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e4025979",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_train = to_seq2seq_dataset(mulvar_train, shuffle=True, seed=42)\n",
    "seq2seq_valid = to_seq2seq_dataset(mulvar_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "af798d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LNSimpleRNNCell(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, activation=\"tanh\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.state_size = units\n",
    "        self.output_size = units\n",
    "        self.simple_rnn_cell = tf.keras.layers.SimpleRNNCell(units,\n",
    "                                                             activation=None)\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        outputs, new_states = self.simple_rnn_cell(inputs, states)\n",
    "        norm_outputs = self.activation(self.layer_norm(outputs))\n",
    "        return norm_outputs, [norm_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "449dd664",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code â€“ ensures reproducibility\n",
    "custom_ln_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.RNN(LNSimpleRNNCell(32), return_sequences=True,\n",
    "                        input_shape=[None, 7]),\n",
    "    tf.keras.layers.Dense(14)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ece8a782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "227/227 [==============================] - 5s 16ms/step - loss: 0.0307 - mae: 0.1715 - mse: 0.0615 - val_loss: 0.0044 - val_mae: 0.0765 - val_mse: 0.0088\n",
      "Epoch 2/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 0.0023 - mae: 0.0477 - mse: 0.0046 - val_loss: 5.1204e-04 - val_mae: 0.0251 - val_mse: 0.0010\n",
      "Epoch 3/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.2726e-04 - mae: 0.0152 - mse: 4.5453e-04 - val_loss: 9.4336e-05 - val_mae: 0.0092 - val_mse: 1.8867e-04\n",
      "Epoch 4/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.7526e-05 - mae: 0.0052 - mse: 5.5052e-05 - val_loss: 5.9280e-06 - val_mae: 0.0027 - val_mse: 1.1856e-05\n",
      "Epoch 5/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 5.2727e-06 - mae: 0.0024 - mse: 1.0545e-05 - val_loss: 8.5937e-07 - val_mae: 0.0010 - val_mse: 1.7187e-06\n",
      "Epoch 6/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.4783e-06 - mae: 0.0017 - mse: 4.9566e-06 - val_loss: 6.6240e-07 - val_mae: 8.0929e-04 - val_mse: 1.3248e-06\n",
      "Epoch 7/10000\n",
      "227/227 [==============================] - 4s 15ms/step - loss: 2.4175e-06 - mae: 0.0017 - mse: 4.8350e-06 - val_loss: 6.7619e-07 - val_mae: 8.9864e-04 - val_mse: 1.3524e-06\n",
      "Epoch 8/10000\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 2.3353e-06 - mae: 0.0017 - mse: 4.6707e-06 - val_loss: 7.9781e-07 - val_mae: 0.0010 - val_mse: 1.5956e-06\n",
      "Epoch 9/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.4485e-06 - mae: 0.0017 - mse: 4.8969e-06 - val_loss: 7.5487e-07 - val_mae: 9.4980e-04 - val_mse: 1.5097e-06\n",
      "Epoch 10/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.5185e-06 - mae: 0.0017 - mse: 5.0370e-06 - val_loss: 7.7400e-07 - val_mae: 9.0657e-04 - val_mse: 1.5480e-06\n",
      "Epoch 11/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.4047e-06 - mae: 0.0017 - mse: 4.8093e-06 - val_loss: 7.5317e-07 - val_mae: 9.8593e-04 - val_mse: 1.5063e-06\n",
      "Epoch 12/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.3238e-06 - mae: 0.0017 - mse: 4.6475e-06 - val_loss: 7.8411e-07 - val_mae: 9.6362e-04 - val_mse: 1.5682e-06\n",
      "Epoch 13/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.5459e-06 - mae: 0.0018 - mse: 5.0918e-06 - val_loss: 8.2601e-07 - val_mae: 9.8165e-04 - val_mse: 1.6520e-06\n",
      "Epoch 14/10000\n",
      "227/227 [==============================] - 4s 15ms/step - loss: 2.5103e-06 - mae: 0.0017 - mse: 5.0206e-06 - val_loss: 7.1852e-07 - val_mae: 9.0289e-04 - val_mse: 1.4370e-06\n",
      "Epoch 15/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.3528e-06 - mae: 0.0017 - mse: 4.7055e-06 - val_loss: 8.0014e-07 - val_mae: 9.2200e-04 - val_mse: 1.6003e-06\n",
      "Epoch 16/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.5231e-06 - mae: 0.0017 - mse: 5.0462e-06 - val_loss: 7.5957e-07 - val_mae: 9.1959e-04 - val_mse: 1.5191e-06\n",
      "Epoch 17/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.5093e-06 - mae: 0.0017 - mse: 5.0186e-06 - val_loss: 7.2602e-07 - val_mae: 8.8726e-04 - val_mse: 1.4520e-06\n",
      "Epoch 18/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.3933e-06 - mae: 0.0017 - mse: 4.7866e-06 - val_loss: 7.6045e-07 - val_mae: 9.5370e-04 - val_mse: 1.5209e-06\n",
      "Epoch 19/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.4005e-06 - mae: 0.0017 - mse: 4.8010e-06 - val_loss: 7.1554e-07 - val_mae: 8.9237e-04 - val_mse: 1.4311e-06\n",
      "Epoch 20/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.3217e-06 - mae: 0.0017 - mse: 4.6434e-06 - val_loss: 6.5550e-07 - val_mae: 8.3074e-04 - val_mse: 1.3110e-06\n",
      "Epoch 21/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.3337e-06 - mae: 0.0017 - mse: 4.6675e-06 - val_loss: 7.3015e-07 - val_mae: 9.3392e-04 - val_mse: 1.4603e-06\n",
      "Epoch 22/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.4180e-06 - mae: 0.0017 - mse: 4.8360e-06 - val_loss: 7.9545e-07 - val_mae: 8.9007e-04 - val_mse: 1.5909e-06\n",
      "Epoch 23/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.4918e-06 - mae: 0.0017 - mse: 4.9836e-06 - val_loss: 7.1546e-07 - val_mae: 8.4464e-04 - val_mse: 1.4309e-06\n",
      "Epoch 24/10000\n",
      "227/227 [==============================] - 4s 15ms/step - loss: 2.4522e-06 - mae: 0.0017 - mse: 4.9045e-06 - val_loss: 7.6522e-07 - val_mae: 8.6171e-04 - val_mse: 1.5304e-06\n",
      "Epoch 25/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.4426e-06 - mae: 0.0017 - mse: 4.8851e-06 - val_loss: 7.3124e-07 - val_mae: 8.7063e-04 - val_mse: 1.4625e-06\n",
      "Epoch 26/10000\n",
      "227/227 [==============================] - 4s 15ms/step - loss: 2.3968e-06 - mae: 0.0017 - mse: 4.7935e-06 - val_loss: 8.2904e-07 - val_mae: 9.3364e-04 - val_mse: 1.6581e-06\n",
      "Epoch 27/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.4881e-06 - mae: 0.0017 - mse: 4.9762e-06 - val_loss: 6.7211e-07 - val_mae: 7.9569e-04 - val_mse: 1.3442e-06\n",
      "Epoch 28/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.3594e-06 - mae: 0.0017 - mse: 4.7188e-06 - val_loss: 6.8882e-07 - val_mae: 8.6544e-04 - val_mse: 1.3776e-06\n",
      "Epoch 29/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.2848e-06 - mae: 0.0017 - mse: 4.5696e-06 - val_loss: 6.4183e-07 - val_mae: 7.8322e-04 - val_mse: 1.2837e-06\n",
      "Epoch 30/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.3426e-06 - mae: 0.0017 - mse: 4.6851e-06 - val_loss: 7.0515e-07 - val_mae: 8.7668e-04 - val_mse: 1.4103e-06\n",
      "Epoch 31/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.3316e-06 - mae: 0.0017 - mse: 4.6632e-06 - val_loss: 6.9982e-07 - val_mae: 8.2228e-04 - val_mse: 1.3996e-06\n",
      "Epoch 32/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.2685e-06 - mae: 0.0016 - mse: 4.5369e-06 - val_loss: 7.8185e-07 - val_mae: 9.3632e-04 - val_mse: 1.5637e-06\n",
      "Epoch 33/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.4593e-06 - mae: 0.0017 - mse: 4.9186e-06 - val_loss: 8.3111e-07 - val_mae: 9.4847e-04 - val_mse: 1.6622e-06\n",
      "Epoch 34/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.5079e-06 - mae: 0.0017 - mse: 5.0158e-06 - val_loss: 7.0514e-07 - val_mae: 8.8770e-04 - val_mse: 1.4103e-06\n",
      "Epoch 35/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.4722e-06 - mae: 0.0017 - mse: 4.9445e-06 - val_loss: 7.5079e-07 - val_mae: 9.0237e-04 - val_mse: 1.5016e-06\n",
      "Epoch 36/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.4818e-06 - mae: 0.0017 - mse: 4.9637e-06 - val_loss: 7.4435e-07 - val_mae: 8.7959e-04 - val_mse: 1.4887e-06\n",
      "Epoch 37/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.4616e-06 - mae: 0.0017 - mse: 4.9232e-06 - val_loss: 7.8033e-07 - val_mae: 9.2174e-04 - val_mse: 1.5607e-06\n",
      "Epoch 38/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.4130e-06 - mae: 0.0017 - mse: 4.8260e-06 - val_loss: 9.2542e-07 - val_mae: 0.0010 - val_mse: 1.8508e-06\n",
      "Epoch 39/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.5552e-06 - mae: 0.0017 - mse: 5.1104e-06 - val_loss: 7.6564e-07 - val_mae: 9.2333e-04 - val_mse: 1.5313e-06\n",
      "Epoch 40/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.5091e-06 - mae: 0.0017 - mse: 5.0182e-06 - val_loss: 7.6538e-07 - val_mae: 8.9499e-04 - val_mse: 1.5308e-06\n",
      "Epoch 41/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.3887e-06 - mae: 0.0017 - mse: 4.7775e-06 - val_loss: 8.0247e-07 - val_mae: 9.0118e-04 - val_mse: 1.6049e-06\n",
      "Epoch 42/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.5224e-06 - mae: 0.0017 - mse: 5.0447e-06 - val_loss: 8.1999e-07 - val_mae: 9.3877e-04 - val_mse: 1.6400e-06\n",
      "Epoch 43/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.5147e-06 - mae: 0.0017 - mse: 5.0293e-06 - val_loss: 7.4580e-07 - val_mae: 8.8722e-04 - val_mse: 1.4916e-06\n",
      "Epoch 44/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.4435e-06 - mae: 0.0017 - mse: 4.8871e-06 - val_loss: 8.1583e-07 - val_mae: 9.2919e-04 - val_mse: 1.6317e-06\n",
      "Epoch 45/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.5728e-06 - mae: 0.0018 - mse: 5.1457e-06 - val_loss: 7.8864e-07 - val_mae: 9.1301e-04 - val_mse: 1.5773e-06\n",
      "Epoch 46/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.3747e-06 - mae: 0.0017 - mse: 4.7494e-06 - val_loss: 7.8270e-07 - val_mae: 9.0974e-04 - val_mse: 1.5654e-06\n",
      "Epoch 47/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.5227e-06 - mae: 0.0017 - mse: 5.0454e-06 - val_loss: 8.8989e-07 - val_mae: 9.9574e-04 - val_mse: 1.7798e-06\n",
      "Epoch 48/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.5251e-06 - mae: 0.0017 - mse: 5.0501e-06 - val_loss: 8.5463e-07 - val_mae: 9.6579e-04 - val_mse: 1.7093e-06\n",
      "Epoch 49/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.5127e-06 - mae: 0.0017 - mse: 5.0255e-06 - val_loss: 7.9071e-07 - val_mae: 9.2358e-04 - val_mse: 1.5814e-06\n",
      "Epoch 50/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.4888e-06 - mae: 0.0017 - mse: 4.9776e-06 - val_loss: 8.9226e-07 - val_mae: 9.9480e-04 - val_mse: 1.7845e-06\n",
      "Epoch 51/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.5004e-06 - mae: 0.0017 - mse: 5.0008e-06 - val_loss: 9.5067e-07 - val_mae: 0.0010 - val_mse: 1.9013e-06\n",
      "Epoch 52/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.5933e-06 - mae: 0.0018 - mse: 5.1865e-06 - val_loss: 7.9187e-07 - val_mae: 8.9880e-04 - val_mse: 1.5837e-06\n",
      "Epoch 53/10000\n",
      "227/227 [==============================] - 4s 15ms/step - loss: 2.4738e-06 - mae: 0.0017 - mse: 4.9476e-06 - val_loss: 9.3517e-07 - val_mae: 0.0010 - val_mse: 1.8703e-06\n",
      "Epoch 54/10000\n",
      "227/227 [==============================] - 4s 15ms/step - loss: 2.6044e-06 - mae: 0.0018 - mse: 5.2087e-06 - val_loss: 8.8380e-07 - val_mae: 9.8156e-04 - val_mse: 1.7676e-06\n",
      "Epoch 55/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.5925e-06 - mae: 0.0018 - mse: 5.1850e-06 - val_loss: 9.3874e-07 - val_mae: 0.0010 - val_mse: 1.8775e-06\n",
      "Epoch 56/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.5889e-06 - mae: 0.0018 - mse: 5.1778e-06 - val_loss: 1.0754e-06 - val_mae: 0.0011 - val_mse: 2.1509e-06\n",
      "Epoch 57/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.5828e-06 - mae: 0.0017 - mse: 5.1655e-06 - val_loss: 8.1303e-07 - val_mae: 9.3423e-04 - val_mse: 1.6261e-06\n",
      "Epoch 58/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.4768e-06 - mae: 0.0017 - mse: 4.9537e-06 - val_loss: 9.1578e-07 - val_mae: 9.9909e-04 - val_mse: 1.8316e-06\n",
      "Epoch 59/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.5566e-06 - mae: 0.0017 - mse: 5.1132e-06 - val_loss: 8.5163e-07 - val_mae: 9.5989e-04 - val_mse: 1.7033e-06\n",
      "Epoch 60/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.5634e-06 - mae: 0.0018 - mse: 5.1268e-06 - val_loss: 9.8824e-07 - val_mae: 0.0011 - val_mse: 1.9765e-06\n",
      "Epoch 61/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.5841e-06 - mae: 0.0017 - mse: 5.1681e-06 - val_loss: 1.0239e-06 - val_mae: 0.0011 - val_mse: 2.0479e-06\n",
      "Epoch 62/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.6268e-06 - mae: 0.0018 - mse: 5.2536e-06 - val_loss: 1.0751e-06 - val_mae: 0.0011 - val_mse: 2.1502e-06\n",
      "Epoch 63/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.7041e-06 - mae: 0.0018 - mse: 5.4083e-06 - val_loss: 1.1861e-06 - val_mae: 0.0012 - val_mse: 2.3723e-06\n",
      "Epoch 64/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.7481e-06 - mae: 0.0018 - mse: 5.4962e-06 - val_loss: 1.0053e-06 - val_mae: 0.0011 - val_mse: 2.0107e-06\n",
      "Epoch 65/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.7091e-06 - mae: 0.0018 - mse: 5.4182e-06 - val_loss: 1.1979e-06 - val_mae: 0.0012 - val_mse: 2.3958e-06\n",
      "Epoch 66/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.8037e-06 - mae: 0.0018 - mse: 5.6074e-06 - val_loss: 1.1085e-06 - val_mae: 0.0011 - val_mse: 2.2171e-06\n",
      "Epoch 67/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.6983e-06 - mae: 0.0018 - mse: 5.3966e-06 - val_loss: 1.0742e-06 - val_mae: 0.0011 - val_mse: 2.1484e-06\n",
      "Epoch 68/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.6299e-06 - mae: 0.0018 - mse: 5.2598e-06 - val_loss: 1.1304e-06 - val_mae: 0.0011 - val_mse: 2.2609e-06\n",
      "Epoch 69/10000\n",
      "227/227 [==============================] - 4s 15ms/step - loss: 2.7058e-06 - mae: 0.0018 - mse: 5.4117e-06 - val_loss: 1.1675e-06 - val_mae: 0.0012 - val_mse: 2.3351e-06\n",
      "Epoch 70/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.6956e-06 - mae: 0.0018 - mse: 5.3913e-06 - val_loss: 1.1358e-06 - val_mae: 0.0011 - val_mse: 2.2715e-06\n",
      "Epoch 71/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.6474e-06 - mae: 0.0018 - mse: 5.2947e-06 - val_loss: 1.1499e-06 - val_mae: 0.0012 - val_mse: 2.2998e-06\n",
      "Epoch 72/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.5432e-06 - mae: 0.0017 - mse: 5.0864e-06 - val_loss: 1.2021e-06 - val_mae: 0.0012 - val_mse: 2.4042e-06\n",
      "Epoch 73/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.7090e-06 - mae: 0.0018 - mse: 5.4180e-06 - val_loss: 1.1903e-06 - val_mae: 0.0012 - val_mse: 2.3805e-06\n",
      "Epoch 74/10000\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 2.7683e-06 - mae: 0.0018 - mse: 5.5366e-06 - val_loss: 1.3260e-06 - val_mae: 0.0013 - val_mse: 2.6520e-06\n",
      "Epoch 75/10000\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 2.8198e-06 - mae: 0.0018 - mse: 5.6396e-06 - val_loss: 1.3361e-06 - val_mae: 0.0013 - val_mse: 2.6722e-06\n",
      "Epoch 76/10000\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 2.7420e-06 - mae: 0.0018 - mse: 5.4839e-06 - val_loss: 1.2993e-06 - val_mae: 0.0013 - val_mse: 2.5987e-06\n",
      "Epoch 77/10000\n",
      "227/227 [==============================] - 4s 15ms/step - loss: 2.7596e-06 - mae: 0.0018 - mse: 5.5192e-06 - val_loss: 1.4077e-06 - val_mae: 0.0013 - val_mse: 2.8153e-06\n",
      "Epoch 78/10000\n",
      "227/227 [==============================] - 4s 15ms/step - loss: 2.8611e-06 - mae: 0.0018 - mse: 5.7222e-06 - val_loss: 1.3228e-06 - val_mae: 0.0013 - val_mse: 2.6456e-06\n",
      "Epoch 79/10000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 2.8697e-06 - mae: 0.0018 - mse: 5.7393e-06 - val_loss: 1.4395e-06 - val_mae: 0.0014 - val_mse: 2.8789e-06\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.4183e-07 - mae: 7.8322e-04 - mse: 1.2837e-06\n"
     ]
    }
   ],
   "source": [
    "#BEST LEARNING_RATE = 0.002 + 160 * 0.001\n",
    "\n",
    "#min_learning_rate = 0.002\n",
    "#max_learning_rate = 0.2\n",
    "#step = 0.001\n",
    "\n",
    "#Mae = []\n",
    "\n",
    "#for learning_rate in np.arange(min_learning_rate, max_learning_rate + step, step):\n",
    "#    mae = fit_and_evaluate(custom_ln_model, seq2seq_train, seq2seq_valid, learning_rate=learning_rate)\n",
    "#    Mae.append(mae)\n",
    "    \n",
    "\n",
    "#for mae in Mae :\n",
    "#    print(mae)\n",
    "\n",
    "#plt.plot(Mae)\n",
    "#plt.show()\n",
    "\n",
    "mae_cstm, mse_cstm = fit_and_evaluate(custom_ln_model, seq2seq_train, seq2seq_valid,\n",
    "                 learning_rate=0.162, epochs=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd9eb5b",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "10c8234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code â€“ ensures reproducibility\n",
    "lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True, input_shape=[None, 7]),\n",
    "    tf.keras.layers.Dense(14)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2b22d2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "227/227 [==============================] - 5s 14ms/step - loss: 0.0374 - mae: 0.1708 - mse: 0.0765 - val_loss: 0.0100 - val_mae: 0.1106 - val_mse: 0.0201\n",
      "Epoch 2/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 0.0037 - mae: 0.0540 - mse: 0.0075 - val_loss: 4.7747e-04 - val_mae: 0.0246 - val_mse: 9.5493e-04\n",
      "Epoch 3/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 3.8108e-04 - mae: 0.0174 - mse: 7.6215e-04 - val_loss: 2.9897e-05 - val_mae: 0.0061 - val_mse: 5.9793e-05\n",
      "Epoch 4/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 4.0077e-05 - mae: 0.0057 - mse: 8.0153e-05 - val_loss: 6.1576e-06 - val_mae: 0.0025 - val_mse: 1.2315e-05\n",
      "Epoch 5/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 5.5246e-06 - mae: 0.0023 - mse: 1.1049e-05 - val_loss: 3.7419e-06 - val_mae: 0.0022 - val_mse: 7.4838e-06\n",
      "Epoch 6/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 1.1369e-06 - mae: 0.0013 - mse: 2.2737e-06 - val_loss: 1.8658e-06 - val_mae: 0.0018 - val_mse: 3.7317e-06\n",
      "Epoch 7/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 6.8538e-07 - mae: 9.4783e-04 - mse: 1.3708e-06 - val_loss: 9.1654e-07 - val_mae: 0.0013 - val_mse: 1.8331e-06\n",
      "Epoch 8/1000\n",
      "227/227 [==============================] - 3s 14ms/step - loss: 1.0294e-06 - mae: 0.0012 - mse: 2.0587e-06 - val_loss: 1.8259e-06 - val_mae: 0.0018 - val_mse: 3.6518e-06\n",
      "Epoch 9/1000\n",
      "227/227 [==============================] - 3s 14ms/step - loss: 6.4594e-07 - mae: 9.3294e-04 - mse: 1.2919e-06 - val_loss: 7.8674e-07 - val_mae: 0.0012 - val_mse: 1.5735e-06\n",
      "Epoch 10/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 9.2243e-07 - mae: 0.0012 - mse: 1.8449e-06 - val_loss: 1.3132e-06 - val_mae: 0.0015 - val_mse: 2.6263e-06\n",
      "Epoch 11/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 6.5985e-07 - mae: 9.5202e-04 - mse: 1.3197e-06 - val_loss: 1.0847e-06 - val_mae: 0.0014 - val_mse: 2.1694e-06\n",
      "Epoch 12/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 1.0600e-06 - mae: 0.0013 - mse: 2.1200e-06 - val_loss: 2.4262e-06 - val_mae: 0.0021 - val_mse: 4.8523e-06\n",
      "Epoch 13/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 6.0056e-07 - mae: 9.1296e-04 - mse: 1.2011e-06 - val_loss: 1.2161e-06 - val_mae: 0.0015 - val_mse: 2.4323e-06\n",
      "Epoch 14/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 1.0183e-06 - mae: 0.0012 - mse: 2.0366e-06 - val_loss: 1.7851e-06 - val_mae: 0.0018 - val_mse: 3.5702e-06\n",
      "Epoch 15/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 6.7183e-07 - mae: 9.6914e-04 - mse: 1.3437e-06 - val_loss: 1.2338e-06 - val_mae: 0.0015 - val_mse: 2.4676e-06\n",
      "Epoch 16/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 8.2730e-07 - mae: 0.0011 - mse: 1.6546e-06 - val_loss: 1.8502e-06 - val_mae: 0.0019 - val_mse: 3.7004e-06\n",
      "Epoch 17/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 6.9769e-07 - mae: 9.9259e-04 - mse: 1.3954e-06 - val_loss: 1.4127e-06 - val_mae: 0.0016 - val_mse: 2.8254e-06\n",
      "Epoch 18/1000\n",
      "227/227 [==============================] - 4s 15ms/step - loss: 7.3922e-07 - mae: 0.0010 - mse: 1.4784e-06 - val_loss: 1.6270e-06 - val_mae: 0.0017 - val_mse: 3.2540e-06\n",
      "Epoch 19/1000\n",
      "227/227 [==============================] - 3s 14ms/step - loss: 7.6596e-07 - mae: 0.0010 - mse: 1.5319e-06 - val_loss: 1.4587e-06 - val_mae: 0.0016 - val_mse: 2.9175e-06\n",
      "Epoch 20/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 9.6437e-07 - mae: 0.0012 - mse: 1.9287e-06 - val_loss: 2.0832e-06 - val_mae: 0.0020 - val_mse: 4.1665e-06\n",
      "Epoch 21/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 5.1013e-07 - mae: 8.3517e-04 - mse: 1.0203e-06 - val_loss: 1.0343e-06 - val_mae: 0.0014 - val_mse: 2.0686e-06\n",
      "Epoch 22/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.1633e-06 - mae: 0.0013 - mse: 2.3265e-06 - val_loss: 1.4761e-06 - val_mae: 0.0016 - val_mse: 2.9523e-06\n",
      "Epoch 23/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 7.1404e-07 - mae: 0.0010 - mse: 1.4281e-06 - val_loss: 1.1862e-06 - val_mae: 0.0015 - val_mse: 2.3723e-06\n",
      "Epoch 24/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 9.6732e-07 - mae: 0.0012 - mse: 1.9346e-06 - val_loss: 1.4301e-06 - val_mae: 0.0016 - val_mse: 2.8603e-06\n",
      "Epoch 25/1000\n",
      "227/227 [==============================] - 3s 14ms/step - loss: 7.3892e-07 - mae: 0.0010 - mse: 1.4778e-06 - val_loss: 1.4780e-06 - val_mae: 0.0017 - val_mse: 2.9560e-06\n",
      "Epoch 26/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 1.0621e-06 - mae: 0.0013 - mse: 2.1242e-06 - val_loss: 2.3390e-06 - val_mae: 0.0021 - val_mse: 4.6781e-06\n",
      "Epoch 27/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 5.6195e-07 - mae: 8.7508e-04 - mse: 1.1239e-06 - val_loss: 1.1403e-06 - val_mae: 0.0014 - val_mse: 2.2805e-06\n",
      "Epoch 28/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 9.4324e-07 - mae: 0.0012 - mse: 1.8865e-06 - val_loss: 1.1090e-06 - val_mae: 0.0014 - val_mse: 2.2180e-06\n",
      "Epoch 29/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 8.2093e-07 - mae: 0.0011 - mse: 1.6419e-06 - val_loss: 1.3649e-06 - val_mae: 0.0016 - val_mse: 2.7298e-06\n",
      "Epoch 30/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 9.7794e-07 - mae: 0.0012 - mse: 1.9559e-06 - val_loss: 1.8766e-06 - val_mae: 0.0019 - val_mse: 3.7532e-06\n",
      "Epoch 31/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 6.1897e-07 - mae: 9.3101e-04 - mse: 1.2379e-06 - val_loss: 9.8961e-07 - val_mae: 0.0013 - val_mse: 1.9792e-06\n",
      "Epoch 32/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 9.4834e-07 - mae: 0.0012 - mse: 1.8967e-06 - val_loss: 1.7393e-06 - val_mae: 0.0018 - val_mse: 3.4785e-06\n",
      "Epoch 33/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 8.0611e-07 - mae: 0.0011 - mse: 1.6122e-06 - val_loss: 1.4447e-06 - val_mae: 0.0016 - val_mse: 2.8894e-06\n",
      "Epoch 34/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 8.9381e-07 - mae: 0.0011 - mse: 1.7876e-06 - val_loss: 1.8937e-06 - val_mae: 0.0019 - val_mse: 3.7875e-06\n",
      "Epoch 35/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 7.0845e-07 - mae: 0.0010 - mse: 1.4169e-06 - val_loss: 1.2392e-06 - val_mae: 0.0015 - val_mse: 2.4784e-06\n",
      "Epoch 36/1000\n",
      "227/227 [==============================] - 3s 14ms/step - loss: 9.4246e-07 - mae: 0.0012 - mse: 1.8849e-06 - val_loss: 1.9519e-06 - val_mae: 0.0019 - val_mse: 3.9038e-06\n",
      "Epoch 37/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 6.7815e-07 - mae: 9.7780e-04 - mse: 1.3563e-06 - val_loss: 1.4453e-06 - val_mae: 0.0016 - val_mse: 2.8906e-06\n",
      "Epoch 38/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 8.0499e-07 - mae: 0.0011 - mse: 1.6100e-06 - val_loss: 1.6140e-06 - val_mae: 0.0017 - val_mse: 3.2279e-06\n",
      "Epoch 39/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 8.8687e-07 - mae: 0.0011 - mse: 1.7737e-06 - val_loss: 1.5554e-06 - val_mae: 0.0017 - val_mse: 3.1108e-06\n",
      "Epoch 40/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 9.5893e-07 - mae: 0.0012 - mse: 1.9179e-06 - val_loss: 1.9069e-06 - val_mae: 0.0019 - val_mse: 3.8138e-06\n",
      "Epoch 41/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 7.2629e-07 - mae: 0.0010 - mse: 1.4526e-06 - val_loss: 1.5895e-06 - val_mae: 0.0017 - val_mse: 3.1790e-06\n",
      "Epoch 42/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 8.1305e-07 - mae: 0.0011 - mse: 1.6261e-06 - val_loss: 1.5003e-06 - val_mae: 0.0017 - val_mse: 3.0006e-06\n",
      "Epoch 43/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.0513e-06 - mae: 0.0012 - mse: 2.1026e-06 - val_loss: 2.0024e-06 - val_mae: 0.0019 - val_mse: 4.0047e-06\n",
      "Epoch 44/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 7.5944e-07 - mae: 0.0010 - mse: 1.5189e-06 - val_loss: 2.1365e-06 - val_mae: 0.0020 - val_mse: 4.2730e-06\n",
      "Epoch 45/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 7.2483e-07 - mae: 0.0010 - mse: 1.4497e-06 - val_loss: 1.1412e-06 - val_mae: 0.0014 - val_mse: 2.2823e-06\n",
      "Epoch 46/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 9.4130e-07 - mae: 0.0012 - mse: 1.8826e-06 - val_loss: 1.6831e-06 - val_mae: 0.0018 - val_mse: 3.3662e-06\n",
      "Epoch 47/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 8.2684e-07 - mae: 0.0011 - mse: 1.6537e-06 - val_loss: 1.1924e-06 - val_mae: 0.0015 - val_mse: 2.3849e-06\n",
      "Epoch 48/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 1.1779e-06 - mae: 0.0013 - mse: 2.3558e-06 - val_loss: 2.2470e-06 - val_mae: 0.0021 - val_mse: 4.4941e-06\n",
      "Epoch 49/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 5.5262e-07 - mae: 8.6447e-04 - mse: 1.1052e-06 - val_loss: 9.6026e-07 - val_mae: 0.0013 - val_mse: 1.9205e-06\n",
      "Epoch 50/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 9.8964e-07 - mae: 0.0012 - mse: 1.9793e-06 - val_loss: 2.0475e-06 - val_mae: 0.0020 - val_mse: 4.0949e-06\n",
      "Epoch 51/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 7.5917e-07 - mae: 0.0010 - mse: 1.5183e-06 - val_loss: 2.1367e-06 - val_mae: 0.0020 - val_mse: 4.2734e-06\n",
      "Epoch 52/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 7.0209e-07 - mae: 9.9526e-04 - mse: 1.4042e-06 - val_loss: 1.7657e-06 - val_mae: 0.0018 - val_mse: 3.5313e-06\n",
      "Epoch 53/1000\n",
      "227/227 [==============================] - 3s 14ms/step - loss: 7.5645e-07 - mae: 0.0010 - mse: 1.5129e-06 - val_loss: 1.2287e-06 - val_mae: 0.0015 - val_mse: 2.4574e-06\n",
      "Epoch 54/1000\n",
      "227/227 [==============================] - 3s 15ms/step - loss: 8.9463e-07 - mae: 0.0011 - mse: 1.7893e-06 - val_loss: 1.4676e-06 - val_mae: 0.0016 - val_mse: 2.9352e-06\n",
      "Epoch 55/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 8.6637e-07 - mae: 0.0011 - mse: 1.7327e-06 - val_loss: 2.1470e-06 - val_mae: 0.0020 - val_mse: 4.2940e-06\n",
      "Epoch 56/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 6.2849e-07 - mae: 9.4193e-04 - mse: 1.2570e-06 - val_loss: 1.1099e-06 - val_mae: 0.0014 - val_mse: 2.2197e-06\n",
      "Epoch 57/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.0468e-06 - mae: 0.0012 - mse: 2.0936e-06 - val_loss: 1.5720e-06 - val_mae: 0.0017 - val_mse: 3.1440e-06\n",
      "Epoch 58/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 1.0197e-06 - mae: 0.0012 - mse: 2.0395e-06 - val_loss: 2.1438e-06 - val_mae: 0.0020 - val_mse: 4.2877e-06\n",
      "Epoch 59/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 5.8434e-07 - mae: 8.9927e-04 - mse: 1.1687e-06 - val_loss: 1.1217e-06 - val_mae: 0.0014 - val_mse: 2.2434e-06\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.8674e-07 - mae: 0.0012 - mse: 1.5735e-06\n"
     ]
    }
   ],
   "source": [
    "# BEST LEARNING_RATE = 15 * 0.01 + 0.01\n",
    "\n",
    "#min_learning_rate = 0.01\n",
    "#max_learning_rate = 0.2\n",
    "#step = 0.01\n",
    "\n",
    "#Mae = []\n",
    "\n",
    "#for learning_rate in np.arange(min_learning_rate, max_learning_rate + step, step):\n",
    "#    mae = fit_and_evaluate(lstm_model, seq2seq_train, seq2seq_valid, learning_rate=learning_rate)\n",
    "#    Mae.append(mae)\n",
    "    \n",
    "\n",
    "#for mae in Mae :\n",
    "#    print(mae)\n",
    "\n",
    "#plt.plot(Mae)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "mae_lstm, mse_lstm = fit_and_evaluate(lstm_model, seq2seq_train, seq2seq_valid,\n",
    "                 learning_rate=0.16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6ba6c2",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8f516338",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code â€“ ensures reproducibility\n",
    "gru_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.GRU(32, return_sequences=True, input_shape=[None, 7]),\n",
    "    tf.keras.layers.Dense(14)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d7f57eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "227/227 [==============================] - 5s 14ms/step - loss: 0.0793 - mae: 0.3010 - mse: 0.1602 - val_loss: 0.0227 - val_mae: 0.1898 - val_mse: 0.0453\n",
      "Epoch 2/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 0.0080 - mae: 0.0958 - mse: 0.0161 - val_loss: 0.0022 - val_mae: 0.0579 - val_mse: 0.0044\n",
      "Epoch 3/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 8.1523e-04 - mae: 0.0306 - mse: 0.0016 - val_loss: 2.0839e-04 - val_mae: 0.0177 - val_mse: 4.1679e-04\n",
      "Epoch 4/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 8.7836e-05 - mae: 0.0099 - mse: 1.7567e-04 - val_loss: 2.3845e-05 - val_mae: 0.0058 - val_mse: 4.7690e-05\n",
      "Epoch 5/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 8.7610e-06 - mae: 0.0032 - mse: 1.7522e-05 - val_loss: 1.9529e-06 - val_mae: 0.0017 - val_mse: 3.9058e-06\n",
      "Epoch 6/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 2.5133e-06 - mae: 0.0017 - mse: 5.0265e-06 - val_loss: 1.2462e-06 - val_mae: 0.0014 - val_mse: 2.4924e-06\n",
      "Epoch 7/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 8.5507e-07 - mae: 0.0011 - mse: 1.7101e-06 - val_loss: 3.7317e-07 - val_mae: 7.5575e-04 - val_mse: 7.4634e-07\n",
      "Epoch 8/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 9.8874e-07 - mae: 0.0011 - mse: 1.9775e-06 - val_loss: 1.5458e-07 - val_mae: 4.7446e-04 - val_mse: 3.0915e-07\n",
      "Epoch 9/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 1.1052e-06 - mae: 0.0011 - mse: 2.2103e-06 - val_loss: 1.7883e-07 - val_mae: 5.0820e-04 - val_mse: 3.5766e-07\n",
      "Epoch 10/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.0760e-06 - mae: 0.0011 - mse: 2.1520e-06 - val_loss: 1.4725e-07 - val_mae: 4.0864e-04 - val_mse: 2.9449e-07\n",
      "Epoch 11/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.7637e-06 - mae: 0.0016 - mse: 3.5273e-06 - val_loss: 1.1385e-06 - val_mae: 0.0014 - val_mse: 2.2771e-06\n",
      "Epoch 12/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 5.2737e-07 - mae: 7.8451e-04 - mse: 1.0547e-06 - val_loss: 1.3970e-07 - val_mae: 3.9700e-04 - val_mse: 2.7939e-07\n",
      "Epoch 13/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.4479e-06 - mae: 0.0014 - mse: 2.8959e-06 - val_loss: 7.4338e-07 - val_mae: 0.0011 - val_mse: 1.4868e-06\n",
      "Epoch 14/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 9.4571e-07 - mae: 0.0011 - mse: 1.8914e-06 - val_loss: 4.6561e-07 - val_mae: 8.6366e-04 - val_mse: 9.3123e-07\n",
      "Epoch 15/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 9.9425e-07 - mae: 0.0012 - mse: 1.9885e-06 - val_loss: 7.9072e-07 - val_mae: 0.0012 - val_mse: 1.5814e-06\n",
      "Epoch 16/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 8.7491e-07 - mae: 0.0011 - mse: 1.7498e-06 - val_loss: 1.1683e-07 - val_mae: 3.9561e-04 - val_mse: 2.3366e-07\n",
      "Epoch 17/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.1584e-06 - mae: 0.0012 - mse: 2.3168e-06 - val_loss: 2.8205e-07 - val_mae: 6.5433e-04 - val_mse: 5.6410e-07\n",
      "Epoch 18/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.1230e-06 - mae: 0.0012 - mse: 2.2459e-06 - val_loss: 3.8535e-07 - val_mae: 7.7962e-04 - val_mse: 7.7070e-07\n",
      "Epoch 19/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 8.5266e-07 - mae: 0.0010 - mse: 1.7053e-06 - val_loss: 2.3100e-07 - val_mae: 5.8326e-04 - val_mse: 4.6199e-07\n",
      "Epoch 20/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.2554e-06 - mae: 0.0013 - mse: 2.5109e-06 - val_loss: 8.0215e-07 - val_mae: 0.0012 - val_mse: 1.6043e-06\n",
      "Epoch 21/1000\n",
      "227/227 [==============================] - 3s 14ms/step - loss: 7.6986e-07 - mae: 9.8714e-04 - mse: 1.5397e-06 - val_loss: 1.4488e-07 - val_mae: 4.6088e-04 - val_mse: 2.8977e-07\n",
      "Epoch 22/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.5698e-06 - mae: 0.0015 - mse: 3.1396e-06 - val_loss: 1.1478e-06 - val_mae: 0.0014 - val_mse: 2.2956e-06\n",
      "Epoch 23/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 7.8239e-07 - mae: 0.0010 - mse: 1.5648e-06 - val_loss: 1.5856e-07 - val_mae: 4.8018e-04 - val_mse: 3.1713e-07\n",
      "Epoch 24/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.1548e-06 - mae: 0.0012 - mse: 2.3095e-06 - val_loss: 5.1570e-07 - val_mae: 9.1344e-04 - val_mse: 1.0314e-06\n",
      "Epoch 25/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 1.1370e-06 - mae: 0.0013 - mse: 2.2740e-06 - val_loss: 1.0650e-06 - val_mae: 0.0014 - val_mse: 2.1299e-06\n",
      "Epoch 26/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 1.1188e-06 - mae: 0.0013 - mse: 2.2376e-06 - val_loss: 3.7621e-07 - val_mae: 7.6916e-04 - val_mse: 7.5242e-07\n",
      "Epoch 27/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 7.3263e-07 - mae: 9.1446e-04 - mse: 1.4653e-06 - val_loss: 1.3149e-07 - val_mae: 3.8783e-04 - val_mse: 2.6298e-07\n",
      "Epoch 28/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.4753e-06 - mae: 0.0014 - mse: 2.9505e-06 - val_loss: 5.0474e-07 - val_mae: 9.0270e-04 - val_mse: 1.0095e-06\n",
      "Epoch 29/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.1117e-06 - mae: 0.0012 - mse: 2.2235e-06 - val_loss: 1.9415e-07 - val_mae: 5.2960e-04 - val_mse: 3.8830e-07\n",
      "Epoch 30/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 9.3604e-07 - mae: 0.0010 - mse: 1.8721e-06 - val_loss: 1.5372e-07 - val_mae: 4.7369e-04 - val_mse: 3.0744e-07\n",
      "Epoch 31/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.1945e-06 - mae: 0.0012 - mse: 2.3889e-06 - val_loss: 2.4985e-07 - val_mae: 6.0993e-04 - val_mse: 4.9970e-07\n",
      "Epoch 32/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.0170e-06 - mae: 0.0011 - mse: 2.0340e-06 - val_loss: 1.8004e-07 - val_mae: 5.0985e-04 - val_mse: 3.6008e-07\n",
      "Epoch 33/1000\n",
      "227/227 [==============================] - 3s 14ms/step - loss: 1.0131e-06 - mae: 0.0011 - mse: 2.0262e-06 - val_loss: 4.2486e-07 - val_mae: 8.2165e-04 - val_mse: 8.4973e-07\n",
      "Epoch 34/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 1.1382e-06 - mae: 0.0013 - mse: 2.2764e-06 - val_loss: 1.1779e-07 - val_mae: 4.0015e-04 - val_mse: 2.3558e-07\n",
      "Epoch 35/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 1.6133e-06 - mae: 0.0015 - mse: 3.2266e-06 - val_loss: 1.1933e-06 - val_mae: 0.0015 - val_mse: 2.3866e-06\n",
      "Epoch 36/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 8.3484e-07 - mae: 0.0011 - mse: 1.6697e-06 - val_loss: 1.6386e-07 - val_mae: 4.8735e-04 - val_mse: 3.2772e-07\n",
      "Epoch 37/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.6997e-06 - mae: 0.0016 - mse: 3.3994e-06 - val_loss: 1.2995e-06 - val_mae: 0.0015 - val_mse: 2.5990e-06\n",
      "Epoch 38/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.0049e-06 - mae: 0.0012 - mse: 2.0098e-06 - val_loss: 1.5481e-07 - val_mae: 4.7518e-04 - val_mse: 3.0961e-07\n",
      "Epoch 39/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.2802e-06 - mae: 0.0013 - mse: 2.5604e-06 - val_loss: 1.2879e-06 - val_mae: 0.0015 - val_mse: 2.5758e-06\n",
      "Epoch 40/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 6.8554e-07 - mae: 9.4013e-04 - mse: 1.3711e-06 - val_loss: 3.3816e-07 - val_mae: 7.2533e-04 - val_mse: 6.7632e-07\n",
      "Epoch 41/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.2094e-06 - mae: 0.0013 - mse: 2.4188e-06 - val_loss: 3.8463e-07 - val_mae: 7.7840e-04 - val_mse: 7.6926e-07\n",
      "Epoch 42/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 9.0259e-07 - mae: 0.0010 - mse: 1.8052e-06 - val_loss: 2.4388e-07 - val_mae: 6.0178e-04 - val_mse: 4.8777e-07\n",
      "Epoch 43/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.0515e-06 - mae: 0.0012 - mse: 2.1029e-06 - val_loss: 4.0238e-07 - val_mae: 7.9814e-04 - val_mse: 8.0477e-07\n",
      "Epoch 44/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 9.8162e-07 - mae: 0.0011 - mse: 1.9632e-06 - val_loss: 6.0897e-07 - val_mae: 0.0010 - val_mse: 1.2179e-06\n",
      "Epoch 45/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 8.0828e-07 - mae: 0.0010 - mse: 1.6166e-06 - val_loss: 2.4787e-07 - val_mae: 6.0742e-04 - val_mse: 4.9574e-07\n",
      "Epoch 46/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 1.0251e-06 - mae: 0.0011 - mse: 2.0501e-06 - val_loss: 2.1424e-07 - val_mae: 5.5853e-04 - val_mse: 4.2849e-07\n",
      "Epoch 47/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 9.9112e-07 - mae: 0.0011 - mse: 1.9822e-06 - val_loss: 1.5282e-07 - val_mae: 4.7242e-04 - val_mse: 3.0565e-07\n",
      "Epoch 48/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 1.0412e-06 - mae: 0.0011 - mse: 2.0824e-06 - val_loss: 3.8090e-07 - val_mae: 7.7462e-04 - val_mse: 7.6179e-07\n",
      "Epoch 49/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.2470e-06 - mae: 0.0013 - mse: 2.4940e-06 - val_loss: 1.6830e-07 - val_mae: 4.9336e-04 - val_mse: 3.3661e-07\n",
      "Epoch 50/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.0293e-06 - mae: 0.0011 - mse: 2.0586e-06 - val_loss: 8.2887e-07 - val_mae: 0.0012 - val_mse: 1.6577e-06\n",
      "Epoch 51/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 8.0404e-07 - mae: 9.9602e-04 - mse: 1.6081e-06 - val_loss: 2.1709e-07 - val_mae: 5.6276e-04 - val_mse: 4.3418e-07\n",
      "Epoch 52/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.1202e-06 - mae: 0.0012 - mse: 2.2405e-06 - val_loss: 1.4073e-07 - val_mae: 4.5435e-04 - val_mse: 2.8146e-07\n",
      "Epoch 53/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.1567e-06 - mae: 0.0012 - mse: 2.3134e-06 - val_loss: 2.3703e-07 - val_mae: 5.9199e-04 - val_mse: 4.7406e-07\n",
      "Epoch 54/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.5370e-06 - mae: 0.0015 - mse: 3.0741e-06 - val_loss: 1.5163e-07 - val_mae: 4.7075e-04 - val_mse: 3.0326e-07\n",
      "Epoch 55/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.5145e-06 - mae: 0.0014 - mse: 3.0291e-06 - val_loss: 4.6976e-07 - val_mae: 8.6774e-04 - val_mse: 9.3951e-07\n",
      "Epoch 56/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 1.1463e-06 - mae: 0.0013 - mse: 2.2927e-06 - val_loss: 3.2561e-07 - val_mae: 7.0991e-04 - val_mse: 6.5122e-07\n",
      "Epoch 57/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.1798e-06 - mae: 0.0013 - mse: 2.3595e-06 - val_loss: 1.1763e-06 - val_mae: 0.0015 - val_mse: 2.3525e-06\n",
      "Epoch 58/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 7.1871e-07 - mae: 9.6926e-04 - mse: 1.4374e-06 - val_loss: 1.4880e-07 - val_mae: 4.6670e-04 - val_mse: 2.9761e-07\n",
      "Epoch 59/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.2629e-06 - mae: 0.0013 - mse: 2.5258e-06 - val_loss: 5.7264e-07 - val_mae: 9.6951e-04 - val_mse: 1.1453e-06\n",
      "Epoch 60/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.0752e-06 - mae: 0.0012 - mse: 2.1505e-06 - val_loss: 7.4630e-07 - val_mae: 0.0011 - val_mse: 1.4926e-06\n",
      "Epoch 61/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 9.7022e-07 - mae: 0.0012 - mse: 1.9404e-06 - val_loss: 4.5997e-07 - val_mae: 8.5758e-04 - val_mse: 9.1993e-07\n",
      "Epoch 62/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 9.5545e-07 - mae: 0.0011 - mse: 1.9109e-06 - val_loss: 2.3146e-07 - val_mae: 5.8393e-04 - val_mse: 4.6293e-07\n",
      "Epoch 63/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 1.5817e-06 - mae: 0.0015 - mse: 3.1634e-06 - val_loss: 1.0022e-06 - val_mae: 0.0013 - val_mse: 2.0043e-06\n",
      "Epoch 64/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 7.9623e-07 - mae: 0.0010 - mse: 1.5925e-06 - val_loss: 5.8843e-07 - val_mae: 9.8483e-04 - val_mse: 1.1769e-06\n",
      "Epoch 65/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.0770e-06 - mae: 0.0012 - mse: 2.1540e-06 - val_loss: 5.4464e-07 - val_mae: 9.4172e-04 - val_mse: 1.0893e-06\n",
      "Epoch 66/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 6.9441e-07 - mae: 9.0839e-04 - mse: 1.3888e-06 - val_loss: 2.5415e-07 - val_mae: 6.1624e-04 - val_mse: 5.0829e-07\n",
      "Epoch 67/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.2345e-06 - mae: 0.0013 - mse: 2.4690e-06 - val_loss: 8.2232e-07 - val_mae: 0.0012 - val_mse: 1.6446e-06\n",
      "Epoch 68/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 9.0696e-07 - mae: 0.0011 - mse: 1.8139e-06 - val_loss: 8.1773e-07 - val_mae: 0.0012 - val_mse: 1.6355e-06\n",
      "Epoch 69/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 8.0279e-07 - mae: 0.0010 - mse: 1.6056e-06 - val_loss: 4.7596e-07 - val_mae: 8.7392e-04 - val_mse: 9.5192e-07\n",
      "Epoch 70/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 8.8515e-07 - mae: 0.0010 - mse: 1.7703e-06 - val_loss: 2.4870e-07 - val_mae: 6.0857e-04 - val_mse: 4.9741e-07\n",
      "Epoch 71/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.4618e-06 - mae: 0.0014 - mse: 2.9237e-06 - val_loss: 1.2897e-06 - val_mae: 0.0015 - val_mse: 2.5793e-06\n",
      "Epoch 72/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 5.9280e-07 - mae: 8.6932e-04 - mse: 1.1856e-06 - val_loss: 3.7291e-07 - val_mae: 7.6430e-04 - val_mse: 7.4581e-07\n",
      "Epoch 73/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.5001e-06 - mae: 0.0015 - mse: 3.0003e-06 - val_loss: 8.3995e-07 - val_mae: 0.0012 - val_mse: 1.6799e-06\n",
      "Epoch 74/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 6.6537e-07 - mae: 9.2057e-04 - mse: 1.3307e-06 - val_loss: 2.2178e-07 - val_mae: 5.6965e-04 - val_mse: 4.4355e-07\n",
      "Epoch 75/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.5923e-06 - mae: 0.0015 - mse: 3.1846e-06 - val_loss: 2.7065e-07 - val_mae: 6.3907e-04 - val_mse: 5.4130e-07\n",
      "Epoch 76/1000\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 1.1695e-06 - mae: 0.0012 - mse: 2.3390e-06 - val_loss: 5.0845e-07 - val_mae: 9.0634e-04 - val_mse: 1.0169e-06\n",
      "Epoch 77/1000\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 1.2931e-06 - mae: 0.0014 - mse: 2.5862e-06 - val_loss: 9.7732e-07 - val_mae: 0.0013 - val_mse: 1.9546e-06\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.3149e-07 - mae: 3.8783e-04 - mse: 2.6298e-07\n"
     ]
    }
   ],
   "source": [
    "# BEST LEARNING_RATE = 15 * 0.01 + 0.15\n",
    "\n",
    "#min_learning_rate = 0.15\n",
    "#max_learning_rate = 0.4\n",
    "#step = 0.01\n",
    "\n",
    "#Mae = []\n",
    "\n",
    "#for learning_rate in np.arange(min_learning_rate, max_learning_rate + step, step):\n",
    "#    mae = fit_and_evaluate(gru_model, seq2seq_train, seq2seq_valid, learning_rate=learning_rate)\n",
    "#    Mae.append(mae)\n",
    "    \n",
    "\n",
    "#for mae in Mae :\n",
    "#    print(mae)\n",
    "\n",
    "#plt.plot(Mae)\n",
    "#plt.show()\n",
    "\n",
    "mae_gru, mse_gru = fit_and_evaluate(gru_model, seq2seq_train, seq2seq_valid,\n",
    "                 learning_rate=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9b676d",
   "metadata": {},
   "source": [
    "# Using One-Dimensional Convolutional Layers to Process Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "07c0b937",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code â€“ ensures reproducibility\n",
    "conv_rnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=4, strides=2,\n",
    "                           activation=\"relu\", input_shape=[None, 7]),\n",
    "    tf.keras.layers.GRU(32, return_sequences=True),\n",
    "    tf.keras.layers.Dense(14)\n",
    "])\n",
    "\n",
    "longer_train = to_seq2seq_dataset(mulvar_train, seq_length=112,\n",
    "                                       shuffle=True, seed=42)\n",
    "longer_valid = to_seq2seq_dataset(mulvar_valid, seq_length=112)\n",
    "downsampled_train = longer_train.map(lambda X, Y: (X, Y[:, 3::2]))\n",
    "downsampled_valid = longer_valid.map(lambda X, Y: (X, Y[:, 3::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4531dd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "225/225 [==============================] - 5s 16ms/step - loss: 1.1005e-06 - mae: 0.0011 - mse: 2.2009e-06 - val_loss: 4.4812e-07 - val_mae: 7.6977e-04 - val_mse: 8.9623e-07\n",
      "Epoch 2/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.3724e-06 - mae: 0.0013 - mse: 2.7448e-06 - val_loss: 5.4277e-07 - val_mae: 9.3236e-04 - val_mse: 1.0855e-06\n",
      "Epoch 3/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 9.8345e-07 - mae: 0.0011 - mse: 1.9669e-06 - val_loss: 4.1591e-07 - val_mae: 8.0759e-04 - val_mse: 8.3182e-07\n",
      "Epoch 4/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.1471e-06 - mae: 0.0013 - mse: 2.2941e-06 - val_loss: 4.9488e-07 - val_mae: 8.8823e-04 - val_mse: 9.8976e-07\n",
      "Epoch 5/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 9.2404e-07 - mae: 0.0011 - mse: 1.8481e-06 - val_loss: 2.5370e-07 - val_mae: 6.1366e-04 - val_mse: 5.0741e-07\n",
      "Epoch 6/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.1180e-06 - mae: 0.0012 - mse: 2.2360e-06 - val_loss: 1.9673e-07 - val_mae: 5.3162e-04 - val_mse: 3.9346e-07\n",
      "Epoch 7/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.2018e-06 - mae: 0.0013 - mse: 2.4037e-06 - val_loss: 4.9969e-07 - val_mae: 8.9311e-04 - val_mse: 9.9939e-07\n",
      "Epoch 8/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 8.2510e-07 - mae: 9.8746e-04 - mse: 1.6502e-06 - val_loss: 1.2423e-07 - val_mae: 4.2346e-04 - val_mse: 2.4847e-07\n",
      "Epoch 9/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.4798e-06 - mae: 0.0014 - mse: 2.9596e-06 - val_loss: 6.4939e-07 - val_mae: 0.0010 - val_mse: 1.2988e-06\n",
      "Epoch 10/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 8.5424e-07 - mae: 0.0010 - mse: 1.7085e-06 - val_loss: 3.4479e-07 - val_mae: 7.2984e-04 - val_mse: 6.8958e-07\n",
      "Epoch 11/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.0029e-06 - mae: 0.0011 - mse: 2.0058e-06 - val_loss: 1.3342e-07 - val_mae: 4.4381e-04 - val_mse: 2.6684e-07\n",
      "Epoch 12/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.3796e-06 - mae: 0.0014 - mse: 2.7592e-06 - val_loss: 5.1681e-07 - val_mae: 9.1036e-04 - val_mse: 1.0336e-06\n",
      "Epoch 13/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 8.2647e-07 - mae: 0.0010 - mse: 1.6529e-06 - val_loss: 2.9251e-07 - val_mae: 6.6553e-04 - val_mse: 5.8502e-07\n",
      "Epoch 14/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.2313e-06 - mae: 0.0013 - mse: 2.4625e-06 - val_loss: 2.4514e-07 - val_mae: 6.0152e-04 - val_mse: 4.9027e-07\n",
      "Epoch 15/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.2236e-06 - mae: 0.0013 - mse: 2.4473e-06 - val_loss: 4.7094e-07 - val_mae: 8.6423e-04 - val_mse: 9.4187e-07\n",
      "Epoch 16/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 9.3272e-07 - mae: 0.0011 - mse: 1.8654e-06 - val_loss: 3.4517e-07 - val_mae: 7.3034e-04 - val_mse: 6.9033e-07\n",
      "Epoch 17/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.0697e-06 - mae: 0.0012 - mse: 2.1393e-06 - val_loss: 3.4073e-07 - val_mae: 7.2508e-04 - val_mse: 6.8147e-07\n",
      "Epoch 18/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 9.6847e-07 - mae: 0.0011 - mse: 1.9369e-06 - val_loss: 3.0622e-07 - val_mae: 6.8302e-04 - val_mse: 6.1244e-07\n",
      "Epoch 19/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.1372e-06 - mae: 0.0012 - mse: 2.2745e-06 - val_loss: 6.2075e-07 - val_mae: 0.0010 - val_mse: 1.2415e-06\n",
      "Epoch 20/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 9.8790e-07 - mae: 0.0012 - mse: 1.9758e-06 - val_loss: 5.7548e-07 - val_mae: 9.6844e-04 - val_mse: 1.1510e-06\n",
      "Epoch 21/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 9.4555e-07 - mae: 0.0011 - mse: 1.8911e-06 - val_loss: 2.9351e-07 - val_mae: 6.6705e-04 - val_mse: 5.8703e-07\n",
      "Epoch 22/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.2804e-06 - mae: 0.0014 - mse: 2.5608e-06 - val_loss: 7.4668e-07 - val_mae: 0.0011 - val_mse: 1.4934e-06\n",
      "Epoch 23/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 9.3361e-07 - mae: 0.0011 - mse: 1.8672e-06 - val_loss: 3.9473e-07 - val_mae: 7.8545e-04 - val_mse: 7.8945e-07\n",
      "Epoch 24/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 9.5798e-07 - mae: 0.0011 - mse: 1.9160e-06 - val_loss: 2.1824e-07 - val_mae: 5.6287e-04 - val_mse: 4.3649e-07\n",
      "Epoch 25/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.1795e-06 - mae: 0.0012 - mse: 2.3590e-06 - val_loss: 2.5504e-07 - val_mae: 6.1541e-04 - val_mse: 5.1008e-07\n",
      "Epoch 26/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.0287e-06 - mae: 0.0012 - mse: 2.0575e-06 - val_loss: 3.6298e-07 - val_mae: 7.5027e-04 - val_mse: 7.2595e-07\n",
      "Epoch 27/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.1361e-06 - mae: 0.0012 - mse: 2.2722e-06 - val_loss: 4.0688e-07 - val_mae: 7.9862e-04 - val_mse: 8.1377e-07\n",
      "Epoch 28/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.0476e-06 - mae: 0.0012 - mse: 2.0952e-06 - val_loss: 6.5077e-07 - val_mae: 0.0010 - val_mse: 1.3015e-06\n",
      "Epoch 29/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 7.5500e-07 - mae: 9.5213e-04 - mse: 1.5100e-06 - val_loss: 1.9355e-07 - val_mae: 5.2710e-04 - val_mse: 3.8710e-07\n",
      "Epoch 30/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.1590e-06 - mae: 0.0012 - mse: 2.3180e-06 - val_loss: 3.1523e-07 - val_mae: 6.9414e-04 - val_mse: 6.3046e-07\n",
      "Epoch 31/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.0062e-06 - mae: 0.0011 - mse: 2.0123e-06 - val_loss: 1.8066e-07 - val_mae: 5.0906e-04 - val_mse: 3.6133e-07\n",
      "Epoch 32/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.2316e-06 - mae: 0.0013 - mse: 2.4633e-06 - val_loss: 4.0259e-07 - val_mae: 7.9301e-04 - val_mse: 8.0518e-07\n",
      "Epoch 33/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.1400e-06 - mae: 0.0012 - mse: 2.2799e-06 - val_loss: 4.4362e-07 - val_mae: 8.3668e-04 - val_mse: 8.8725e-07\n",
      "Epoch 34/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 9.3072e-07 - mae: 0.0011 - mse: 1.8614e-06 - val_loss: 2.5301e-07 - val_mae: 6.1264e-04 - val_mse: 5.0601e-07\n",
      "Epoch 35/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.1088e-06 - mae: 0.0012 - mse: 2.2177e-06 - val_loss: 2.7533e-07 - val_mae: 6.4306e-04 - val_mse: 5.5067e-07\n",
      "Epoch 36/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.1615e-06 - mae: 0.0013 - mse: 2.3231e-06 - val_loss: 6.9764e-07 - val_mae: 0.0011 - val_mse: 1.3953e-06\n",
      "Epoch 37/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 9.0830e-07 - mae: 0.0011 - mse: 1.8166e-06 - val_loss: 4.2183e-07 - val_mae: 8.1426e-04 - val_mse: 8.4366e-07\n",
      "Epoch 38/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 9.5391e-07 - mae: 0.0011 - mse: 1.9078e-06 - val_loss: 2.4536e-07 - val_mae: 6.0190e-04 - val_mse: 4.9073e-07\n",
      "Epoch 39/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.1459e-07 - mae: 0.0010 - mse: 1.8292e-06 - val_loss: 1.6630e-07 - val_mae: 4.8953e-04 - val_mse: 3.3261e-07\n",
      "Epoch 40/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.4437e-06 - mae: 0.0014 - mse: 2.8875e-06 - val_loss: 8.7813e-07 - val_mae: 0.0012 - val_mse: 1.7563e-06\n",
      "Epoch 41/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 8.6632e-07 - mae: 0.0011 - mse: 1.7326e-06 - val_loss: 2.0680e-07 - val_mae: 5.4614e-04 - val_mse: 4.1361e-07\n",
      "Epoch 42/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.1535e-06 - mae: 0.0012 - mse: 2.3070e-06 - val_loss: 4.3236e-07 - val_mae: 8.2491e-04 - val_mse: 8.6472e-07\n",
      "Epoch 43/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.0592e-06 - mae: 0.0012 - mse: 2.1185e-06 - val_loss: 5.1358e-07 - val_mae: 9.0700e-04 - val_mse: 1.0272e-06\n",
      "Epoch 44/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.1035e-06 - mae: 0.0012 - mse: 2.2070e-06 - val_loss: 4.7376e-07 - val_mae: 8.6700e-04 - val_mse: 9.4752e-07\n",
      "Epoch 45/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.0826e-06 - mae: 0.0012 - mse: 2.1653e-06 - val_loss: 6.5904e-07 - val_mae: 0.0010 - val_mse: 1.3181e-06\n",
      "Epoch 46/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 8.0842e-07 - mae: 0.0010 - mse: 1.6168e-06 - val_loss: 3.4032e-07 - val_mae: 7.2443e-04 - val_mse: 6.8065e-07\n",
      "Epoch 47/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.0212e-06 - mae: 0.0011 - mse: 2.0424e-06 - val_loss: 4.1717e-07 - val_mae: 8.0944e-04 - val_mse: 8.3434e-07\n",
      "Epoch 48/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.0793e-06 - mae: 0.0012 - mse: 2.1585e-06 - val_loss: 4.5283e-07 - val_mae: 8.4578e-04 - val_mse: 9.0567e-07\n",
      "Epoch 49/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.0309e-06 - mae: 0.0012 - mse: 2.0619e-06 - val_loss: 3.8970e-07 - val_mae: 7.7998e-04 - val_mse: 7.7940e-07\n",
      "Epoch 50/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.8079e-07 - mae: 0.0011 - mse: 1.9616e-06 - val_loss: 3.6239e-07 - val_mae: 7.4988e-04 - val_mse: 7.2479e-07\n",
      "Epoch 51/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.0137e-06 - mae: 0.0012 - mse: 2.0275e-06 - val_loss: 6.4843e-07 - val_mae: 0.0010 - val_mse: 1.2969e-06\n",
      "Epoch 52/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 9.5506e-07 - mae: 0.0011 - mse: 1.9101e-06 - val_loss: 4.1172e-07 - val_mae: 8.0348e-04 - val_mse: 8.2344e-07\n",
      "Epoch 53/1000\n",
      "  5/225 [..............................] - ETA: 2s - loss: 1.5932e-06 - mae: 0.0015 - mse: 3.1865e-06 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[186], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mae_conv, mse_conv \u001b[38;5;241m=\u001b[39m fit_and_evaluate(conv_rnn_model, downsampled_train, downsampled_valid,\n\u001b[0;32m      2\u001b[0m                  learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.185\u001b[39m)\n",
      "Cell \u001b[1;32mIn[132], line 6\u001b[0m, in \u001b[0;36mfit_and_evaluate\u001b[1;34m(model, train_set, valid_set, learning_rate, epochs)\u001b[0m\n\u001b[0;32m      4\u001b[0m opt \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.99\u001b[39m)\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mHuber(), optimizer\u001b[38;5;241m=\u001b[39mopt, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train_set, validation_data\u001b[38;5;241m=\u001b[39mvalid_set, epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m      7\u001b[0m                     callbacks\u001b[38;5;241m=\u001b[39m[early_stopping_cb])\n\u001b[0;32m      8\u001b[0m valid_loss, valid_mae,valid_mse \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(valid_set)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m valid_mae \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1e6\u001b[39m, valid_mse \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1e6\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\Lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mae_conv, mse_conv = fit_and_evaluate(conv_rnn_model, downsampled_train, downsampled_valid,\n",
    "                 learning_rate=0.185)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "66853ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394.334812881425\n",
      "0.2551224440594524\n"
     ]
    }
   ],
   "source": [
    "print(mae_conv)\n",
    "print(mse_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21511d0e",
   "metadata": {},
   "source": [
    "# WaveNet - Bis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "90ee30d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedActivationUnit(tf.keras.layers.Layer):\n",
    "    def __init__(self, activation=\"tanh\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        n_filters = inputs.shape[-1] // 2\n",
    "        linear_output = self.activation(inputs[..., :n_filters])\n",
    "        gate = tf.keras.activations.sigmoid(inputs[..., n_filters:])\n",
    "        return self.activation(linear_output) * gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1142065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavenet_residual_block(inputs, n_filters, dilation_rate):\n",
    "    z = tf.keras.layers.Conv1D(2 * n_filters, kernel_size=2, padding=\"causal\",\n",
    "                            dilation_rate=dilation_rate)(inputs)\n",
    "    z = GatedActivationUnit()(z)\n",
    "    z = tf.keras.layers.Conv1D(n_filters, kernel_size=1)(z)\n",
    "    return tf.keras.layers.Add()([z, inputs]), z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9f3a0302",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "n_layers_per_block = 3  # 10 in the paper\n",
    "n_blocks = 1  # 3 in the paper\n",
    "n_filters = 3  # 128 in the paper\n",
    "n_outputs = 14  # 256 in the paper\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=[None, 7])\n",
    "z = tf.keras.layers.Conv1D(n_filters, kernel_size=2, padding=\"causal\")(inputs)\n",
    "skip_to_last = []\n",
    "for dilation_rate in [2**i for i in range(n_layers_per_block)] * n_blocks:\n",
    "    z, skip = wavenet_residual_block(z, n_filters, dilation_rate)\n",
    "    skip_to_last.append(skip)\n",
    "\n",
    "z = tf.keras.activations.relu(tf.keras.layers.Add()(skip_to_last))\n",
    "z = tf.keras.layers.Conv1D(n_filters, kernel_size=1, activation=\"relu\")(z)\n",
    "Y_preds = tf.keras.layers.Conv1D(n_outputs, kernel_size=1)(z)\n",
    "\n",
    "full_wavenet_model = tf.keras.Model(inputs=[inputs], outputs=[Y_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0af40872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "225/225 [==============================] - 3s 9ms/step - loss: 1.4024e-04 - mae: 0.0129 - mse: 2.8047e-04 - val_loss: 4.4277e-06 - val_mae: 0.0026 - val_mse: 8.8553e-06\n",
      "Epoch 2/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 1.3469e-05 - mae: 0.0041 - mse: 2.6939e-05 - val_loss: 2.8114e-06 - val_mae: 0.0022 - val_mse: 5.6228e-06\n",
      "Epoch 3/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 2.6922e-06 - mae: 0.0017 - mse: 5.3845e-06 - val_loss: 7.7415e-07 - val_mae: 0.0010 - val_mse: 1.5483e-06\n",
      "Epoch 4/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.7981e-06 - mae: 0.0014 - mse: 3.5961e-06 - val_loss: 2.5035e-07 - val_mae: 5.6344e-04 - val_mse: 5.0069e-07\n",
      "Epoch 5/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5759e-06 - mae: 0.0013 - mse: 3.1518e-06 - val_loss: 1.6335e-07 - val_mae: 4.3668e-04 - val_mse: 3.2670e-07\n",
      "Epoch 6/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5526e-06 - mae: 0.0013 - mse: 3.1051e-06 - val_loss: 1.7195e-07 - val_mae: 4.4606e-04 - val_mse: 3.4391e-07\n",
      "Epoch 7/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5959e-06 - mae: 0.0014 - mse: 3.1917e-06 - val_loss: 1.9860e-07 - val_mae: 4.8712e-04 - val_mse: 3.9720e-07\n",
      "Epoch 8/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.6542e-06 - mae: 0.0014 - mse: 3.3084e-06 - val_loss: 1.8517e-07 - val_mae: 4.6686e-04 - val_mse: 3.7035e-07\n",
      "Epoch 9/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.6426e-06 - mae: 0.0014 - mse: 3.2853e-06 - val_loss: 2.2032e-07 - val_mae: 5.1798e-04 - val_mse: 4.4064e-07\n",
      "Epoch 10/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.7061e-06 - mae: 0.0014 - mse: 3.4122e-06 - val_loss: 2.5232e-07 - val_mae: 5.6094e-04 - val_mse: 5.0463e-07\n",
      "Epoch 11/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.7679e-06 - mae: 0.0015 - mse: 3.5357e-06 - val_loss: 3.2003e-07 - val_mae: 6.4922e-04 - val_mse: 6.4006e-07\n",
      "Epoch 12/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.7948e-06 - mae: 0.0014 - mse: 3.5896e-06 - val_loss: 2.2897e-07 - val_mae: 5.2982e-04 - val_mse: 4.5794e-07\n",
      "Epoch 13/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.7426e-06 - mae: 0.0014 - mse: 3.4853e-06 - val_loss: 2.6422e-07 - val_mae: 5.7655e-04 - val_mse: 5.2843e-07\n",
      "Epoch 14/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.7471e-06 - mae: 0.0014 - mse: 3.4942e-06 - val_loss: 2.2251e-07 - val_mae: 5.2108e-04 - val_mse: 4.4503e-07\n",
      "Epoch 15/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.7096e-06 - mae: 0.0014 - mse: 3.4191e-06 - val_loss: 2.1292e-07 - val_mae: 5.0770e-04 - val_mse: 4.2584e-07\n",
      "Epoch 16/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.6404e-06 - mae: 0.0014 - mse: 3.2808e-06 - val_loss: 1.4256e-07 - val_mae: 4.0358e-04 - val_mse: 2.8512e-07\n",
      "Epoch 17/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5074e-06 - mae: 0.0013 - mse: 3.0148e-06 - val_loss: 1.3467e-07 - val_mae: 3.9699e-04 - val_mse: 2.6934e-07\n",
      "Epoch 18/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5026e-06 - mae: 0.0013 - mse: 3.0052e-06 - val_loss: 1.7099e-07 - val_mae: 4.4452e-04 - val_mse: 3.4197e-07\n",
      "Epoch 19/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5909e-06 - mae: 0.0014 - mse: 3.1819e-06 - val_loss: 1.9493e-07 - val_mae: 4.8167e-04 - val_mse: 3.8985e-07\n",
      "Epoch 20/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.6541e-06 - mae: 0.0014 - mse: 3.3083e-06 - val_loss: 1.9104e-07 - val_mae: 4.7570e-04 - val_mse: 3.8207e-07\n",
      "Epoch 21/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5719e-06 - mae: 0.0013 - mse: 3.1437e-06 - val_loss: 1.4607e-07 - val_mae: 4.0759e-04 - val_mse: 2.9214e-07\n",
      "Epoch 22/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.4652e-06 - mae: 0.0013 - mse: 2.9304e-06 - val_loss: 1.8295e-07 - val_mae: 4.6338e-04 - val_mse: 3.6589e-07\n",
      "Epoch 23/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5907e-06 - mae: 0.0014 - mse: 3.1815e-06 - val_loss: 1.7666e-07 - val_mae: 4.5352e-04 - val_mse: 3.5332e-07\n",
      "Epoch 24/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.6411e-06 - mae: 0.0014 - mse: 3.2821e-06 - val_loss: 2.0848e-07 - val_mae: 5.0147e-04 - val_mse: 4.1696e-07\n",
      "Epoch 25/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.6549e-06 - mae: 0.0014 - mse: 3.3097e-06 - val_loss: 2.0763e-07 - val_mae: 5.0026e-04 - val_mse: 4.1527e-07\n",
      "Epoch 26/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.7025e-06 - mae: 0.0014 - mse: 3.4051e-06 - val_loss: 2.0909e-07 - val_mae: 5.0227e-04 - val_mse: 4.1818e-07\n",
      "Epoch 27/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.6505e-06 - mae: 0.0014 - mse: 3.3010e-06 - val_loss: 2.0106e-07 - val_mae: 4.9066e-04 - val_mse: 4.0211e-07\n",
      "Epoch 28/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5942e-06 - mae: 0.0014 - mse: 3.1884e-06 - val_loss: 1.6603e-07 - val_mae: 4.3666e-04 - val_mse: 3.3205e-07\n",
      "Epoch 29/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5949e-06 - mae: 0.0014 - mse: 3.1898e-06 - val_loss: 1.9775e-07 - val_mae: 4.8583e-04 - val_mse: 3.9550e-07\n",
      "Epoch 30/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.6204e-06 - mae: 0.0014 - mse: 3.2408e-06 - val_loss: 2.2140e-07 - val_mae: 5.1957e-04 - val_mse: 4.4281e-07\n",
      "Epoch 31/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.6483e-06 - mae: 0.0014 - mse: 3.2966e-06 - val_loss: 1.7318e-07 - val_mae: 4.4798e-04 - val_mse: 3.4635e-07\n",
      "Epoch 32/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5936e-06 - mae: 0.0014 - mse: 3.1872e-06 - val_loss: 1.8087e-07 - val_mae: 4.6013e-04 - val_mse: 3.6174e-07\n",
      "Epoch 33/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5811e-06 - mae: 0.0013 - mse: 3.1622e-06 - val_loss: 1.6667e-07 - val_mae: 4.3769e-04 - val_mse: 3.3335e-07\n",
      "Epoch 34/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5871e-06 - mae: 0.0014 - mse: 3.1741e-06 - val_loss: 1.7403e-07 - val_mae: 4.4932e-04 - val_mse: 3.4806e-07\n",
      "Epoch 35/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.6054e-06 - mae: 0.0014 - mse: 3.2109e-06 - val_loss: 2.2837e-07 - val_mae: 5.2901e-04 - val_mse: 4.5673e-07\n",
      "Epoch 36/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.6910e-06 - mae: 0.0014 - mse: 3.3820e-06 - val_loss: 1.9002e-07 - val_mae: 4.7432e-04 - val_mse: 3.8004e-07\n",
      "Epoch 37/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5969e-06 - mae: 0.0014 - mse: 3.1937e-06 - val_loss: 1.5697e-07 - val_mae: 4.2253e-04 - val_mse: 3.1394e-07\n",
      "Epoch 38/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5209e-06 - mae: 0.0013 - mse: 3.0417e-06 - val_loss: 1.5530e-07 - val_mae: 4.2003e-04 - val_mse: 3.1060e-07\n",
      "Epoch 39/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.4837e-06 - mae: 0.0013 - mse: 2.9674e-06 - val_loss: 1.4822e-07 - val_mae: 4.1019e-04 - val_mse: 2.9644e-07\n",
      "Epoch 40/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5435e-06 - mae: 0.0013 - mse: 3.0871e-06 - val_loss: 1.9280e-07 - val_mae: 4.7843e-04 - val_mse: 3.8560e-07\n",
      "Epoch 41/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 1.6483e-06 - mae: 0.0014 - mse: 3.2967e-06 - val_loss: 1.9872e-07 - val_mae: 4.8726e-04 - val_mse: 3.9744e-07\n",
      "Epoch 42/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 1.6186e-06 - mae: 0.0014 - mse: 3.2373e-06 - val_loss: 1.5742e-07 - val_mae: 4.2326e-04 - val_mse: 3.1484e-07\n",
      "Epoch 43/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5650e-06 - mae: 0.0014 - mse: 3.1300e-06 - val_loss: 1.8283e-07 - val_mae: 4.6322e-04 - val_mse: 3.6567e-07\n",
      "Epoch 44/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5673e-06 - mae: 0.0013 - mse: 3.1346e-06 - val_loss: 1.4614e-07 - val_mae: 4.0754e-04 - val_mse: 2.9229e-07\n",
      "Epoch 45/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5456e-06 - mae: 0.0013 - mse: 3.0913e-06 - val_loss: 1.9327e-07 - val_mae: 4.7921e-04 - val_mse: 3.8653e-07\n",
      "Epoch 46/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.6360e-06 - mae: 0.0014 - mse: 3.2720e-06 - val_loss: 2.2443e-07 - val_mae: 5.2366e-04 - val_mse: 4.4886e-07\n",
      "Epoch 47/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.7296e-06 - mae: 0.0014 - mse: 3.4591e-06 - val_loss: 2.6613e-07 - val_mae: 5.7906e-04 - val_mse: 5.3226e-07\n",
      "Epoch 48/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 1.7971e-06 - mae: 0.0015 - mse: 3.5942e-06 - val_loss: 2.6093e-07 - val_mae: 5.7229e-04 - val_mse: 5.2187e-07\n",
      "Epoch 49/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 1.7849e-06 - mae: 0.0015 - mse: 3.5697e-06 - val_loss: 2.8877e-07 - val_mae: 6.0865e-04 - val_mse: 5.7755e-07\n",
      "Epoch 50/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.7854e-06 - mae: 0.0015 - mse: 3.5707e-06 - val_loss: 2.7144e-07 - val_mae: 5.8600e-04 - val_mse: 5.4288e-07\n",
      "Epoch 51/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.7296e-06 - mae: 0.0014 - mse: 3.4591e-06 - val_loss: 2.2836e-07 - val_mae: 5.2911e-04 - val_mse: 4.5673e-07\n",
      "Epoch 52/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.7403e-06 - mae: 0.0014 - mse: 3.4806e-06 - val_loss: 2.3605e-07 - val_mae: 5.3950e-04 - val_mse: 4.7210e-07\n",
      "Epoch 53/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.6998e-06 - mae: 0.0014 - mse: 3.3996e-06 - val_loss: 1.9715e-07 - val_mae: 4.8499e-04 - val_mse: 3.9430e-07\n",
      "Epoch 54/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5621e-06 - mae: 0.0013 - mse: 3.1242e-06 - val_loss: 1.4771e-07 - val_mae: 4.0952e-04 - val_mse: 2.9542e-07\n",
      "Epoch 55/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5486e-06 - mae: 0.0013 - mse: 3.0971e-06 - val_loss: 1.9705e-07 - val_mae: 4.8490e-04 - val_mse: 3.9410e-07\n",
      "Epoch 56/1000\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 1.6167e-06 - mae: 0.0014 - mse: 3.2333e-06 - val_loss: 1.4874e-07 - val_mae: 4.1079e-04 - val_mse: 2.9749e-07\n",
      "Epoch 57/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.4634e-06 - mae: 0.0013 - mse: 2.9269e-06 - val_loss: 1.4831e-07 - val_mae: 4.1036e-04 - val_mse: 2.9661e-07\n",
      "Epoch 58/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5220e-06 - mae: 0.0013 - mse: 3.0441e-06 - val_loss: 1.5422e-07 - val_mae: 4.1856e-04 - val_mse: 3.0844e-07\n",
      "Epoch 59/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5214e-06 - mae: 0.0013 - mse: 3.0427e-06 - val_loss: 1.3653e-07 - val_mae: 3.9824e-04 - val_mse: 2.7306e-07\n",
      "Epoch 60/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.4610e-06 - mae: 0.0013 - mse: 2.9219e-06 - val_loss: 1.5096e-07 - val_mae: 4.1383e-04 - val_mse: 3.0191e-07\n",
      "Epoch 61/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.4895e-06 - mae: 0.0013 - mse: 2.9789e-06 - val_loss: 1.6797e-07 - val_mae: 4.3974e-04 - val_mse: 3.3595e-07\n",
      "Epoch 62/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5782e-06 - mae: 0.0014 - mse: 3.1564e-06 - val_loss: 1.6435e-07 - val_mae: 4.3401e-04 - val_mse: 3.2870e-07\n",
      "Epoch 63/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.5728e-06 - mae: 0.0014 - mse: 3.1456e-06 - val_loss: 1.9153e-07 - val_mae: 4.7658e-04 - val_mse: 3.8306e-07\n",
      "Epoch 64/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.6820e-06 - mae: 0.0014 - mse: 3.3641e-06 - val_loss: 2.3295e-07 - val_mae: 5.3524e-04 - val_mse: 4.6590e-07\n",
      "Epoch 65/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.6975e-06 - mae: 0.0014 - mse: 3.3950e-06 - val_loss: 1.8139e-07 - val_mae: 4.6095e-04 - val_mse: 3.6278e-07\n",
      "Epoch 66/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.6221e-06 - mae: 0.0014 - mse: 3.2443e-06 - val_loss: 2.0390e-07 - val_mae: 4.9488e-04 - val_mse: 4.0779e-07\n",
      "Epoch 67/1000\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.6678e-06 - mae: 0.0014 - mse: 3.3356e-06 - val_loss: 2.4276e-07 - val_mae: 5.4836e-04 - val_mse: 4.8552e-07\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.3467e-07 - mae: 3.9699e-04 - mse: 2.6934e-07\n"
     ]
    }
   ],
   "source": [
    "# BEST LEARNING_RATE = 30 * 0.01 + 0.15\n",
    "\n",
    "#min_learning_rate = 0.15\n",
    "#max_learning_rate = 0.5\n",
    "#step = 0.01\n",
    "\n",
    "#Mae = []\n",
    "\n",
    "#for learning_rate in np.arange(min_learning_rate, max_learning_rate + step, step):\n",
    "#    mae = fit_and_evaluate(full_wavenet_model, longer_train, longer_valid, learning_rate=learning_rate)\n",
    "#    Mae.append(mae)\n",
    "    \n",
    "\n",
    "#for mae in Mae :\n",
    "#    print(mae)\n",
    "\n",
    "#plt.plot(Mae)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "mae_wave, mse_wave = fit_and_evaluate(full_wavenet_model, longer_train, longer_valid,\n",
    "                 learning_rate=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49365d61",
   "metadata": {},
   "source": [
    "# LSTM - Version youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "26709525",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code â€“ ensures reproducibility\n",
    "yt_model1 = tf.keras.Sequential([\n",
    "    #tf.keras.layers.LSTM(200, return_sequences=True, input_shape=[None, 7]),\n",
    "    #tf.keras.layers.Dropout(0.2),\n",
    "    #tf.keras.layers.LSTM(200),\n",
    "    #tf.keras.layers.Dropout(0.2),\n",
    "    #tf.keras.layers.Dense(14)\n",
    "    \n",
    "    tf.keras.layers.GRU(200, return_sequences=True, input_shape=[None, 7]),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.GRU(200, return_sequences=True),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.GRU(200, return_sequences=True),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(14)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "aeedfd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "227/227 [==============================] - 72s 301ms/step - loss: 0.0236 - mae: 0.1508 - mse: 0.0477 - val_loss: 8.0748e-04 - val_mae: 0.0330 - val_mse: 0.0016\n",
      "Epoch 2/1000\n",
      "227/227 [==============================] - 68s 298ms/step - loss: 6.2208e-04 - mae: 0.0259 - mse: 0.0012 - val_loss: 1.3895e-05 - val_mae: 0.0042 - val_mse: 2.7790e-05\n",
      "Epoch 3/1000\n",
      "227/227 [==============================] - 67s 294ms/step - loss: 6.7591e-05 - mae: 0.0088 - mse: 1.3518e-04 - val_loss: 2.5209e-06 - val_mae: 0.0019 - val_mse: 5.0417e-06\n",
      "Epoch 4/1000\n",
      "227/227 [==============================] - 67s 297ms/step - loss: 2.5623e-05 - mae: 0.0054 - mse: 5.1245e-05 - val_loss: 2.0718e-06 - val_mae: 0.0016 - val_mse: 4.1436e-06\n",
      "Epoch 5/1000\n",
      "227/227 [==============================] - 69s 303ms/step - loss: 1.6217e-05 - mae: 0.0043 - mse: 3.2434e-05 - val_loss: 1.5830e-06 - val_mae: 0.0015 - val_mse: 3.1661e-06\n",
      "Epoch 6/1000\n",
      "227/227 [==============================] - 68s 301ms/step - loss: 1.2724e-05 - mae: 0.0039 - mse: 2.5448e-05 - val_loss: 1.1334e-06 - val_mae: 0.0012 - val_mse: 2.2669e-06\n",
      "Epoch 7/1000\n",
      "227/227 [==============================] - 69s 301ms/step - loss: 1.0380e-05 - mae: 0.0035 - mse: 2.0761e-05 - val_loss: 6.4127e-07 - val_mae: 9.3684e-04 - val_mse: 1.2825e-06\n",
      "Epoch 8/1000\n",
      "227/227 [==============================] - 70s 307ms/step - loss: 8.7799e-06 - mae: 0.0032 - mse: 1.7560e-05 - val_loss: 3.8420e-07 - val_mae: 6.5369e-04 - val_mse: 7.6840e-07\n",
      "Epoch 9/1000\n",
      "227/227 [==============================] - 70s 309ms/step - loss: 7.6963e-06 - mae: 0.0030 - mse: 1.5393e-05 - val_loss: 5.3627e-07 - val_mae: 8.6747e-04 - val_mse: 1.0725e-06\n",
      "Epoch 10/1000\n",
      "227/227 [==============================] - 68s 301ms/step - loss: 7.1807e-06 - mae: 0.0029 - mse: 1.4361e-05 - val_loss: 5.5761e-07 - val_mae: 8.7330e-04 - val_mse: 1.1152e-06\n",
      "Epoch 11/1000\n",
      "227/227 [==============================] - 69s 304ms/step - loss: 6.5838e-06 - mae: 0.0028 - mse: 1.3168e-05 - val_loss: 7.2779e-07 - val_mae: 0.0010 - val_mse: 1.4556e-06\n",
      "Epoch 12/1000\n",
      "227/227 [==============================] - 67s 296ms/step - loss: 5.9775e-06 - mae: 0.0027 - mse: 1.1955e-05 - val_loss: 1.0651e-06 - val_mae: 0.0012 - val_mse: 2.1302e-06\n",
      "Epoch 13/1000\n",
      "227/227 [==============================] - 67s 296ms/step - loss: 5.6834e-06 - mae: 0.0026 - mse: 1.1367e-05 - val_loss: 1.3816e-06 - val_mae: 0.0013 - val_mse: 2.7633e-06\n",
      "Epoch 14/1000\n",
      "227/227 [==============================] - 67s 295ms/step - loss: 5.0985e-06 - mae: 0.0025 - mse: 1.0197e-05 - val_loss: 7.2021e-07 - val_mae: 9.0583e-04 - val_mse: 1.4404e-06\n",
      "Epoch 15/1000\n",
      "227/227 [==============================] - 68s 297ms/step - loss: 4.4408e-06 - mae: 0.0023 - mse: 8.8816e-06 - val_loss: 4.2988e-07 - val_mae: 7.5308e-04 - val_mse: 8.5975e-07\n",
      "Epoch 16/1000\n",
      "227/227 [==============================] - 67s 296ms/step - loss: 3.8946e-06 - mae: 0.0022 - mse: 7.7892e-06 - val_loss: 4.0154e-07 - val_mae: 7.1807e-04 - val_mse: 8.0309e-07\n",
      "Epoch 17/1000\n",
      "227/227 [==============================] - 65s 285ms/step - loss: 3.6588e-06 - mae: 0.0021 - mse: 7.3177e-06 - val_loss: 5.4108e-07 - val_mae: 8.6432e-04 - val_mse: 1.0822e-06\n",
      "Epoch 18/1000\n",
      "227/227 [==============================] - 67s 293ms/step - loss: 3.3529e-06 - mae: 0.0020 - mse: 6.7059e-06 - val_loss: 4.7703e-07 - val_mae: 7.6990e-04 - val_mse: 9.5405e-07\n",
      "Epoch 19/1000\n",
      "227/227 [==============================] - 67s 294ms/step - loss: 3.7164e-06 - mae: 0.0021 - mse: 7.4329e-06 - val_loss: 5.7373e-07 - val_mae: 8.6904e-04 - val_mse: 1.1475e-06\n",
      "Epoch 20/1000\n",
      "227/227 [==============================] - 67s 295ms/step - loss: 3.2453e-06 - mae: 0.0020 - mse: 6.4907e-06 - val_loss: 4.7213e-07 - val_mae: 7.6079e-04 - val_mse: 9.4425e-07\n",
      "Epoch 21/1000\n",
      "227/227 [==============================] - 66s 291ms/step - loss: 3.2229e-06 - mae: 0.0020 - mse: 6.4457e-06 - val_loss: 4.3132e-07 - val_mae: 7.5326e-04 - val_mse: 8.6265e-07\n",
      "Epoch 22/1000\n",
      "227/227 [==============================] - 66s 292ms/step - loss: 3.1825e-06 - mae: 0.0020 - mse: 6.3649e-06 - val_loss: 5.2001e-07 - val_mae: 7.9409e-04 - val_mse: 1.0400e-06\n",
      "Epoch 23/1000\n",
      "227/227 [==============================] - 67s 295ms/step - loss: 3.0955e-06 - mae: 0.0019 - mse: 6.1910e-06 - val_loss: 4.2606e-07 - val_mae: 7.4870e-04 - val_mse: 8.5212e-07\n",
      "Epoch 24/1000\n",
      "227/227 [==============================] - 65s 288ms/step - loss: 3.2758e-06 - mae: 0.0020 - mse: 6.5517e-06 - val_loss: 8.4628e-07 - val_mae: 0.0010 - val_mse: 1.6926e-06\n",
      "Epoch 25/1000\n",
      "227/227 [==============================] - 65s 286ms/step - loss: 3.3705e-06 - mae: 0.0020 - mse: 6.7411e-06 - val_loss: 1.0752e-06 - val_mae: 0.0012 - val_mse: 2.1504e-06\n",
      "Epoch 26/1000\n",
      "227/227 [==============================] - 66s 292ms/step - loss: 3.4298e-06 - mae: 0.0021 - mse: 6.8595e-06 - val_loss: 1.4832e-06 - val_mae: 0.0015 - val_mse: 2.9664e-06\n",
      "Epoch 27/1000\n",
      "227/227 [==============================] - 67s 294ms/step - loss: 3.5461e-06 - mae: 0.0021 - mse: 7.0922e-06 - val_loss: 1.6626e-06 - val_mae: 0.0015 - val_mse: 3.3252e-06\n",
      "Epoch 28/1000\n",
      "227/227 [==============================] - 65s 287ms/step - loss: 3.6281e-06 - mae: 0.0021 - mse: 7.2562e-06 - val_loss: 1.1820e-06 - val_mae: 0.0013 - val_mse: 2.3640e-06\n",
      "Epoch 29/1000\n",
      "227/227 [==============================] - 68s 299ms/step - loss: 3.3228e-06 - mae: 0.0020 - mse: 6.6456e-06 - val_loss: 6.2838e-07 - val_mae: 8.9956e-04 - val_mse: 1.2568e-06\n",
      "Epoch 30/1000\n",
      "227/227 [==============================] - 67s 293ms/step - loss: 3.0631e-06 - mae: 0.0019 - mse: 6.1262e-06 - val_loss: 5.2702e-07 - val_mae: 8.1377e-04 - val_mse: 1.0540e-06\n",
      "Epoch 31/1000\n",
      "227/227 [==============================] - 67s 294ms/step - loss: 3.0241e-06 - mae: 0.0019 - mse: 6.0482e-06 - val_loss: 5.1872e-07 - val_mae: 8.5381e-04 - val_mse: 1.0374e-06\n",
      "Epoch 32/1000\n",
      "227/227 [==============================] - 66s 291ms/step - loss: 2.8971e-06 - mae: 0.0019 - mse: 5.7942e-06 - val_loss: 5.4882e-07 - val_mae: 8.7181e-04 - val_mse: 1.0976e-06\n",
      "Epoch 33/1000\n",
      "227/227 [==============================] - 65s 287ms/step - loss: 2.8348e-06 - mae: 0.0019 - mse: 5.6696e-06 - val_loss: 5.5942e-07 - val_mae: 8.8679e-04 - val_mse: 1.1188e-06\n",
      "Epoch 34/1000\n",
      "227/227 [==============================] - 66s 290ms/step - loss: 3.0305e-06 - mae: 0.0019 - mse: 6.0610e-06 - val_loss: 5.6747e-07 - val_mae: 9.1848e-04 - val_mse: 1.1349e-06\n",
      "Epoch 35/1000\n",
      "227/227 [==============================] - 65s 287ms/step - loss: 3.0590e-06 - mae: 0.0019 - mse: 6.1180e-06 - val_loss: 6.4107e-07 - val_mae: 9.5285e-04 - val_mse: 1.2821e-06\n",
      "Epoch 36/1000\n",
      "227/227 [==============================] - 64s 280ms/step - loss: 3.2417e-06 - mae: 0.0020 - mse: 6.4835e-06 - val_loss: 6.1790e-07 - val_mae: 8.9727e-04 - val_mse: 1.2358e-06\n",
      "Epoch 37/1000\n",
      "227/227 [==============================] - 64s 280ms/step - loss: 3.6590e-06 - mae: 0.0021 - mse: 7.3180e-06 - val_loss: 1.3967e-06 - val_mae: 0.0014 - val_mse: 2.7934e-06\n",
      "Epoch 38/1000\n",
      "227/227 [==============================] - 64s 283ms/step - loss: 4.3477e-06 - mae: 0.0022 - mse: 8.6954e-06 - val_loss: 3.2372e-06 - val_mae: 0.0020 - val_mse: 6.4744e-06\n",
      "Epoch 39/1000\n",
      "227/227 [==============================] - 64s 280ms/step - loss: 4.7321e-06 - mae: 0.0023 - mse: 9.4643e-06 - val_loss: 2.2240e-06 - val_mae: 0.0017 - val_mse: 4.4480e-06\n",
      "Epoch 40/1000\n",
      "227/227 [==============================] - 64s 281ms/step - loss: 3.9812e-06 - mae: 0.0022 - mse: 7.9624e-06 - val_loss: 5.4783e-07 - val_mae: 8.5209e-04 - val_mse: 1.0957e-06\n",
      "Epoch 41/1000\n",
      "227/227 [==============================] - 64s 280ms/step - loss: 2.6749e-06 - mae: 0.0018 - mse: 5.3499e-06 - val_loss: 6.3842e-07 - val_mae: 9.1210e-04 - val_mse: 1.2768e-06\n",
      "Epoch 42/1000\n",
      "227/227 [==============================] - 64s 280ms/step - loss: 2.5606e-06 - mae: 0.0018 - mse: 5.1212e-06 - val_loss: 5.2237e-07 - val_mae: 8.2477e-04 - val_mse: 1.0447e-06\n",
      "Epoch 43/1000\n",
      "227/227 [==============================] - 64s 281ms/step - loss: 2.5337e-06 - mae: 0.0018 - mse: 5.0675e-06 - val_loss: 5.6673e-07 - val_mae: 8.5410e-04 - val_mse: 1.1335e-06\n",
      "Epoch 44/1000\n",
      "227/227 [==============================] - 64s 282ms/step - loss: 2.3441e-06 - mae: 0.0017 - mse: 4.6881e-06 - val_loss: 4.2754e-07 - val_mae: 7.3149e-04 - val_mse: 8.5508e-07\n",
      "Epoch 45/1000\n",
      "227/227 [==============================] - 64s 280ms/step - loss: 2.4157e-06 - mae: 0.0017 - mse: 4.8313e-06 - val_loss: 4.5319e-07 - val_mae: 7.5841e-04 - val_mse: 9.0637e-07\n",
      "Epoch 46/1000\n",
      "227/227 [==============================] - 64s 281ms/step - loss: 2.4043e-06 - mae: 0.0017 - mse: 4.8087e-06 - val_loss: 5.4088e-07 - val_mae: 8.0999e-04 - val_mse: 1.0818e-06\n",
      "Epoch 47/1000\n",
      "227/227 [==============================] - 64s 280ms/step - loss: 2.2232e-06 - mae: 0.0017 - mse: 4.4464e-06 - val_loss: 4.2871e-07 - val_mae: 7.3159e-04 - val_mse: 8.5742e-07\n",
      "Epoch 48/1000\n",
      "227/227 [==============================] - 63s 279ms/step - loss: 2.2340e-06 - mae: 0.0017 - mse: 4.4679e-06 - val_loss: 4.3926e-07 - val_mae: 7.3378e-04 - val_mse: 8.7851e-07\n",
      "Epoch 49/1000\n",
      "227/227 [==============================] - 64s 280ms/step - loss: 2.1955e-06 - mae: 0.0016 - mse: 4.3909e-06 - val_loss: 4.6254e-07 - val_mae: 7.4543e-04 - val_mse: 9.2508e-07\n",
      "Epoch 50/1000\n",
      "227/227 [==============================] - 63s 279ms/step - loss: 2.2462e-06 - mae: 0.0017 - mse: 4.4923e-06 - val_loss: 4.2009e-07 - val_mae: 7.1650e-04 - val_mse: 8.4018e-07\n",
      "Epoch 51/1000\n",
      "227/227 [==============================] - 64s 280ms/step - loss: 2.3500e-06 - mae: 0.0017 - mse: 4.7001e-06 - val_loss: 3.9817e-07 - val_mae: 6.8395e-04 - val_mse: 7.9635e-07\n",
      "Epoch 52/1000\n",
      "227/227 [==============================] - 69s 304ms/step - loss: 2.2924e-06 - mae: 0.0017 - mse: 4.5848e-06 - val_loss: 4.8224e-07 - val_mae: 7.4314e-04 - val_mse: 9.6449e-07\n",
      "Epoch 53/1000\n",
      "227/227 [==============================] - 68s 299ms/step - loss: 2.2558e-06 - mae: 0.0017 - mse: 4.5115e-06 - val_loss: 5.5439e-07 - val_mae: 8.0897e-04 - val_mse: 1.1088e-06\n",
      "Epoch 54/1000\n",
      "227/227 [==============================] - 67s 295ms/step - loss: 2.3760e-06 - mae: 0.0017 - mse: 4.7519e-06 - val_loss: 6.7216e-07 - val_mae: 9.1680e-04 - val_mse: 1.3443e-06\n",
      "Epoch 55/1000\n",
      "227/227 [==============================] - 66s 290ms/step - loss: 2.3882e-06 - mae: 0.0017 - mse: 4.7763e-06 - val_loss: 7.4261e-07 - val_mae: 9.6062e-04 - val_mse: 1.4852e-06\n",
      "Epoch 56/1000\n",
      "227/227 [==============================] - 63s 279ms/step - loss: 2.4741e-06 - mae: 0.0017 - mse: 4.9483e-06 - val_loss: 8.5790e-07 - val_mae: 0.0011 - val_mse: 1.7158e-06\n",
      "Epoch 57/1000\n",
      "227/227 [==============================] - 64s 282ms/step - loss: 2.5302e-06 - mae: 0.0017 - mse: 5.0604e-06 - val_loss: 1.0147e-06 - val_mae: 0.0012 - val_mse: 2.0293e-06\n",
      "Epoch 58/1000\n",
      "227/227 [==============================] - 64s 284ms/step - loss: 2.6674e-06 - mae: 0.0018 - mse: 5.3348e-06 - val_loss: 1.0868e-06 - val_mae: 0.0012 - val_mse: 2.1736e-06\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 3.8420e-07 - mae: 6.5369e-04 - mse: 7.6840e-07\n"
     ]
    }
   ],
   "source": [
    "mae_yt1, mse_yt1 = fit_and_evaluate(yt_model1, seq2seq_train, seq2seq_valid,\n",
    "                 learning_rate=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0f64fb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code â€“ ensures reproducibility\n",
    "yt_model2 = tf.keras.Sequential([\n",
    "    \n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=4, strides=2, activation=\"relu\", input_shape=[None, 7]),\n",
    "    tf.keras.layers.GRU(32, return_sequences=True),\n",
    "    #tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(14))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ec351a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "225/225 [==============================] - 5s 15ms/step - loss: 0.0760 - mae: 0.2893 - mse: 0.1534 - val_loss: 0.0221 - val_mae: 0.1651 - val_mse: 0.0442\n",
      "Epoch 2/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.0077 - mae: 0.0920 - mse: 0.0154 - val_loss: 0.0018 - val_mae: 0.0481 - val_mse: 0.0037\n",
      "Epoch 3/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.1287e-04 - mae: 0.0299 - mse: 0.0016 - val_loss: 1.6937e-04 - val_mae: 0.0133 - val_mse: 3.3874e-04\n",
      "Epoch 4/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.4413e-05 - mae: 0.0096 - mse: 1.6883e-04 - val_loss: 1.7954e-05 - val_mae: 0.0043 - val_mse: 3.5909e-05\n",
      "Epoch 5/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.6205e-06 - mae: 0.0034 - mse: 1.9241e-05 - val_loss: 3.0611e-06 - val_mae: 0.0020 - val_mse: 6.1221e-06\n",
      "Epoch 6/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 2.2168e-06 - mae: 0.0016 - mse: 4.4337e-06 - val_loss: 2.3666e-06 - val_mae: 0.0020 - val_mse: 4.7332e-06\n",
      "Epoch 7/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 7.3053e-07 - mae: 9.8431e-04 - mse: 1.4611e-06 - val_loss: 8.0636e-07 - val_mae: 0.0012 - val_mse: 1.6127e-06\n",
      "Epoch 8/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.1896e-07 - mae: 0.0011 - mse: 1.6379e-06 - val_loss: 8.9253e-07 - val_mae: 0.0012 - val_mse: 1.7851e-06\n",
      "Epoch 9/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.0166e-06 - mae: 0.0012 - mse: 2.0331e-06 - val_loss: 1.3082e-06 - val_mae: 0.0015 - val_mse: 2.6164e-06\n",
      "Epoch 10/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 7.8631e-07 - mae: 0.0011 - mse: 1.5726e-06 - val_loss: 1.5680e-06 - val_mae: 0.0017 - val_mse: 3.1359e-06\n",
      "Epoch 11/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.2302e-07 - mae: 0.0012 - mse: 1.8460e-06 - val_loss: 1.1494e-06 - val_mae: 0.0014 - val_mse: 2.2988e-06\n",
      "Epoch 12/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.1113e-07 - mae: 0.0012 - mse: 1.8223e-06 - val_loss: 1.7146e-06 - val_mae: 0.0018 - val_mse: 3.4292e-06\n",
      "Epoch 13/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 6.6986e-07 - mae: 9.5086e-04 - mse: 1.3397e-06 - val_loss: 6.7536e-07 - val_mae: 0.0011 - val_mse: 1.3507e-06\n",
      "Epoch 14/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 1.0126e-06 - mae: 0.0012 - mse: 2.0251e-06 - val_loss: 9.6248e-07 - val_mae: 0.0013 - val_mse: 1.9250e-06\n",
      "Epoch 15/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.1489e-06 - mae: 0.0013 - mse: 2.2979e-06 - val_loss: 1.6931e-06 - val_mae: 0.0018 - val_mse: 3.3862e-06\n",
      "Epoch 16/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.1291e-06 - mae: 0.0013 - mse: 2.2583e-06 - val_loss: 1.7686e-06 - val_mae: 0.0018 - val_mse: 3.5373e-06\n",
      "Epoch 17/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.5635e-07 - mae: 0.0012 - mse: 1.9127e-06 - val_loss: 1.6365e-06 - val_mae: 0.0017 - val_mse: 3.2730e-06\n",
      "Epoch 18/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.6929e-07 - mae: 0.0012 - mse: 1.9386e-06 - val_loss: 1.7250e-06 - val_mae: 0.0018 - val_mse: 3.4500e-06\n",
      "Epoch 19/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 7.2025e-07 - mae: 0.0010 - mse: 1.4405e-06 - val_loss: 8.2294e-07 - val_mae: 0.0012 - val_mse: 1.6459e-06\n",
      "Epoch 20/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.2694e-06 - mae: 0.0014 - mse: 2.5389e-06 - val_loss: 1.4339e-06 - val_mae: 0.0016 - val_mse: 2.8679e-06\n",
      "Epoch 21/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.2134e-07 - mae: 0.0011 - mse: 1.6427e-06 - val_loss: 1.1364e-06 - val_mae: 0.0014 - val_mse: 2.2727e-06\n",
      "Epoch 22/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.0151e-06 - mae: 0.0012 - mse: 2.0302e-06 - val_loss: 1.2437e-06 - val_mae: 0.0015 - val_mse: 2.4874e-06\n",
      "Epoch 23/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.1392e-06 - mae: 0.0013 - mse: 2.2784e-06 - val_loss: 2.1515e-06 - val_mae: 0.0020 - val_mse: 4.3030e-06\n",
      "Epoch 24/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 5.4996e-07 - mae: 8.7366e-04 - mse: 1.0999e-06 - val_loss: 8.2602e-07 - val_mae: 0.0012 - val_mse: 1.6520e-06\n",
      "Epoch 25/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.0306e-06 - mae: 0.0012 - mse: 2.0612e-06 - val_loss: 7.9496e-07 - val_mae: 0.0012 - val_mse: 1.5899e-06\n",
      "Epoch 26/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.7654e-07 - mae: 0.0011 - mse: 1.7531e-06 - val_loss: 9.2880e-07 - val_mae: 0.0013 - val_mse: 1.8576e-06\n",
      "Epoch 27/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 9.2156e-07 - mae: 0.0012 - mse: 1.8431e-06 - val_loss: 1.2290e-06 - val_mae: 0.0015 - val_mse: 2.4579e-06\n",
      "Epoch 28/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.7392e-07 - mae: 0.0012 - mse: 1.9478e-06 - val_loss: 1.1417e-06 - val_mae: 0.0014 - val_mse: 2.2833e-06\n",
      "Epoch 29/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 6.8576e-07 - mae: 9.6378e-04 - mse: 1.3715e-06 - val_loss: 8.6278e-07 - val_mae: 0.0012 - val_mse: 1.7256e-06\n",
      "Epoch 30/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 6.2519e-07 - mae: 8.5592e-04 - mse: 1.2504e-06 - val_loss: 2.7355e-07 - val_mae: 6.4101e-04 - val_mse: 5.4710e-07\n",
      "Epoch 31/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 1.4486e-06 - mae: 0.0015 - mse: 2.8973e-06 - val_loss: 2.0731e-06 - val_mae: 0.0020 - val_mse: 4.1462e-06\n",
      "Epoch 32/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 7.0718e-07 - mae: 9.9518e-04 - mse: 1.4144e-06 - val_loss: 1.1760e-06 - val_mae: 0.0015 - val_mse: 2.3520e-06\n",
      "Epoch 33/1000\n",
      "225/225 [==============================] - 4s 15ms/step - loss: 8.3945e-07 - mae: 0.0011 - mse: 1.6789e-06 - val_loss: 1.5581e-06 - val_mae: 0.0017 - val_mse: 3.1162e-06\n",
      "Epoch 34/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 6.0943e-07 - mae: 9.0991e-04 - mse: 1.2189e-06 - val_loss: 7.6660e-07 - val_mae: 0.0011 - val_mse: 1.5332e-06\n",
      "Epoch 35/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.1156e-06 - mae: 0.0013 - mse: 2.2313e-06 - val_loss: 1.7324e-06 - val_mae: 0.0018 - val_mse: 3.4648e-06\n",
      "Epoch 36/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 5.4537e-07 - mae: 8.4102e-04 - mse: 1.0907e-06 - val_loss: 8.1916e-07 - val_mae: 0.0012 - val_mse: 1.6383e-06\n",
      "Epoch 37/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.6583e-07 - mae: 0.0012 - mse: 1.9317e-06 - val_loss: 1.0516e-06 - val_mae: 0.0014 - val_mse: 2.1031e-06\n",
      "Epoch 38/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.1059e-06 - mae: 0.0013 - mse: 2.2118e-06 - val_loss: 2.0175e-06 - val_mae: 0.0019 - val_mse: 4.0350e-06\n",
      "Epoch 39/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.5470e-07 - mae: 0.0012 - mse: 1.9094e-06 - val_loss: 1.7415e-06 - val_mae: 0.0018 - val_mse: 3.4831e-06\n",
      "Epoch 40/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 6.4577e-07 - mae: 9.3916e-04 - mse: 1.2915e-06 - val_loss: 6.1324e-07 - val_mae: 0.0010 - val_mse: 1.2265e-06\n",
      "Epoch 41/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.9997e-07 - mae: 0.0011 - mse: 1.7999e-06 - val_loss: 9.3600e-07 - val_mae: 0.0013 - val_mse: 1.8720e-06\n",
      "Epoch 42/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.7042e-07 - mae: 0.0011 - mse: 1.7408e-06 - val_loss: 1.1273e-06 - val_mae: 0.0014 - val_mse: 2.2546e-06\n",
      "Epoch 43/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.0146e-06 - mae: 0.0012 - mse: 2.0292e-06 - val_loss: 1.9982e-06 - val_mae: 0.0019 - val_mse: 3.9963e-06\n",
      "Epoch 44/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 7.4229e-07 - mae: 0.0010 - mse: 1.4846e-06 - val_loss: 1.1994e-06 - val_mae: 0.0015 - val_mse: 2.3987e-06\n",
      "Epoch 45/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 7.8416e-07 - mae: 0.0010 - mse: 1.5683e-06 - val_loss: 9.5230e-07 - val_mae: 0.0013 - val_mse: 1.9046e-06\n",
      "Epoch 46/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.5718e-07 - mae: 0.0011 - mse: 1.7144e-06 - val_loss: 8.2140e-07 - val_mae: 0.0012 - val_mse: 1.6428e-06\n",
      "Epoch 47/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.4455e-07 - mae: 0.0012 - mse: 1.8891e-06 - val_loss: 1.1476e-06 - val_mae: 0.0014 - val_mse: 2.2952e-06\n",
      "Epoch 48/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.0645e-07 - mae: 0.0012 - mse: 1.8129e-06 - val_loss: 1.5694e-06 - val_mae: 0.0017 - val_mse: 3.1388e-06\n",
      "Epoch 49/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.7820e-07 - mae: 0.0012 - mse: 1.9564e-06 - val_loss: 1.2691e-06 - val_mae: 0.0015 - val_mse: 2.5382e-06\n",
      "Epoch 50/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.0380e-07 - mae: 0.0011 - mse: 1.6076e-06 - val_loss: 1.0907e-06 - val_mae: 0.0014 - val_mse: 2.1815e-06\n",
      "Epoch 51/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.0089e-06 - mae: 0.0012 - mse: 2.0179e-06 - val_loss: 1.4632e-06 - val_mae: 0.0016 - val_mse: 2.9263e-06\n",
      "Epoch 52/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.7202e-07 - mae: 0.0011 - mse: 1.7440e-06 - val_loss: 1.5937e-06 - val_mae: 0.0017 - val_mse: 3.1873e-06\n",
      "Epoch 53/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 5.6739e-07 - mae: 8.7632e-04 - mse: 1.1348e-06 - val_loss: 5.5411e-07 - val_mae: 9.4757e-04 - val_mse: 1.1082e-06\n",
      "Epoch 54/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.8370e-07 - mae: 0.0011 - mse: 1.7674e-06 - val_loss: 8.9950e-07 - val_mae: 0.0013 - val_mse: 1.7990e-06\n",
      "Epoch 55/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 1.1190e-06 - mae: 0.0013 - mse: 2.2379e-06 - val_loss: 1.6228e-06 - val_mae: 0.0017 - val_mse: 3.2455e-06\n",
      "Epoch 56/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 6.8792e-07 - mae: 9.7941e-04 - mse: 1.3758e-06 - val_loss: 9.1307e-07 - val_mae: 0.0013 - val_mse: 1.8261e-06\n",
      "Epoch 57/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 7.0427e-07 - mae: 9.6138e-04 - mse: 1.4085e-06 - val_loss: 7.2933e-07 - val_mae: 0.0011 - val_mse: 1.4587e-06\n",
      "Epoch 58/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.3757e-06 - mae: 0.0014 - mse: 2.7514e-06 - val_loss: 1.9812e-06 - val_mae: 0.0019 - val_mse: 3.9623e-06\n",
      "Epoch 59/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 7.2451e-07 - mae: 0.0010 - mse: 1.4490e-06 - val_loss: 9.4539e-07 - val_mae: 0.0013 - val_mse: 1.8908e-06\n",
      "Epoch 60/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.0626e-07 - mae: 0.0010 - mse: 1.6125e-06 - val_loss: 9.3365e-07 - val_mae: 0.0013 - val_mse: 1.8673e-06\n",
      "Epoch 61/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.1833e-06 - mae: 0.0013 - mse: 2.3665e-06 - val_loss: 1.3934e-06 - val_mae: 0.0016 - val_mse: 2.7867e-06\n",
      "Epoch 62/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.3502e-06 - mae: 0.0014 - mse: 2.7005e-06 - val_loss: 2.1358e-06 - val_mae: 0.0020 - val_mse: 4.2716e-06\n",
      "Epoch 63/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 5.7069e-07 - mae: 8.9553e-04 - mse: 1.1414e-06 - val_loss: 1.1958e-06 - val_mae: 0.0015 - val_mse: 2.3917e-06\n",
      "Epoch 64/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 7.6659e-07 - mae: 0.0010 - mse: 1.5332e-06 - val_loss: 6.6242e-07 - val_mae: 0.0011 - val_mse: 1.3248e-06\n",
      "Epoch 65/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.3982e-06 - mae: 0.0015 - mse: 2.7963e-06 - val_loss: 2.3481e-06 - val_mae: 0.0021 - val_mse: 4.6962e-06\n",
      "Epoch 66/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 7.0438e-07 - mae: 0.0010 - mse: 1.4088e-06 - val_loss: 1.0304e-06 - val_mae: 0.0014 - val_mse: 2.0608e-06\n",
      "Epoch 67/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.0880e-06 - mae: 0.0013 - mse: 2.1760e-06 - val_loss: 1.8029e-06 - val_mae: 0.0018 - val_mse: 3.6058e-06\n",
      "Epoch 68/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 7.2545e-07 - mae: 0.0010 - mse: 1.4509e-06 - val_loss: 8.2895e-07 - val_mae: 0.0012 - val_mse: 1.6579e-06\n",
      "Epoch 69/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 7.4025e-07 - mae: 9.9031e-04 - mse: 1.4805e-06 - val_loss: 8.3716e-07 - val_mae: 0.0012 - val_mse: 1.6743e-06\n",
      "Epoch 70/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.0253e-06 - mae: 0.0012 - mse: 2.0507e-06 - val_loss: 1.2408e-06 - val_mae: 0.0015 - val_mse: 2.4816e-06\n",
      "Epoch 71/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 7.0664e-07 - mae: 9.8046e-04 - mse: 1.4133e-06 - val_loss: 6.1285e-07 - val_mae: 0.0010 - val_mse: 1.2257e-06\n",
      "Epoch 72/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.1039e-06 - mae: 0.0012 - mse: 2.2079e-06 - val_loss: 1.2822e-06 - val_mae: 0.0015 - val_mse: 2.5644e-06\n",
      "Epoch 73/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 6.1354e-07 - mae: 9.0061e-04 - mse: 1.2271e-06 - val_loss: 7.8586e-07 - val_mae: 0.0012 - val_mse: 1.5717e-06\n",
      "Epoch 74/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.7562e-07 - mae: 0.0012 - mse: 1.9512e-06 - val_loss: 1.1575e-06 - val_mae: 0.0014 - val_mse: 2.3151e-06\n",
      "Epoch 75/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 7.2960e-07 - mae: 0.0010 - mse: 1.4592e-06 - val_loss: 7.1849e-07 - val_mae: 0.0011 - val_mse: 1.4370e-06\n",
      "Epoch 76/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.0722e-06 - mae: 0.0013 - mse: 2.1445e-06 - val_loss: 2.0337e-06 - val_mae: 0.0020 - val_mse: 4.0675e-06\n",
      "Epoch 77/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 7.2382e-07 - mae: 0.0010 - mse: 1.4476e-06 - val_loss: 1.1929e-06 - val_mae: 0.0015 - val_mse: 2.3858e-06\n",
      "Epoch 78/1000\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 1.2956e-06 - mae: 0.0014 - mse: 2.5911e-06 - val_loss: 2.6431e-06 - val_mae: 0.0022 - val_mse: 5.2863e-06\n",
      "Epoch 79/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 5.8493e-07 - mae: 9.1337e-04 - mse: 1.1699e-06 - val_loss: 1.0013e-06 - val_mae: 0.0013 - val_mse: 2.0026e-06\n",
      "Epoch 80/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.1405e-06 - mae: 0.0013 - mse: 2.2810e-06 - val_loss: 2.1726e-06 - val_mae: 0.0020 - val_mse: 4.3451e-06\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.7355e-07 - mae: 6.4101e-04 - mse: 5.4710e-07\n"
     ]
    }
   ],
   "source": [
    "mae_yt2, mse_yt2 = fit_and_evaluate(yt_model2, downsampled_train, downsampled_valid,\n",
    "                 learning_rate=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f1e9beac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code â€“ ensures reproducibility\n",
    "yt_model3 = tf.keras.Sequential([\n",
    "    \n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=4, strides=2, activation=\"relu\", input_shape=[None, 7]),\n",
    "    tf.keras.layers.GRU(32, return_sequences=True),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(14))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1d0bf06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "225/225 [==============================] - 5s 16ms/step - loss: 0.0865 - mae: 0.3240 - mse: 0.1754 - val_loss: 0.0102 - val_mae: 0.1178 - val_mse: 0.0205\n",
      "Epoch 2/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0114 - mae: 0.1158 - mse: 0.0228 - val_loss: 0.0011 - val_mae: 0.0381 - val_mse: 0.0021\n",
      "Epoch 3/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 0.0012 - mae: 0.0377 - mse: 0.0024 - val_loss: 1.1768e-04 - val_mae: 0.0127 - val_mse: 2.3537e-04\n",
      "Epoch 4/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.2469e-04 - mae: 0.0122 - mse: 2.4937e-04 - val_loss: 1.1707e-05 - val_mae: 0.0039 - val_mse: 2.3413e-05\n",
      "Epoch 5/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.4766e-05 - mae: 0.0042 - mse: 2.9532e-05 - val_loss: 3.5730e-06 - val_mae: 0.0024 - val_mse: 7.1460e-06\n",
      "Epoch 6/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 2.2378e-06 - mae: 0.0017 - mse: 4.4757e-06 - val_loss: 1.8477e-06 - val_mae: 0.0018 - val_mse: 3.6954e-06\n",
      "Epoch 7/1000\n",
      "225/225 [==============================] - 4s 15ms/step - loss: 9.6117e-07 - mae: 0.0011 - mse: 1.9223e-06 - val_loss: 1.3136e-06 - val_mae: 0.0015 - val_mse: 2.6273e-06\n",
      "Epoch 8/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.8455e-07 - mae: 0.0011 - mse: 1.7691e-06 - val_loss: 1.2455e-06 - val_mae: 0.0015 - val_mse: 2.4910e-06\n",
      "Epoch 9/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.2286e-07 - mae: 0.0011 - mse: 1.8457e-06 - val_loss: 1.6333e-06 - val_mae: 0.0017 - val_mse: 3.2667e-06\n",
      "Epoch 10/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.4043e-07 - mae: 0.0011 - mse: 1.6809e-06 - val_loss: 1.3647e-06 - val_mae: 0.0016 - val_mse: 2.7294e-06\n",
      "Epoch 11/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.0473e-06 - mae: 0.0012 - mse: 2.0945e-06 - val_loss: 1.4230e-06 - val_mae: 0.0016 - val_mse: 2.8460e-06\n",
      "Epoch 12/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.1021e-06 - mae: 0.0013 - mse: 2.2042e-06 - val_loss: 1.9909e-06 - val_mae: 0.0019 - val_mse: 3.9818e-06\n",
      "Epoch 13/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 7.7809e-07 - mae: 0.0010 - mse: 1.5562e-06 - val_loss: 1.3391e-06 - val_mae: 0.0016 - val_mse: 2.6781e-06\n",
      "Epoch 14/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.3351e-07 - mae: 0.0011 - mse: 1.8670e-06 - val_loss: 1.5444e-06 - val_mae: 0.0017 - val_mse: 3.0888e-06\n",
      "Epoch 15/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.5906e-07 - mae: 0.0012 - mse: 1.9181e-06 - val_loss: 1.5478e-06 - val_mae: 0.0017 - val_mse: 3.0957e-06\n",
      "Epoch 16/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.4763e-07 - mae: 0.0011 - mse: 1.6953e-06 - val_loss: 1.2508e-06 - val_mae: 0.0015 - val_mse: 2.5016e-06\n",
      "Epoch 17/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.0167e-06 - mae: 0.0012 - mse: 2.0334e-06 - val_loss: 1.6941e-06 - val_mae: 0.0018 - val_mse: 3.3882e-06\n",
      "Epoch 18/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.5358e-07 - mae: 0.0011 - mse: 1.7072e-06 - val_loss: 1.4031e-06 - val_mae: 0.0016 - val_mse: 2.8063e-06\n",
      "Epoch 19/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.1931e-06 - mae: 0.0013 - mse: 2.3863e-06 - val_loss: 1.9193e-06 - val_mae: 0.0019 - val_mse: 3.8387e-06\n",
      "Epoch 20/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.8025e-07 - mae: 0.0011 - mse: 1.7605e-06 - val_loss: 1.3669e-06 - val_mae: 0.0016 - val_mse: 2.7338e-06\n",
      "Epoch 21/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.8909e-07 - mae: 0.0011 - mse: 1.7782e-06 - val_loss: 1.5996e-06 - val_mae: 0.0017 - val_mse: 3.1991e-06\n",
      "Epoch 22/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.6906e-07 - mae: 0.0011 - mse: 1.7381e-06 - val_loss: 1.4034e-06 - val_mae: 0.0016 - val_mse: 2.8068e-06\n",
      "Epoch 23/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.2488e-07 - mae: 0.0011 - mse: 1.6498e-06 - val_loss: 1.3313e-06 - val_mae: 0.0016 - val_mse: 2.6626e-06\n",
      "Epoch 24/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.8417e-07 - mae: 0.0012 - mse: 1.9683e-06 - val_loss: 1.8508e-06 - val_mae: 0.0019 - val_mse: 3.7016e-06\n",
      "Epoch 25/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 7.5046e-07 - mae: 0.0010 - mse: 1.5009e-06 - val_loss: 1.0802e-06 - val_mae: 0.0014 - val_mse: 2.1605e-06\n",
      "Epoch 26/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.0453e-06 - mae: 0.0012 - mse: 2.0906e-06 - val_loss: 1.3303e-06 - val_mae: 0.0016 - val_mse: 2.6605e-06\n",
      "Epoch 27/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 8.0924e-07 - mae: 0.0011 - mse: 1.6185e-06 - val_loss: 1.3181e-06 - val_mae: 0.0015 - val_mse: 2.6362e-06\n",
      "Epoch 28/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.0012e-06 - mae: 0.0012 - mse: 2.0023e-06 - val_loss: 1.7822e-06 - val_mae: 0.0018 - val_mse: 3.5643e-06\n",
      "Epoch 29/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.4052e-07 - mae: 0.0012 - mse: 1.8810e-06 - val_loss: 1.7291e-06 - val_mae: 0.0018 - val_mse: 3.4582e-06\n",
      "Epoch 30/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.4697e-07 - mae: 0.0011 - mse: 1.6939e-06 - val_loss: 1.1169e-06 - val_mae: 0.0014 - val_mse: 2.2339e-06\n",
      "Epoch 31/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.5368e-07 - mae: 0.0012 - mse: 1.9074e-06 - val_loss: 1.6478e-06 - val_mae: 0.0017 - val_mse: 3.2956e-06\n",
      "Epoch 32/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 7.6655e-07 - mae: 0.0010 - mse: 1.5331e-06 - val_loss: 1.1238e-06 - val_mae: 0.0014 - val_mse: 2.2476e-06\n",
      "Epoch 33/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.0827e-07 - mae: 0.0011 - mse: 1.8165e-06 - val_loss: 1.3250e-06 - val_mae: 0.0016 - val_mse: 2.6500e-06\n",
      "Epoch 34/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 7.5997e-07 - mae: 0.0010 - mse: 1.5199e-06 - val_loss: 8.9167e-07 - val_mae: 0.0012 - val_mse: 1.7833e-06\n",
      "Epoch 35/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.2252e-06 - mae: 0.0013 - mse: 2.4503e-06 - val_loss: 2.3712e-06 - val_mae: 0.0021 - val_mse: 4.7425e-06\n",
      "Epoch 36/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 7.0058e-07 - mae: 9.8563e-04 - mse: 1.4012e-06 - val_loss: 1.4231e-06 - val_mae: 0.0016 - val_mse: 2.8463e-06\n",
      "Epoch 37/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 7.9078e-07 - mae: 0.0010 - mse: 1.5816e-06 - val_loss: 9.7682e-07 - val_mae: 0.0013 - val_mse: 1.9536e-06\n",
      "Epoch 38/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.1509e-06 - mae: 0.0013 - mse: 2.3018e-06 - val_loss: 1.9509e-06 - val_mae: 0.0019 - val_mse: 3.9018e-06\n",
      "Epoch 39/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.5459e-07 - mae: 0.0012 - mse: 1.9092e-06 - val_loss: 1.8514e-06 - val_mae: 0.0019 - val_mse: 3.7027e-06\n",
      "Epoch 40/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.1788e-07 - mae: 0.0011 - mse: 1.6358e-06 - val_loss: 1.5571e-06 - val_mae: 0.0017 - val_mse: 3.1141e-06\n",
      "Epoch 41/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.0639e-07 - mae: 0.0011 - mse: 1.8128e-06 - val_loss: 1.1536e-06 - val_mae: 0.0014 - val_mse: 2.3073e-06\n",
      "Epoch 42/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.8684e-07 - mae: 0.0012 - mse: 1.9737e-06 - val_loss: 1.8034e-06 - val_mae: 0.0018 - val_mse: 3.6068e-06\n",
      "Epoch 43/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 7.4000e-07 - mae: 0.0010 - mse: 1.4800e-06 - val_loss: 1.1803e-06 - val_mae: 0.0015 - val_mse: 2.3607e-06\n",
      "Epoch 44/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.0137e-06 - mae: 0.0012 - mse: 2.0274e-06 - val_loss: 1.5478e-06 - val_mae: 0.0017 - val_mse: 3.0957e-06\n",
      "Epoch 45/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 7.5979e-07 - mae: 0.0010 - mse: 1.5196e-06 - val_loss: 1.1188e-06 - val_mae: 0.0014 - val_mse: 2.2376e-06\n",
      "Epoch 46/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.1011e-06 - mae: 0.0013 - mse: 2.2022e-06 - val_loss: 2.2647e-06 - val_mae: 0.0021 - val_mse: 4.5294e-06\n",
      "Epoch 47/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.3075e-07 - mae: 0.0011 - mse: 1.6615e-06 - val_loss: 1.5831e-06 - val_mae: 0.0017 - val_mse: 3.1663e-06\n",
      "Epoch 48/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 7.8242e-07 - mae: 0.0010 - mse: 1.5648e-06 - val_loss: 1.4196e-06 - val_mae: 0.0016 - val_mse: 2.8392e-06\n",
      "Epoch 49/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.0915e-07 - mae: 0.0011 - mse: 1.8183e-06 - val_loss: 1.5499e-06 - val_mae: 0.0017 - val_mse: 3.0998e-06\n",
      "Epoch 50/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 7.7088e-07 - mae: 0.0010 - mse: 1.5418e-06 - val_loss: 1.3084e-06 - val_mae: 0.0015 - val_mse: 2.6169e-06\n",
      "Epoch 51/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.0282e-06 - mae: 0.0012 - mse: 2.0563e-06 - val_loss: 1.6179e-06 - val_mae: 0.0017 - val_mse: 3.2359e-06\n",
      "Epoch 52/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 7.5087e-07 - mae: 0.0010 - mse: 1.5017e-06 - val_loss: 9.6680e-07 - val_mae: 0.0013 - val_mse: 1.9336e-06\n",
      "Epoch 53/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.2561e-06 - mae: 0.0014 - mse: 2.5122e-06 - val_loss: 2.1091e-06 - val_mae: 0.0020 - val_mse: 4.2181e-06\n",
      "Epoch 54/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 6.6653e-07 - mae: 9.5615e-04 - mse: 1.3331e-06 - val_loss: 9.7330e-07 - val_mae: 0.0013 - val_mse: 1.9466e-06\n",
      "Epoch 55/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 1.1932e-06 - mae: 0.0013 - mse: 2.3863e-06 - val_loss: 1.7028e-06 - val_mae: 0.0018 - val_mse: 3.4056e-06\n",
      "Epoch 56/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 7.7765e-07 - mae: 0.0010 - mse: 1.5553e-06 - val_loss: 1.6082e-06 - val_mae: 0.0017 - val_mse: 3.2165e-06\n",
      "Epoch 57/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 8.9355e-07 - mae: 0.0011 - mse: 1.7871e-06 - val_loss: 1.5023e-06 - val_mae: 0.0017 - val_mse: 3.0046e-06\n",
      "Epoch 58/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 9.1715e-07 - mae: 0.0011 - mse: 1.8343e-06 - val_loss: 1.3449e-06 - val_mae: 0.0016 - val_mse: 2.6899e-06\n",
      "Epoch 59/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 8.8000e-07 - mae: 0.0011 - mse: 1.7600e-06 - val_loss: 1.5556e-06 - val_mae: 0.0017 - val_mse: 3.1112e-06\n",
      "Epoch 60/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 8.6590e-07 - mae: 0.0011 - mse: 1.7318e-06 - val_loss: 1.3056e-06 - val_mae: 0.0015 - val_mse: 2.6113e-06\n",
      "Epoch 61/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 1.2176e-06 - mae: 0.0013 - mse: 2.4352e-06 - val_loss: 1.7739e-06 - val_mae: 0.0018 - val_mse: 3.5477e-06\n",
      "Epoch 62/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 8.6513e-07 - mae: 0.0011 - mse: 1.7303e-06 - val_loss: 1.4126e-06 - val_mae: 0.0016 - val_mse: 2.8252e-06\n",
      "Epoch 63/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 9.1484e-07 - mae: 0.0011 - mse: 1.8297e-06 - val_loss: 1.5139e-06 - val_mae: 0.0017 - val_mse: 3.0278e-06\n",
      "Epoch 64/1000\n",
      "225/225 [==============================] - 4s 15ms/step - loss: 1.0381e-06 - mae: 0.0012 - mse: 2.0762e-06 - val_loss: 1.6706e-06 - val_mae: 0.0018 - val_mse: 3.3412e-06\n",
      "Epoch 65/1000\n",
      "225/225 [==============================] - 4s 15ms/step - loss: 8.0205e-07 - mae: 0.0011 - mse: 1.6041e-06 - val_loss: 1.3900e-06 - val_mae: 0.0016 - val_mse: 2.7799e-06\n",
      "Epoch 66/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 1.0459e-06 - mae: 0.0012 - mse: 2.0917e-06 - val_loss: 1.5172e-06 - val_mae: 0.0017 - val_mse: 3.0344e-06\n",
      "Epoch 67/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 9.2300e-07 - mae: 0.0012 - mse: 1.8460e-06 - val_loss: 1.6297e-06 - val_mae: 0.0017 - val_mse: 3.2595e-06\n",
      "Epoch 68/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 7.9250e-07 - mae: 0.0011 - mse: 1.5850e-06 - val_loss: 1.4222e-06 - val_mae: 0.0016 - val_mse: 2.8444e-06\n",
      "Epoch 69/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 8.4826e-07 - mae: 0.0011 - mse: 1.6965e-06 - val_loss: 1.2518e-06 - val_mae: 0.0015 - val_mse: 2.5036e-06\n",
      "Epoch 70/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 9.8422e-07 - mae: 0.0012 - mse: 1.9684e-06 - val_loss: 1.4739e-06 - val_mae: 0.0016 - val_mse: 2.9477e-06\n",
      "Epoch 71/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 9.4594e-07 - mae: 0.0012 - mse: 1.8919e-06 - val_loss: 1.7441e-06 - val_mae: 0.0018 - val_mse: 3.4883e-06\n",
      "Epoch 72/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.0051e-06 - mae: 0.0012 - mse: 2.0102e-06 - val_loss: 1.9870e-06 - val_mae: 0.0019 - val_mse: 3.9739e-06\n",
      "Epoch 73/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.8991e-07 - mae: 0.0011 - mse: 1.7798e-06 - val_loss: 1.8821e-06 - val_mae: 0.0019 - val_mse: 3.7641e-06\n",
      "Epoch 74/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 8.5302e-07 - mae: 0.0011 - mse: 1.7060e-06 - val_loss: 1.2047e-06 - val_mae: 0.0015 - val_mse: 2.4095e-06\n",
      "Epoch 75/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.0551e-06 - mae: 0.0012 - mse: 2.1101e-06 - val_loss: 2.0063e-06 - val_mae: 0.0019 - val_mse: 4.0127e-06\n",
      "Epoch 76/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 7.0015e-07 - mae: 9.8513e-04 - mse: 1.4003e-06 - val_loss: 1.0784e-06 - val_mae: 0.0014 - val_mse: 2.1567e-06\n",
      "Epoch 77/1000\n",
      "225/225 [==============================] - 3s 14ms/step - loss: 1.0169e-06 - mae: 0.0012 - mse: 2.0338e-06 - val_loss: 1.2247e-06 - val_mae: 0.0015 - val_mse: 2.4495e-06\n",
      "Epoch 78/1000\n",
      "225/225 [==============================] - 4s 15ms/step - loss: 9.1436e-07 - mae: 0.0011 - mse: 1.8287e-06 - val_loss: 1.3043e-06 - val_mae: 0.0015 - val_mse: 2.6086e-06\n",
      "Epoch 79/1000\n",
      "225/225 [==============================] - 4s 16ms/step - loss: 8.5921e-07 - mae: 0.0011 - mse: 1.7184e-06 - val_loss: 1.2611e-06 - val_mae: 0.0015 - val_mse: 2.5222e-06\n",
      "Epoch 80/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 1.1414e-06 - mae: 0.0013 - mse: 2.2828e-06 - val_loss: 1.6423e-06 - val_mae: 0.0017 - val_mse: 3.2846e-06\n",
      "Epoch 81/1000\n",
      "225/225 [==============================] - 4s 15ms/step - loss: 8.6020e-07 - mae: 0.0011 - mse: 1.7204e-06 - val_loss: 1.2932e-06 - val_mae: 0.0015 - val_mse: 2.5864e-06\n",
      "Epoch 82/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 8.9407e-07 - mae: 0.0011 - mse: 1.7881e-06 - val_loss: 1.0908e-06 - val_mae: 0.0014 - val_mse: 2.1815e-06\n",
      "Epoch 83/1000\n",
      "225/225 [==============================] - 3s 15ms/step - loss: 1.1708e-06 - mae: 0.0013 - mse: 2.3416e-06 - val_loss: 1.9776e-06 - val_mae: 0.0019 - val_mse: 3.9552e-06\n",
      "Epoch 84/1000\n",
      "225/225 [==============================] - 4s 15ms/step - loss: 8.0797e-07 - mae: 0.0011 - mse: 1.6159e-06 - val_loss: 1.2383e-06 - val_mae: 0.0015 - val_mse: 2.4766e-06\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 8.9167e-07 - mae: 0.0012 - mse: 1.7833e-06\n"
     ]
    }
   ],
   "source": [
    "mae_yt3, mse_yt3 = fit_and_evaluate(yt_model3, downsampled_train, downsampled_valid,\n",
    "                 learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563b80c1",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5c826db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_data = {\n",
    "    #'Simple RNN': {'MAE': mae_rnn, 'MSE': mse_rnn},\n",
    "    #'Univariable': {'MAE': mae_univar, 'MSE': mse_univar},\n",
    "    #'Deep RNN': {'MAE': mae_deep, 'MSE': mse_deep},\n",
    "    #'Multivariable': {'MAE': mae_mul, 'MSE': mse_mul},\n",
    "    '14 Step Ahead': {'MAE': mae_ahead, 'MSE': mse_ahead},\n",
    "    'Custom LN': {'MAE': mae_cstm, 'MSE': mse_cstm},\n",
    "    'LSTM': {'MAE': mae_lstm, 'MSE': mse_lstm},\n",
    "    'GRU': {'MAE': mae_gru, 'MSE': mse_gru},\n",
    "    '1-Dim Conv Layer': {'MAE': mae_conv, 'MSE': mse_conv},\n",
    "    'Wavenet': {'MAE': mae_wave, 'MSE': mse_wave},\n",
    "    'YT Model 1': {'MAE': mae_yt1, 'MSE': mse_yt1},\n",
    "    'YT Model 2': {'MAE': mae_yt2, 'MSE': mse_yt2},\n",
    "    'YT Model 3': {'MAE': mae_yt3, 'MSE': mse_yt3}\n",
    "}\n",
    "\n",
    "# Extracting model names, MAE values, and MSE values from the dictionary\n",
    "models = list(model_data.keys())\n",
    "mae_values = [model_data[model]['MAE'] for model in models]\n",
    "mse_values = [model_data[model]['MSE'] for model in models]\n",
    "\n",
    "# Creating bar charts to compare MAE values of different models\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(models, mae_values, color='blue')\n",
    "plt.title('Mean Absolute Error (MAE) Comparison')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('MAE Values')\n",
    "plt.xticks(rotation='vertical') \n",
    "\n",
    "# Creating bar charts to compare MSE values of different models\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(models, mse_values, color='red')\n",
    "plt.title('Mean Squared Error (MSE) Comparison')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('MSE Values')\n",
    "plt.xticks(rotation='vertical') \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
